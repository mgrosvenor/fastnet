%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Matthew Grosvenor at 2013-01-27 13:38:19 +0000 


%% Saved with string encoding Unicode (UTF-8) 



@book{barroso2009datacenter,
	Author = {Barroso, L.A. and H{\"o}lzle, U.},
	Date-Added = {2012-11-07 12:35:26 +0000},
	Date-Modified = {2012-11-07 12:35:26 +0000},
	Isbn = {9781598295566},
	Publisher = {Morgan \& Claypool},
	Series = {Synthesis lectures in computer architecture},
	Title = {The Datacenter as a Computer: An Introduction to the Design of Warehouse-scale Machines},
	Url = {http://books.google.co.uk/books?id=Y3hhzdSSK58C},
	Year = {2009},
	Bdsk-Url-1 = {http://books.google.co.uk/books?id=Y3hhzdSSK58C}}

@article{Ha:2008:CNT:1400097.1400105,
	Acmid = {1400105},
	Address = {New York, NY, USA},
	Author = {Ha, Sangtae and Rhee, Injong and Xu, Lisong},
	Date-Added = {2012-11-05 17:33:18 +0000},
	Date-Modified = {2012-11-05 17:33:18 +0000},
	Doi = {10.1145/1400097.1400105},
	Issn = {0163-5980},
	Issue_Date = {July 2008},
	Journal = {SIGOPS Oper. Syst. Rev.},
	Month = jul,
	Number = {5},
	Numpages = {11},
	Pages = {64--74},
	Publisher = {ACM},
	Title = {CUBIC: a new TCP-friendly high-speed TCP variant},
	Url = {http://doi.acm.org/10.1145/1400097.1400105},
	Volume = {42},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1400097.1400105},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1400097.1400105}}

@misc{ieee8023,
	Author = {{IEEE Standards Association}},
	Date-Added = {2012-11-05 17:19:33 +0000},
	Date-Modified = {2012-11-05 17:22:36 +0000},
	Pages = {49},
	Title = {{CSMA/CD standard 802.3-2008}},
	Year = {2008}}

@inproceedings{Ryzhyk:2009:DTD:1519065.1519095,
	Acmid = {1519095},
	Address = {New York, NY, USA},
	Author = {Ryzhyk, Leonid and Chubb, Peter and Kuz, Ihor and Heiser, Gernot},
	Booktitle = {Proceedings of the 4th ACM European conference on Computer systems},
	Date-Added = {2012-11-05 16:09:36 +0000},
	Date-Modified = {2012-11-05 16:09:36 +0000},
	Doi = {10.1145/1519065.1519095},
	Isbn = {978-1-60558-482-9},
	Keywords = {concurrent programming, device drivers, domain-specific languages, fault avoidance, reliability},
	Location = {Nuremberg, Germany},
	Numpages = {14},
	Pages = {275--288},
	Publisher = {ACM},
	Series = {EuroSys '09},
	Title = {Dingo: taming device drivers},
	Url = {http://doi.acm.org/10.1145/1519065.1519095},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1519065.1519095},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1519065.1519095}}

@inproceedings{Ryzhyk:2011:IDD:1950365.1950383,
	Acmid = {1950383},
	Address = {New York, NY, USA},
	Author = {Ryzhyk, Leonid and Keys, John and Mirla, Balachandra and Raghunath, Arun and Vij, Mona and Heiser, Gernot},
	Booktitle = {Proceedings of the sixteenth international conference on Architectural support for programming languages and operating systems},
	Date-Added = {2012-11-05 16:08:48 +0000},
	Date-Modified = {2012-11-05 16:08:48 +0000},
	Doi = {10.1145/1950365.1950383},
	Isbn = {978-1-4503-0266-1},
	Keywords = {automated testing, co-verification, device drivers, reliability, rtl testbenches},
	Location = {Newport Beach, California, USA},
	Numpages = {12},
	Pages = {133--144},
	Publisher = {ACM},
	Series = {ASPLOS '11},
	Title = {Improved device driver reliability through hardware verification reuse},
	Url = {http://doi.acm.org/10.1145/1950365.1950383},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1950365.1950383},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1950365.1950383}}

@inproceedings{Renzelmann2012,
	Acmid = {2228302},
	Address = {Berkeley, CA, USA},
	Author = {Matthew J. Renzelmann, Asim Kadav, and Michael M. Swift,},
	Booktitle = {Proceedings of the 10th ACM SIGCOMM conference on Operating Systems Design and Implementation},
	Date-Added = {2012-11-05 16:04:23 +0000},
	Date-Modified = {2012-11-05 16:06:02 +0000},
	Location = {San Jose, CA},
	Numpages = {1},
	Pages = {3--3},
	Publisher = {USENIX Association},
	Series = {OSDI'12},
	Title = {SymDrive: Testing Drivers without Devices},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2228298.2228302}}

@inproceedings{Alizadeh:2010:DCT:851182.1851192,
	Acmid = {1851192},
	Address = {New York, NY, USA},
	Author = {Alizadeh, Mohammad and Greenberg, Albert and Maltz, David A. and Padhye, Jitendra and Patel, Parveen and Prabhakar, Balaji and Sengupta, Sudipta and Sridharan, Murari},
	Booktitle = {Proceedings of the ACM SIGCOMM 2010 conference},
	Date-Added = {2012-11-05 15:56:37 +0000},
	Date-Modified = {2012-11-05 15:56:47 +0000},
	Doi = {10.1145/1851182.1851192},
	Isbn = {978-1-4503-0201-2},
	Keywords = {ECN, TCP, data center network},
	Location = {New Delhi, India},
	Numpages = {12},
	Pages = {63--74},
	Publisher = {ACM},
	Series = {SIGCOMM '10},
	Title = {Data center TCP (DCTCP)},
	Url = {http://doi.acm.org/10.1145/1851182.1851192},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1851182.1851192},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1851182.1851192}}

@article{cornelldcread,
	Author = {Emin G{\"u}n Sirer},
	Date-Added = {2012-11-05 15:52:05 +0000},
	Date-Modified = {2012-11-05 15:54:31 +0000},
	Journal = {http://www.cs.cornell.edu/courses/cs6452/2012sp/lectures.php},
	Month = {June},
	Title = {Datacenter Networks and Services (Reading List)},
	Year = {2012}}

@article{uvnicmsnslides,
	Author = {Matthew P. Grosvenor},
	Date-Added = {2012-11-05 15:44:28 +0000},
	Date-Modified = {2012-11-05 15:45:08 +0000},
	Journal = {http://www.informatics.sussex.ac.uk/research/projects/ngn/slides/msn12talks/grosvenor-uvnic.pdf},
	Month = {July},
	Title = {uvNIC: Rapid Prototyping Network Devices},
	Year = {2012}}

@article{uvnicweb,
	Author = {Matthew P. Grosvenor},
	Date-Added = {2012-11-05 15:42:06 +0000},
	Date-Modified = {2012-11-05 15:45:48 +0000},
	Journal = {http://www.cl.cam.ac.uk/research/srg/netos/mrc/projects/uvNIC/},
	Month = {August},
	Title = {uvNIC: The Userspace Virtual Network Interface Controler},
	Year = {2012}}

@inproceedings{Grosvenor:2012:URP:42356.2342423,
	Acmid = {2342423},
	Address = {New York, NY, USA},
	Author = {Grosvenor, Matthew P.},
	Booktitle = {Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer communication},
	Date-Added = {2012-11-05 15:41:03 +0000},
	Date-Modified = {2012-11-05 15:45:33 +0000},
	Doi = {10.1145/2342356.2342423},
	Isbn = {978-1-4503-1419-0},
	Keywords = {device driver, emulation, hardware, userspace, virtualisation},
	Location = {Helsinki, Finland},
	Numpages = {2},
	Pages = {307--308},
	Publisher = {ACM},
	Series = {SIGCOMM '12},
	Title = {uvNIC: Rapid Prototyping Network Interface Controller Device Drivers},
	Url = {http://doi.acm.org/10.1145/2342356.2342423},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342423},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342423}}

@article{Nagle:1995:CCI:205447.205454,
	Acmid = {205454},
	Address = {New York, NY, USA},
	Author = {Nagle, John},
	Date-Added = {2012-11-05 15:30:23 +0000},
	Date-Modified = {2012-11-05 15:30:23 +0000},
	Doi = {10.1145/205447.205454},
	Issn = {0146-4833},
	Issue_Date = {Jan. 1995},
	Journal = {SIGCOMM Comput. Commun. Rev.},
	Month = jan,
	Number = {1},
	Numpages = {5},
	Pages = {61--65},
	Publisher = {ACM},
	Title = {Congestion control in IP/TCP internetworks},
	Url = {http://doi.acm.org/10.1145/205447.205454},
	Volume = {25},
	Year = {1995},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/205447.205454},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/205447.205454}}

@inproceedings{Barroso:2011:WCE:2000064.2019527,
	Acmid = {2019527},
	Address = {New York, NY, USA},
	Author = {Barroso, Luiz Andre},
	Booktitle = {Proceedings of the 38th annual international symposium on Computer architecture},
	Date-Added = {2012-11-05 15:27:08 +0000},
	Date-Modified = {2012-11-05 15:27:08 +0000},
	Isbn = {978-1-4503-0472-6},
	Location = {San Jose, California, USA},
	Pages = {--},
	Publisher = {ACM},
	Series = {ISCA '11},
	Title = {Warehouse-Scale Computing: Entering the Teenage Decade},
	Url = {http://dl.acm.org/citation.cfm?id=2000064.2019527},
	Year = {2011},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2000064.2019527}}

@inproceedings{Rumble:2011:TLL:1991596.1991611,
	Acmid = {1991611},
	Address = {Berkeley, CA, USA},
	Author = {Rumble, Stephen M. and Ongaro, Diego and Stutsman, Ryan and Rosenblum, Mendel and Ousterhout, John K.},
	Booktitle = {Proceedings of the 13th USENIX conference on Hot topics in operating systems},
	Date-Added = {2012-11-05 15:24:49 +0000},
	Date-Modified = {2012-11-05 15:24:49 +0000},
	Location = {Napa, California},
	Numpages = {1},
	Pages = {11--11},
	Publisher = {USENIX Association},
	Series = {HotOS'13},
	Title = {It's time for low latency},
	Url = {http://dl.acm.org/citation.cfm?id=1991596.1991611},
	Year = {2011},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1991596.1991611}}

@inproceedings{Zhou:2012:MMC:2342356.2342440,
	Acmid = {2342440},
	Address = {New York, NY, USA},
	Author = {Zhou, Xia and Zhang, Zengbin and Zhu, Yibo and Li, Yubo and Kumar, Saipriya and Vahdat, Amin and Zhao, Ben Y. and Zheng, Haitao},
	Booktitle = {Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer communication},
	Date-Added = {2012-11-05 15:22:00 +0000},
	Date-Modified = {2012-11-05 15:22:00 +0000},
	Doi = {10.1145/2342356.2342440},
	Isbn = {978-1-4503-1419-0},
	Keywords = {60 ghz wireless, data centers, wireless beamforming},
	Location = {Helsinki, Finland},
	Numpages = {12},
	Pages = {443--454},
	Publisher = {ACM},
	Series = {SIGCOMM '12},
	Title = {Mirror mirror on the ceiling: flexible wireless links for data centers},
	Url = {http://doi.acm.org/10.1145/2342356.2342440},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342440},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342440}}

@inproceedings{Halperin:2011:ADC:2018436.2018442,
	Acmid = {2018442},
	Address = {New York, NY, USA},
	Author = {Halperin, Daniel and Kandula, Srikanth and Padhye, Jitendra and Bahl, Paramvir and Wetherall, David},
	Booktitle = {Proceedings of the ACM SIGCOMM 2011 conference},
	Date-Added = {2012-11-05 15:20:28 +0000},
	Date-Modified = {2012-11-05 15:20:28 +0000},
	Doi = {10.1145/2018436.2018442},
	Isbn = {978-1-4503-0797-0},
	Keywords = {60 ghz, 802.11ad, data center, datacenter, flyways, network},
	Location = {Toronto, Ontario, Canada},
	Numpages = {12},
	Pages = {38--49},
	Publisher = {ACM},
	Series = {SIGCOMM '11},
	Title = {Augmenting data center networks with multi-gigabit wireless links},
	Url = {http://doi.acm.org/10.1145/2018436.2018442},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2018436.2018442},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2018436.2018442}}

@article{bufferbloat,
	Acmid = {2063196},
	Address = {New York, NY, USA},
	Author = {Gettys, Jim and Nichols, Kathleen},
	Date-Added = {2012-11-05 14:53:29 +0000},
	Date-Modified = {2013-01-27 13:38:18 +0000},
	Doi = {10.1145/2063176.2063196},
	Issn = {0001-0782},
	Issue_Date = {January 2012},
	Journal = {Commun. ACM},
	Month = jan,
	Number = {1},
	Numpages = {9},
	Pages = {57--65},
	Publisher = {ACM},
	Title = {Bufferbloat: dark buffers in the internet},
	Url = {http://doi.acm.org/10.1145/2063176.2063196},
	Volume = {55},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2063176.2063196},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2063176.2063196}}

//Jacobson, Van},
@article{Nichols:2012:CQD:2209249.2209264,
	Acmid = {2209264},
	Address = {New York, NY, USA},
	Author = {Nichols, Kathleen and others},
	Date-Added = {2012-11-05 14:51:50 +0000},
	Date-Modified = {2012-11-05 14:51:50 +0000},
	Doi = {10.1145/2209249.2209264},
	Issn = {0001-0782},
	Issue_Date = {July 2012},
	Journal = {Communications of the ACM},
	Month = jul,
	Number = {7},
	Numpages = {9},
	Pages = {42--50},
	Publisher = {ACM},
	Title = {Controlling queue delay},
	Url = {http://doi.acm.org/10.1145/2209249.2209264},
	Volume = {55},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2209249.2209264},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2209249.2209264}}

// Nichols, Kathleen},
@article{Gettys:2011:BDB:2063166.2071893,
	Acmid = {2071893},
	Address = {New York, NY, USA},
	Articleno = {40},
	Author = {Gettys, Jim and others},
	Date-Added = {2012-11-05 13:41:23 +0000},
	Date-Modified = {2012-11-05 13:41:23 +0000},
	Doi = {10.1145/2063166.2071893},
	Issn = {1542-7730},
	Issue_Date = {November 2011},
	Journal = {ACM Queue},
	Month = nov,
	Number = {11},
	Numpages = {15},
	Pages = {40:40--40:54},
	Title = {Bufferbloat: Dark Buffers in the Internet},
	Url = {http://doi.acm.org/10.1145/2063166.2071893},
	Volume = {9},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2063166.2071893},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2063166.2071893}}

@inbook{latstup96,
	Author = {Stuart Cheshire},
	Date-Added = {2012-11-05 13:37:37 +0000},
	Date-Modified = {2012-11-05 13:39:06 +0000},
	Publisher = {{http://rescomp.stanford.edu/~cheshire/rants/Latency.html}},
	Title = {{It's The Latency Stupid}},
	Year = {May 1996}}

@electronic{netmapweb,
	Author = {Luigi Rizzo},
	Date-Added = {2012-11-05 13:31:42 +0000},
	Date-Modified = {2012-11-05 13:32:36 +0000},
	Month = {November},
	Title = {{Netmap - A Novel Framework for Fast Packet I/O}},
	Url = {http://info.iet.unipi.it/~luigi/netmap/},
	Year = {2012},
	Bdsk-Url-1 = {http://info.iet.unipi.it/~luigi/netmap/}}

@electronic{openonloadweb,
	Author = {{Solarflare Communications Inc}},
	Date-Added = {2012-11-05 13:28:55 +0000},
	Date-Modified = {2012-11-05 13:34:51 +0000},
	Lastchecked = {November 2012},
	Month = {November},
	Title = {www.openonload.org},
	Url = {http://www.openonload.org/},
	Year = {2012},
	Bdsk-Url-1 = {http://www.openonload.org/}}

@webpage{chelsiot420,
	Author = {{Chelsio Communications Inc.}},
	Date-Added = {2012-11-05 13:17:03 +0000},
	Date-Modified = {2012-11-05 13:22:50 +0000},
	Keywords = {HFT NIC},
	Month = {November},
	Title = {{Technical Brief, Chelsio T420 low latency server connectivity}},
	Url = {http://chelsio.com/assetlibrary/pdf/CHL_11Q1_FIN_SB-02%20%285%29.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://chelsio.com/assetlibrary/pdf/CHL_11Q1_FIN_SB-02%20%285%29.pdf}}

@electronic{myricom8c2,
	Author = {{Myricom Inc}},
	Date-Added = {2012-11-05 13:12:41 +0000},
	Date-Modified = {2012-11-05 13:16:02 +0000},
	Keywords = {hft nic},
	Month = {November},
	Title = {{Product Brief, 10G-PCIE2-8C2-2S Two-Port 10-Gigabit Ethernet Network Adapters Optimized for Financial Trading }},
	Url = {https://www.myricom.com/images/stories/10G-PCIE2-8C2-2S.pdf},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RElpOUy5vYmplY3RzViRjbGFzc1dOUy5rZXlzog8QgASABoAHohMUgAKAA1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgMGRpXTlMuZGF0YU8RAbwAAAAAAbwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMo8fxNIKwAAAAXNFBQxMEctUENJRTItOEMyLTJTLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADtgS5zL1rugAAAAAAAAAAAAIABAAACSAAAAAAAAAAAAAAAAAAAAAHUmVhZGluZwAAEAAIAADKPHEDAAAAEQAIAADMvWu6AAAAAQAUAAXNFAA6vWoAG4N0AAXGbAAAvzEAAgBLTWFjaW50b3NoIEhEOlVzZXJzOgBtZ3Jvc3Zlbm9yOgBEcm9wYm94OgBQSEQ6AFJlYWRpbmc6ADEwRy1QQ0lFMi04QzItMlMucGRmAAAOACoAFAAxADAARwAtAFAAQwBJAEUAMgAtADgAQwAyAC0AMgBTAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA5VXNlcnMvbWdyb3N2ZW5vci9Ecm9wYm94L1BIRC9SZWFkaW5nLzEwRy1QQ0lFMi04QzItMlMucGRmAAATAAEvAAAVAAIAEf//AACABdIcHR4fWCRjbGFzc2VzWiRjbGFzc25hbWWjHyAhXU5TTXV0YWJsZURhdGFWTlNEYXRhWE5TT2JqZWN0XxAuLi4vLi4vRHJvcGJveC9QSEQvUmVhZGluZy8xMEctUENJRTItOEMyLTJTLnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZABsAG8AcQBzAHUAeAB6AHwAhgCTAJgAoAJgAmICZwJwAnsCfwKNApQCnQLOAtMC1gLjAugAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC+g==}}

@webpage{melanox3en,
	Author = {{Melanox Technologies}},
	Date-Added = {2012-11-05 12:59:26 +0000},
	Date-Modified = {2012-11-05 13:09:01 +0000},
	Month = {November},
	Title = {{Product Brief, ConnectX -3 EN}},
	Url = {http://www.mellanox.com/related-docs/prod_adapter_cards/ConnectX3_EN_Card.pdf},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RElpOUy5vYmplY3RzViRjbGFzc1dOUy5rZXlzog8QgASABoAHohMUgAKAA1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgMGRpXTlMuZGF0YU8RAb4AAAAAAb4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMo8fxNIKwAAAAXNFBVDb25uZWN0WDNfRU5fQ2FyZC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADtf61zL1odwAAAAAAAAAAAAIABAAACSAAAAAAAAAAAAAAAAAAAAAHUmVhZGluZwAAEAAIAADKPHEDAAAAEQAIAADMvWh3AAAAAQAUAAXNFAA6vWoAG4N0AAXGbAAAvzEAAgBMTWFjaW50b3NoIEhEOlVzZXJzOgBtZ3Jvc3Zlbm9yOgBEcm9wYm94OgBQSEQ6AFJlYWRpbmc6AENvbm5lY3RYM19FTl9DYXJkLnBkZgAOACwAFQBDAG8AbgBuAGUAYwB0AFgAMwBfAEUATgBfAEMAYQByAGQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADpVc2Vycy9tZ3Jvc3Zlbm9yL0Ryb3Bib3gvUEhEL1JlYWRpbmcvQ29ubmVjdFgzX0VOX0NhcmQucGRmABMAAS8AABUAAgAR//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEC8uLi8uLi9Ecm9wYm94L1BIRC9SZWFkaW5nL0Nvbm5lY3RYM19FTl9DYXJkLnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZABsAG8AcQBzAHUAeAB6AHwAhgCTAJgAoAJiAmQCaQJyAn0CgQKPApYCnwLRAtYC2QLmAusAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC/Q==}}

@electronic{ciscohft,
	Author = {{Cisco Corporation}},
	Date-Added = {2012-11-05 12:48:07 +0000},
	Date-Modified = {2012-11-05 12:50:29 +0000},
	Keywords = {hft switch cisco},
	Month = {November},
	Title = {{Algo Speed High-Frequency Trading Solution}},
	Url = {http://www.cisco.com/web/strategy/docs/finance/c22-658397-01_sOview.pdf},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RElpOUy5vYmplY3RzViRjbGFzc1dOUy5rZXlzog8QgASABoAHohMUgAKAA1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgMGRpXTlMuZGF0YU8RAcwAAAAAAcwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMo8fxNIKwAAAAXNFBhjMjItNjU4Mzk3LTAxX3NPdmlldy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADtfBQzL1mCwAAAAAAAAAAAAIABAAACSAAAAAAAAAAAAAAAAAAAAAHUmVhZGluZwAAEAAIAADKPHEDAAAAEQAIAADMvWYLAAAAAQAUAAXNFAA6vWoAG4N0AAXGbAAAvzEAAgBPTWFjaW50b3NoIEhEOlVzZXJzOgBtZ3Jvc3Zlbm9yOgBEcm9wYm94OgBQSEQ6AFJlYWRpbmc6AGMyMi02NTgzOTctMDFfc092aWV3LnBkZgAADgAyABgAYwAyADIALQA2ADUAOAAzADkANwAtADAAMQBfAHMATwB2AGkAZQB3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgA9VXNlcnMvbWdyb3N2ZW5vci9Ecm9wYm94L1BIRC9SZWFkaW5nL2MyMi02NTgzOTctMDFfc092aWV3LnBkZgAAEwABLwAAFQACABH//wAAgAXSHB0eH1gkY2xhc3Nlc1okY2xhc3NuYW1lox8gIV1OU011dGFibGVEYXRhVk5TRGF0YVhOU09iamVjdF8QMi4uLy4uL0Ryb3Bib3gvUEhEL1JlYWRpbmcvYzIyLTY1ODM5Ny0wMV9zT3ZpZXcucGRm0hwdJCWiJSFcTlNEaWN0aW9uYXJ5EgABhqBfEA9OU0tleWVkQXJjaGl2ZXIACAARABYAHwAoADIANQA6ADwARQBLAFIAXQBkAGwAbwBxAHMAdQB4AHoAfACGAJMAmACgAnACcgJ3AoACiwKPAp0CpAKtAuIC5wLqAvcC/AAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAMO}}

@misc{zeptomux,
	Author = {{Zeptonics Pty Ltd}},
	Date-Added = {2012-11-05 12:35:34 +0000},
	Date-Modified = {2012-11-05 12:51:47 +0000},
	Keywords = {hft switch trading},
	Month = {November},
	Publisher = {Zeptonics Pty Ltd},
	Title = {{Overview, ZeptoMux 10GbE Multiplexing Switch}},
	Url = {http://www.zeptonics.com/network-devices/zeptomux-overview.pdf},
	note = {\url{http://bit.ly/WppK8j}; accessed 18/01/2013.},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RElpOUy5vYmplY3RzViRjbGFzc1dOUy5rZXlzog8QgASABoAHohMUgAKAA1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgMGRpXTlMuZGF0YU8RAb4AAAAAAb4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMo8fxNIKwAAAAXNFBV6ZXB0b211eC1vdmVydmlldy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADteWbzL1jZwAAAAAAAAAAAAIABAAACSAAAAAAAAAAAAAAAAAAAAAHUmVhZGluZwAAEAAIAADKPHEDAAAAEQAIAADMvWNnAAAAAQAUAAXNFAA6vWoAG4N0AAXGbAAAvzEAAgBMTWFjaW50b3NoIEhEOlVzZXJzOgBtZ3Jvc3Zlbm9yOgBEcm9wYm94OgBQSEQ6AFJlYWRpbmc6AHplcHRvbXV4LW92ZXJ2aWV3LnBkZgAOACwAFQB6AGUAcAB0AG8AbQB1AHgALQBvAHYAZQByAHYAaQBlAHcALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADpVc2Vycy9tZ3Jvc3Zlbm9yL0Ryb3Bib3gvUEhEL1JlYWRpbmcvemVwdG9tdXgtb3ZlcnZpZXcucGRmABMAAS8AABUAAgAR//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEC8uLi8uLi9Ecm9wYm94L1BIRC9SZWFkaW5nL3plcHRvbXV4LW92ZXJ2aWV3LnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZABsAG8AcQBzAHUAeAB6AHwAhgCTAJgAoAJiAmQCaQJyAn0CgQKPApYCnwLRAtYC2QLmAusAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC/Q==}}

@electronic{arista2012,
	Author = {{Arista Networks}},
	Date-Added = {2012-11-02 17:36:00 +0000},
	Date-Modified = {2012-11-05 12:46:57 +0000},
	Institution = {Arista Networks},
	Keywords = {Arsita Switch Low-Latency HFT HPC},
	Lastchecked = {2 November 2012},
	Month = {November},
	Title = {{Product Description: 7150 Series 1/10 GbE SFP Ultra Low Latency Switch}},
	Url = {http://www.aristanetworks.com/media/system/pdf/Datasheets/7150S_Datasheet.pdf},
	Year = {2012},
	Bdsk-Url-1 = {http://www.aristanetworks.com/media/system/pdf/Datasheets/7150S_Datasheet.pdf}}

@article{Hall1997,
	Author = {Hall, James and Sabatino, Roberto and Crosby, Simon and Leslie, Ian},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Hall et al. - Unknown - Counting the Cycles a Comparative Study of NFS Performance over High Speed Networks.pdf:pdf},
	Journal = {IN PROCEEDINGS OF THE 22ND ANNUAL CONFERENCE ON LOCAL COMPUTER NETWORKS (LCN'97) (MINNEAPOLIS, MN},
	Pages = {8 -- 19},
	Title = {{Counting the Cycles: a Comparative Study of NFS Performance over High Speed Networks}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3373B9B7B3EEEE7E99796989DB1206A3?doi=10.1.1.47.1066},
	Volume = {22},
	Year = {1997},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary;jsessionid=3373B9B7B3EEEE7E99796989DB1206A3?doi=10.1.1.47.1066}}

@article{Ye,
	Author = {Ye, Shunyuan and Shen, Yanming and Panwar, Shivendra},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Ye, Shen, Panwar - Unknown - Distributed Scheduling Algorithms for High-Speed Switching Systems.pdf:pdf},
	Title = {{Distributed Scheduling Algorithms for High-Speed Switching Systems}}}

@unpublished{Solarflare2010,
	Abstract = {The drive towards low latency trading systems, and market data delivery in particular, means IT professionals on Wall Street are constantly on the lookout for innovative new techniques and technologies. The picture goes well beyond just raw speed, however, as market participants understand that consistency and predictability are just as important. With more trading decisions and order execution processes being automated, it is critical to make sure information flows quickly and consistently through the front, mid and back office. One of the biggest shifts companies are embracing to ensure this consistently low latency is the move to purpose-built hardware. They're using network interface cards (NICs) that have been purpose-built for performance, and they are discovering that middleware appliances can distribute data with greater performance and predictability than software-based solutions. The fact that hardware-based solutions also reduce complexity and TCO is icing on the cake. This paper describes how a system based on message routers from Solace Systems, 10 GigE adapters from Solarflare Communications and 10GigE switches from Arista Networks can deliver lower and more consistent latency than software-based solutions. To document the capabilities of such a system, the companies conducted tests that measured latency at rates as high as 5 million messages per second. This paper provides average and 99.9th percentile figures at a variety of rates. In all tests the platform demonstrated latency that was both low and consistent. When routing 1,000,000 messages per second the platform exhibited average latency of 24 microseconds and 99.9th percentile latency of 27 microseconds. At five times that volume, rates that represent substantial performance headroom for most firms, latency was still low with minimal jitter: average latency was 35 microseconds and 99.9th percentile latency was 46.},
	Author = {Solarflare},
	Booktitle = {Solarflare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/solace-solarflare-arista.pdf:pdf},
	Pages = {4},
	Title = {{Solace , Solarflare and Arista Demonstrate Market Data Distribution with Low , Consistent Latency}},
	Year = {2010}}

@article{Kapasi2002,
	Author = {Kapasi, U.J. and Dally, W.J. and Rixner, S. and Owens, J.D. and Khailany, B.},
	Doi = {10.1109/ICCD.2002.1106783},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/kapasi\_iccd2002\_arch.pdf:pdf},
	Isbn = {0-7695-1700-5},
	Journal = {Proceedings. IEEE International Conference on Computer Design: VLSI in Computers and Processors},
	Pages = {282--288},
	Publisher = {IEEE Comput. Soc},
	Title = {{The Imagine Stream Processor}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1106783},
	Year = {2002},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1106783},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/ICCD.2002.1106783}}

@article{Abadi2003,
	Abstract = {This paper describes the basic processing model and architecture of Aurora, a new system to manage data streams for monitoring applications. Monitoring applications differ substantially from conventional business data process- ing. The fact that a software system must process and react to continual inputs from many sources (e.g., sensors) rather than from human operators requires one to rethink the fundamen- tal architecture of a DBMS for this application area. In this paper, we present Aurora, a new DBMS currently under con- struction at Brandeis University, BrownUniversity, and M.I.T. We first provide an overview of the basic Aurora model and architecture and then describe in detail a stream-oriented set of operators.},
	Author = {Abadi, D.J. and Carney, Don and \c{C}etintemel, U. and Cherniack, Mitch and Convey, Christian and Lee, Sangdon and Stonebraker, Michael and Tatbul, Nesime and Zdonik, Stan},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/30120120.pdf:pdf},
	Journal = {The VLDB Journal},
	Keywords = {continuous queries,data stream management,database triggers,quality-of-service,real-time systems},
	Number = {2},
	Pages = {120--139},
	Publisher = {Springer},
	Title = {{Aurora: a new model and architecture for data stream management}},
	Url = {http://www.springerlink.com/index/PJCE12GUQE5Q6YME.pdf},
	Volume = {12},
	Year = {2003},
	Bdsk-Url-1 = {http://www.springerlink.com/index/PJCE12GUQE5Q6YME.pdf}}

@unpublished{Transmode,
	Author = {Transmode},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Transmode - Unknown - Low Latency -- How low can you go(2).pdf:pdf},
	Title = {{Low Latency -- How low can you go ?}}}

@article{Bittau,
	Author = {Bittau, Andrea and Karp, Brad},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/wedge.pdf:pdf},
	Title = {{Wedge : Splitting Applications into Reduced-Privilege Compartments}}}

@unpublished{Financial2011,
	Author = {Financial, Impulse and Handler, Feed},
	Booktitle = {Computing},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Financial, Handler - 2011 - Press Release Press Release(2).pdf:pdf},
	Number = {January},
	Pages = {351006--351007},
	Title = {{Press Release Press Release}},
	Year = {2011}}

@article{Moorthy1999,
	Abstract = {Clusters ofworkstations have emerged as a popular plat- form for parallel and distributed computing. Commodity high speed networks which are used to connect worksta- tion clusters provide high bandwidth, but also have high latency. SCRAMNet is an extremely low latency replicated non-coherent shared memory network, so far used only for real-time applications. This paper reports our early expe- riences with using SCRAMNet for cluster computing. We have implemented a user-level zero-copy message pass- ing protocol for SCRAMNet called the BillBoard Protocol (BBP). The one way latency for sending a 4-byte message between two nodes using the BBP is measured to be as low as 7.8  s. Since SCRAMNet supports hardware level repli- cation of messages, it is possible to implement multicast with almost the same latency as point-to-point communi- cation. Using the BBP, the latency for broadcasting short messages to 4 nodes is measured to be 10.1 tency for a 4-node barrier ismeasured to be 37  s and the la- s. We have  also built anMPI library on top of the BBP whichmakes use of multicast support from the BBP. Our results demonstrate the potential of SCRAMNet as a high performance intercon- nect for building scalable workstation clusters supporting message passing.},
	Author = {Moorthy, Vijay and Jacunski, MG and Pillai, Manoj},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Moorthy et al. - Unknown - Low-Latency Message Passing on Workstation Clusters using SCRAMNet ½ ¾(2).pdf:pdf},
	Journal = {13th International and 10th Symposium on Parallel and Distributed Processing, 1999. 1999 IPPS/SPDP. Proceedings},
	Title = {{Low-latency message passing on workstation clusters using SCRAMNet}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=760450},
	Year = {1999},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=760450}}

@unpublished{Voltarie,
	Author = {Voltarie},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Voltaire, Accelerator - Unknown - Voltaire Lowest Latency Ethernet Solution for Financial Services(2).pdf:pdf},
	Title = {{Voltaire Lowest Latency Ethernet Solution for Financial Services}}}

@article{Shyamasundar2002,
	Abstract = {In this paper; we develop a messaging infrastructure; called LLM; to arrive at a robust and efficient low latency message passing infrastructure for kernel-to-kernel communication. The main focus is to overcome the high latencies associated with the conventional communication protocol stack management of TCP/IP. The LLM provides a transport protocol that offers high reliability at the fragment level keeping the acknowledgment overhead low given the high reliability levels of the LAN. The system utilizes some of the architectural facilities provided by the Linux kernel specially designed for optimization in the respective areas. Reliability against fragment losses is ensured by using a low overhead negative acknowledgment scheme. The implementation is in the form of loadable modules extending the Linux OS. In a typical implementation on a cluster of two nodes; each of uniprocessor Intel Pentium 400 MHz on a 10/100 Mbps LAN achieved an average round trip latency of .169ms as compared to the .531ms obtained by ICMP (Ping) protocol. A relative comparison of LLM with others is also provided.},
	Annote = {
        From Duplicate 1 ( 
        
        
          LLM: A low latency messaging infrastructure for Linux clusters
        
        
         - Shyamasundar, R; Rajan, B; Prasad, M )

        
        

        From Duplicate 1 ( 
        
        
          LLM: A low latency messaging infrastructure for Linux clusters
        
        
         - Shyamasundar, R; Rajan, B; Prasad, M )

        
        

        

        

        

        

        From Duplicate 2 ( 
        
        
          LLM: A low latency messaging infrastructure for Linux clusters
        
        
         - Shyamasundar, R; Rajan, B; Prasad, M )

        
        

        

        

      },
	Author = {Shyamasundar, R and Rajan, B and Prasad, M},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Manager, Messaging, Detector - Unknown - No Title(2).pdf:pdf},
	Journal = {HiPC '02 Proceedings of the 9th International Conference on High Performance Computing},
	Number = {11},
	Pages = {1829--1841},
	Publisher = {Wiley Online Library},
	Title = {{LLM: A low latency messaging infrastructure for Linux clusters}},
	Url = {http://onlinelibrary.wiley.com/doi/10.1002/cbdv.200490137/abstract http://www.springerlink.com/index/76Q0RUW2JHGY5QPQ.pdf},
	Volume = {1},
	Year = {2002},
	Bdsk-Url-1 = {http://onlinelibrary.wiley.com/doi/10.1002/cbdv.200490137/abstract%20http://www.springerlink.com/index/76Q0RUW2JHGY5QPQ.pdf}}

@article{Beheshti2008,
	Author = {Beheshti, Neda and Ganjali, Yashar and Goel, Ashish and McKeown, Nick},
	Doi = {10.1109/IWQOS.2008.13},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/buff-network.pdf:pdf},
	Isbn = {978-1-4244-2084-1},
	Issn = {1548-615X},
	Journal = {2008 16th Interntional Workshop on Quality of Service},
	Month = jun,
	Pages = {65--69},
	Publisher = {Ieee},
	Title = {{Obtaining High Throughput in Networks with Tiny Buffers}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4539669},
	Year = {2008},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4539669},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/IWQOS.2008.13}}

@misc{HyperTransportConsortium2008,
	Abstract = {For system and subsystem manufacturers, delivering low-latency high- performance computing solutions at affordable prices has been an insurmountable barrier. Although processor speeds and bandwidth have taken quantum leaps over the last decade, the last few inches between the adapter slot and system CPU create a bottleneck that restricts the development of cost-effective high-performance computing solutions. For complex modeling, high-end transactional systems, commercial data centers and large system clusters, high latency or {"}wait time{"} is a stumbling block that is holding back the development of systems with supercomputer-level performance using off-the-shelf components. Fortunately, a new expansion interconnect brings ultra-low latency and high performance to an expansion slot, enabling direct communication between the system CPU and high performance subsystems. HTXTM, an expansion connector specification that leverages industry-standard HyperTransportTM technology, overcomes the latency barrier common with standard systems. This white paper will address some of the challenges related to developing low-cost high-performance computing solutions and introduce the advantages of HTX.},
	Annote = {
        From Duplicate 2 ( 
        
          The future of High-Performance Computing: Direct Low Latency CPU-to-Subsystem Interconnect
        
         - Hyper Transport Consortium; others )

        
        

        

        

      },
	Author = {{Hyper Transport Consortium} and Others},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Drivers - 2004 - The Future of High-Performance Computing Direct Low Latency CPU-to-Subsystem Interconnect.pdf:pdf},
	Number = {October},
	Pages = {1--11},
	Publisher = {Whitepaper},
	Title = {{The future of High-Performance Computing: Direct Low Latency CPU-to-Subsystem Interconnect}},
	Url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Future+of+High-Performance+Computing+:+Direct+Low+Latency+CPU-to-Subsystem+Interconnect\#0},
	Year = {2008},
	Bdsk-Url-1 = {http://scholar.google.com/scholar?hl=en%5C&btnG=Search%5C&q=intitle:The+Future+of+High-Performance+Computing+:+Direct+Low+Latency+CPU-to-Subsystem+Interconnect%5C#0}}

@article{Patterson2004,
	Author = {Patterson, David a.},
	Doi = {10.1145/1022594.1022596},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p71-patterson.pdf:pdf},
	Issn = {00010782},
	Journal = {Communications of the ACM},
	Month = oct,
	Number = {10},
	Pages = {71--75},
	Title = {{Latency lags bandwith}},
	Url = {http://portal.acm.org/citation.cfm?doid=1022594.1022596},
	Volume = {47},
	Year = {2004},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1022594.1022596},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1022594.1022596}}

@webpage{solarsfn5322f,
	Abstract = {Solarflare{\textregistered} SFN5322F dual-port enterprise SFP+ server adapter combines precision time synchronization with ultra-low latency 10G Ethernet, both accelerating time synchronization and providing the industry's best application performance on a single data network and in a single PCIe slot. The SFN5322F delivers unmatched scalable performance for data centers and the industry's lowest power consumption for additional cost savings.},
	Author = {{Solarflare Communications Inc}},
	Booktitle = {Solarflare},
	Date-Modified = {2012-11-05 13:34:20 +0000},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_SFN5322F\_10GbE\_Adapter\_Brief.pdf:pdf},
	Lastchecked = {November},
	Month = {November},
	Pages = {2},
	Title = {{Product Brief, Dual-Port 10GbE Precision Time Synchronization Server Adapter SFN5322F}},
	Year = {2012}}

@techreport{Armbrust2009,
	Abstract = {Provided certain obstacles are overcome, we believe Cloud Computing has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new interactive Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about over-provisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or under-provisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get their results as quickly as their programs can scale, since using 1000 servers for one hour costs no more than using one server for 1000 hours. This elasticity of resources, without paying a premium for large scale, is unprecedented in the history of IT. The economies of scale of very large-scale datacenters combined with ``pay-as-you-go'' resource usage has heralded the rise of Cloud Computing. It is now attractive to deploy an innovative new Internet service on a third party's Internet Datacenter rather than your own infrastructure, and to gracefully scale its resources as it grows or declines in popularity and revenue. Expanding and shrinking daily in response to normal diurnal patterns could lower costs even further. Cloud Computing transfers the risks of over-provisioning or under-provisioning to the Cloud Computing provider, who mitigates that risk by statistical multiplexing over a much larger set of users and who offers relatively low prices due better utilization and from the economy of purchasing at a larger scale. We define terms, present an economic model that quantifies the key buy vs. pay-as-you-go decision, offer a spectrum to classify Cloud Computing providers, and give our view of the top 10 obstacles and opportunities to the growth of Cloud Computing.},
	Author = {Armbrust, Michael and Joseph, Anthony D and Katz, Randy H and Patterson, David A},
	Doi = {10.1145/1721654.1721672},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Armbrust et al. - 2009 - Above the Clouds A Berkeley View of Cloud Computing.pdf:pdf},
	Institution = {EECS Department, University of California, Berkeley},
	Issn = {00010782},
	Number = {UCB/EECS-2009-28},
	Pages = {07--013},
	Publisher = {Citeseer},
	Series = {UCB/EECS-2009-28},
	Title = {{Above the Clouds : A Berkeley View of Cloud Computing}},
	Url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.7163\&amp;rep=rep1\&amp;type=pdf},
	Volume = {53},
	Year = {2009},
	Bdsk-Url-1 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.149.7163%5C&amp;rep=rep1%5C&amp;type=pdf},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1721654.1721672}}

@inproceedings{Wray2010,
	Abstract = {This paper describes an algorithmic trading en- gine based on reconfigurable hardware, derived from a soft- ware implementation. Our approach exploits parallelism and reconfigurability of field-programmable gate array (FPGA) technology. FPGAs offer many benefits over software solutions, including a reduction in latency, while increasing overall throughput and computational density. All of which are im- portant attributes to a successful algorithmic trading engine. Experiments show that the peak performance of our hardware architecture for algorithmic trading is 133 times faster than the corresponding software implementation. Six implementations can operate simultaneously on a Xilinx Vertex 5 xc5vlx30 FPGA on average, maximising performance and available resource usage.},
	Annote = {
        From Duplicate 1 ( 
        
        
          Exploring algorithmic trading in reconfigurable hardware
        
        
         - Wray, Stephen; Luk, Wayne; Pietzuch, Peter )

        
        

        

        

      },
	Author = {Wray, Stephen and Luk, Wayne and Pietzuch, Peter},
	Booktitle = {Application-specific Systems Architectures and Processors (ASAP), 2010 21st IEEE International Conference on},
	Date-Modified = {2012-11-02 12:49:38 +0000},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Wray, Luk, Pietzuch - 2010 - Exploring Algorithmic Trading in Reconfigurable Hardware(2).pdf:pdf},
	Isbn = {9781424469673},
	Keywords = {algorithmic trading,reconfigurable hardware},
	Pages = {325--328},
	Publisher = {IEEE},
	Title = {{Exploring algorithmic trading in reconfigurable hardware}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5540966},
	Year = {2010},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=5540966}}

@article{Networking,
	Author = {Networking, High-speed},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/TILE-Gx 8000 Series Brief\_0.pdf:pdf},
	Journal = {Development},
	Title = {{TILE-Gx {\texttrademark} 8000 Series Processor TILE-Gx {\texttrademark} 8000 Series Processor}}}

@unpublished{Melanox2012,
	Abstract = {ConnectX-2 EN Ethernet Network Interface Cards (NIC) deliver high- bandwidth and industry-leading 10GigE connectivity with stateless offloads for converged fabrics in High-Performance Computing, Enterprise Data Centers, and Embedded environments.},
	Author = {Melanox},
	Booktitle = {Melanox},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/ConnectX-2\_EN\_Cards.pdf:pdf},
	Number = {Vm},
	Pages = {2},
	Title = {{ConnectX-2 EN Ethernet Network Interface Cards}},
	Year = {2012}}

@article{Eicken1995,
	Author = {Eicken, Thorsten Von and Basu, Anindya and Buch, Vineet},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/sosp.pdf:pdf},
	Journal = {ACM SIGOPS Operating},
	Title = {{U-Net: a user-level network interface for parallel and distributed computing (includes URL)}},
	Url = {http://dl.acm.org/citation.cfm?id=224061},
	Year = {1995},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=224061}}

@article{Partridge1993,
	Author = {Partridge, Craig and Pink, Stephen},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p429-partridge.pdf:pdf},
	Journal = {IEEE/ACM Transactions on Networking (TON)},
	Number = {4},
	Pages = {429--440},
	Title = {{A faster udp}},
	Url = {http://dl.acm.org/citation.cfm?id=169943},
	Volume = {1},
	Year = {1993},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=169943}}

@inproceedings{Riddoch2001,
	Abstract = {Recent user-level network interfaces have placed an increasing proportion of their functionality in hardware, in order to provide an efficient user-level interface. The performance of such systems is signif- icantly better than that of traditional network archi- tectures, but comes at a cost; namely increasing com- plexity of the hardware, reduced flexibility and limited scalability. In this paper we present a technique that reduces the overhead of the application/device-driver inter- face, hence shifting the tradeoff towards a soft im- plementation. We show how this technique is used to improve the performance of the CLAN user-level network interface. Results given show that the per- formance of this interface exceeds that of other tech- nologies that provide a direct user-level interface to the hardware, whilst retaining the flexibility and sim- plicity of a software interface.},
	Author = {Riddoch, D and Pope, S.},
	Booktitle = {International Conference on Parallel and Distributed Processing Techniques and Applications},
	Date-Modified = {2012-11-02 12:55:43 +0000},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Riddoch - Unknown - A Low Overhead Application Device-driver Interface for User-level Networking.pdf:pdf},
	Keywords = {asyn-,device-driver,networking,user-level},
	Rating = {0},
	Read = {0},
	Title = {{A Low Overhead Application/Device-driver Interface for User-level Networking}},
	Url = {http://www.cl.cam.ac.uk/research/dtg/publications/public/djr23/pdpta2001\_riddoch.pdf},
	Year = {2001},
	Bdsk-Url-1 = {http://www.cl.cam.ac.uk/research/dtg/publications/public/djr23/pdpta2001%5C_riddoch.pdf}}

@article{Yea,
	Author = {Ye, Shunyuan and Shen, Yanming and Panwar, Shivendra},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Ye, Shen, Panwar - Unknown - Distributed Scheduling Algorithms for High-Speed Switching Systems.pdf:pdf},
	Title = {{Distributed Scheduling Algorithms for High-Speed Switching Systems}}}

@inproceedings{Obraczka2000,
	Author = {Obraczka, K and Silva, F},
	Booktitle = {Proc IEEE Globecom 2000},
	Title = {{Network Latency Metrics for Server Proximity}},
	Year = {2000}}

@unpublished{Netronome2009,
	Abstract = {Network traffic in both enterprise and carrier networks continues to rise, driving the bandwidth requirements and line rates to 10Gbps today, and expecting to grow to 40Gbps and beyond in a few years. With the need for application awareness, content inspection, and security processing, the amount of processing power within the network infrastructure at these ever- increasing line rates grows exponentially. To enable service providers and network equipment vendors to meet the high-performance challenge, a new multi- chip, multi-core heterogeneous processor architecture is required. In this architecture, a Network Flow multi-core Processor (NFP), optimized for L2-L7 processing, works in conjunction with one or more general- purpose multi-core CPUs. Designs based on this architecture will allow equipment providers to deliver high-performance, flexible and field-programmable systems that enable service providers to generate more revenue per user over a longer product life cycle. This paper discusses this new class of flow-processing architecture and its role in the new heterogeneous multi-processing architecture. },
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/The Evolution to Network Flow Processing (5-09).pdf:pdf},
	Pages = {7},
	Title = {{The Evolution to Network Flow Processing}},
	Year = {2009}}

@article{Mckeown1997,
	Author = {Mckeown, Nick and Izzard, Martin and Ellersick, William and Horowitz, Mark},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/00566194.pdf:pdf},
	Title = {{T INY T ERA : A P ACKET S WITCH C ORE}},
	Year = {1997}}

@inproceedings{Ravindran2005,
	Abstract = {To realize high performance, embedded applications are deploy ed on mu ltiprocessor platforms tailored for an appli- cation domain. H ow ev er, w hen a su itable platform is not av ailable, only few application niches can ju stify the in- creasing costs of an IC produ ct design. An alternativ e is to design the mu ltiprocessor on an F P G A. This retains the programmability adv antage, w hile obv iating the risk s in pro- du cing silicon. This also opens F P G As to the w orld of soft- w are designers. In this paper, w e demonstrate the feasibility of F P G A-based mu ltiprocessors for high performance ap- plications. W e deploy IP v 4 pack et forw arding on a mu l- tiprocessor on the X ilinx V irtex -II P ro F P G A. The design achievesa1.8 G bpsthroughputandlosesonly 2.6X inper- formance (normalized to area) compared to an implemen- tation on the Intel IX P -2 8 0 0 netw ork processor. W e also dev elop a design space ex ploration framew ork u sing I nteger L inear P rogramming to ex plore mu ltiprocessor confi gu ra- tions for an application. U sing this framew ork , w e achiev e a more effi cient mu ltiprocessor design su rpassing the perfor- mance of ou r hand-tu ned solu tion for pack et forw arding.},
	Author = {Ravindran, K. and Satish, N. and Jin, Y. and Keutzer, K.},
	Booktitle = {Field Programmable Logic and Applications, 2005. International Conference on},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/01515769.pdf:pdf},
	Isbn = {0780393627},
	Pages = {487--492},
	Publisher = {IEEE},
	Title = {{An FPGA-based soft multiprocessor system for IPv4 packet forwarding}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1515769},
	Year = {2005},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=1515769}}

@article{Hall1998,
	Abstract = {In the management of a modern LAN or campus network, two assues are of key amportance, namely network performance and capacaty plannang. In thas paper we report on results from an experamental programme whach aams to quantafy the performance that can be achaeved wath a real distrabuted applacataon runnzng over a range of dafferent network technologaes, ancludang Ethernet, ATM, FDDI, and a 100 Mb/s packet-swatched LAN. In partacu- lar we analyse the contrabutaon of each of the varaous applacataon and network components to the overall performance experaenced by applacataons},
	Author = {Hall, J and Sabatino, R and Crosby, S},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/00665100.pdf:pdf;:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Hall, Sabatino, Crosby - 1998 - A Comparative Study of High Speed Networks.pdf:pdf},
	Journal = {INFOCOM '98. Seventeenth Annual Joint Conference of the IEEE Computer and Communications Societies.},
	Title = {{A Comparative Study of High Speed Networks}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=665100},
	Year = {1998},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=665100}}

@article{Lu2012,
	Author = {Lu, Guohan},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p31.pdf:pdf},
	Isbn = {9781450314770},
	Keywords = {challenging to support this,commodity switch,fine-grained,ip 5-tuple flows,large for-,such limi-,tation makes it very,tcam entries to match,tcp,traffic co-processing unit},
	Pages = {31--36},
	Title = {{Using CPU as a Traffic Co-processing Unit in Commodity Switches}},
	Year = {2012}}

@article{Pottathuparambil2011,
	Annote = {        From Duplicate 1 (                   Low-Latency FPGA Based Financial Data Feed Handler                 - Pottathuparambil, Robin; Coyne, Jack; Allred, Jeffrey; Lynch, William; Natoli, Vincent )
                
        
        
      },
	Author = {Pottathuparambil, Robin and Coyne, Jack and Allred, Jeffrey and Lynch, William and Natoli, Vincent},
	Doi = {10.1109/FCCM.2011.50},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Pottathuparambil et al. - 2011 - Low-Latency FPGA Based Financial Data Feed Handler(2).pdf:pdf},
	Isbn = {978-1-61284-277-6},
	Journal = {2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines},
	Month = may,
	Pages = {93--96},
	Publisher = {Ieee},
	Title = {{Low-Latency FPGA Based Financial Data Feed Handler}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5771256},
	Year = {2011},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5771256},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/FCCM.2011.50}}

@article{Martin1997,
	Address = {New York, New York, USA},
	Author = {Martin, Richard P. and Vahdat, Amin M. and Culler, David E. and Anderson, Thomas E.},
	Doi = {10.1145/264107.264146},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/00604538.pdf:pdf},
	Isbn = {0897919017},
	Journal = {Proceedings of the 24th annual international symposium on Computer architecture - ISCA '97},
	Pages = {85--97},
	Publisher = {ACM Press},
	Title = {{Effects of communication latency, overhead, and bandwidth in a cluster architecture}},
	Url = {http://portal.acm.org/citation.cfm?doid=264107.264146},
	Year = {1997},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=264107.264146},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/264107.264146}}

@unpublished{Netronome2009a,
	Abstract = {With rising network traffic and the need for application awareness, content inspection, and security processing, the amount of network IO processing at line rates increases exponentially. This, coupled with the need for virtualization, places a huge burden on the network IO subsystem. At 10Gbps and beyond, this dictates the use of an IO virtualization co-processor (IOV-P). By classifying network traffic into flows, applying security rules and pinning flows to a specific virtual machine (VM) on a specific core on the host, and/or by load-balancing various flows into various VMs, the IOV-P enables the overall system to achieve full network performance.},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome - Understanding Network IO Virtualization (9-09).pdf:pdf},
	Pages = {8},
	Title = {{Understanding Network IO Virtualization ( IOV )}},
	Year = {2009}}

@article{Binkert2004,
	Author = {Binkert, NL and Hsu, LR and Saidi, AG},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/10.1.1.59.327.pdf:pdf},
	Journal = {Ann Arbor},
	Pages = {1--23},
	Title = {{Analyzing nic overheads in network-intensive workloads}},
	Url = {http://www.eecs.umich.edu/techreports/cse/2004/CSE-TR-505-04.pdf},
	Year = {2004},
	Bdsk-Url-1 = {http://www.eecs.umich.edu/techreports/cse/2004/CSE-TR-505-04.pdf}}

@article{Clos1952,
	Abstract = {This paper describes a method of design arrays of crosspoints for use in telephone switching systems in which it will always be possilbe to establish a connection from an idle inlet to an idle outlet regardless of the number of calls served by the system.},
	Author = {Clos, Charles},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - bstj32-2-406.pdf.pdf:pdf},
	Journal = {Bell System Technical Journal},
	Keywords = {Clos Network},
	Pages = {406--424},
	Publisher = {Bell System Technical Journal},
	Title = {{A Study of Non-Blocking Switching Networks}},
	Year = {1952}}

@article{Drepper,
	Author = {Drepper, Ulrich and Hat, Red},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/ols2006v1-pages-247-260.pdf:pdf},
	Title = {{The Need for Asynchronous , Zero-Copy Network I / O Problems and Possible Solutions}}}

@unpublished{Zuccarello2008,
	Author = {Zuccarello, Callaway},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Zuccarello - 2008 - For immediate release(2).pdf:pdf},
	Isbn = {3148624300},
	Number = {January},
	Pages = {1--3},
	Title = {{For immediate release}},
	Year = {2008}}

@article{Moorthy1999a,
	Abstract = {Clusters ofworkstations have emerged as a popular plat- form for parallel and distributed computing. Commodity high speed networks which are used to connect worksta- tion clusters provide high bandwidth, but also have high latency. SCRAMNet is an extremely low latency replicated non-coherent shared memory network, so far used only for real-time applications. This paper reports our early expe- riences with using SCRAMNet for cluster computing. We have implemented a user-level zero-copy message pass- ing protocol for SCRAMNet called the BillBoard Protocol (BBP). The one way latency for sending a 4-byte message between two nodes using the BBP is measured to be as low as 7.8  s. Since SCRAMNet supports hardware level repli- cation of messages, it is possible to implement multicast with almost the same latency as point-to-point communi- cation. Using the BBP, the latency for broadcasting short messages to 4 nodes is measured to be 10.1 tency for a 4-node barrier ismeasured to be 37  s and the la- s. We have  also built anMPI library on top of the BBP whichmakes use of multicast support from the BBP. Our results demonstrate the potential of SCRAMNet as a high performance intercon- nect for building scalable workstation clusters supporting message passing.},
	Author = {Moorthy, Vijay and Jacunski, MG and Pillai, Manoj},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Moorthy et al. - Unknown - Low-Latency Message Passing on Workstation Clusters using SCRAMNet ½ ¾(2).pdf:pdf},
	Journal = {13th International and 10th Symposium on Parallel and Distributed Processing, 1999. 1999 IPPS/SPDP. Proceedings},
	Title = {{Low-latency message passing on workstation clusters using SCRAMNet}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=760450},
	Year = {1999},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=760450}}

@unpublished{Netronome2011,
	Abstract = {Netronome's Network Flow Engine (NFE-3240) is the industry's highest-performance PCIe accelerationcardspecificallydesignedtoimprove the network performance of Intel{\textregistered}-based appli- ances and servers. Available in 2-port 10 Gigabit Ethernet and 6-port Gigabit Ethernet options, the NFE-3240 provides up to 20 Gbps of line-rate programmable packet and flow processing per card, providing a 10x performance increase over standard NICs in real-world network and security applications running on IA/x86 systems. The NFE-3240 enables the acceleration of network and security applications by utilizing high- performance packet processing delivered from 40 networking-optimizedmicroengine processor cores. The NFE-3240 utilizes several techniques to dramatically improve network I/O workloads, including packet classification, stateful flow analysis, deep packet inspection and dynamic load-balancingofflowsacrossahigh-performance virtualizedPCIedatapathtomultiplex86CPUcores toparallelize applicationprocessing.},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome NFE-3240 Product Brief (4-11).pdf:pdf},
	Pages = {2},
	Title = {{Netronome Network Flow Engine NFE-3240}},
	Year = {2011}}

@article{Pottathuparambil2011a,
	Author = {Pottathuparambil, Robin and Coyne, Jack and Allred, Jeffrey and Lynch, William and Natoli, Vincent},
	Doi = {10.1109/FCCM.2011.50},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Pottathuparambil et al. - 2011 - Low-Latency FPGA Based Financial Data Feed Handler(2).pdf:pdf},
	Isbn = {978-1-61284-277-6},
	Journal = {2011 IEEE 19th Annual International Symposium on Field-Programmable Custom Computing Machines},
	Month = may,
	Pages = {93--96},
	Publisher = {Ieee},
	Title = {{Low-Latency FPGA Based Financial Data Feed Handler}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5771256},
	Year = {2011},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5771256},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/FCCM.2011.50}}

@article{Rasmussen,
	Author = {Rasmussen, Alexander and Porter, George and Conley, Michael and Madhyastha, Harsha V and Mysore, Radhika Niranjan and Pucher, Alexander and Vahdat, Amin},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Rasmussen.pdf:pdf},
	Title = {{TritonSort : A Balanced Large-Scale Sorting System}}}

@unpublished{Netronome2008,
	Abstract = {Moving device virtualization from the virtual machine monitor (VMM) to the devices improves virtual-machine perform- ance significantly, but requires support from the devices. PCI and PCI Express (PCIe) devices can provide VMs with direct and secure I/O through the use of multiple functions per card, but at significant cost and inflexibility. One solution to help reduce the costs is the PCIe SR-IOV standard, which introduces lightweight, virtual PCIe functions. Netronome is currently developing a highly configurable and programmable PCIe networking device that can change its behavior at runtime and provide a number of different types of device functions to the host system (e.g., standard NIC, specialized packet capturing devices or crypto offload engines). We have found the PCIe SR-IOV standard to be too inflexible to support these types of devices, primarily due to its mechanism for configuring virtual functions. In this paper, Netronome proposes an alternative approach which does not require additional silicon and provides significantly higher flexibility than SR-IOV. We achieve this by delegating enumeration and configuration of ``software-configurable virtual functions'' to the main device driver for the device. This solution is compatible with the higher layers of the PCI device stack of modern operating systems and hypervisors so that all the existing mechanisms can be lever- aged for hot-plugging, discovering devices, loading device drivers and assigning PCI devices to virtual machines (including providing DMA isolation with IO-MMUs). Netronome presents details of a prototype implementation for Linux{\textregistered} and Xen.{\textregistered}},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Standardized but Flexible I-O for Self-Virtualizing Devices (5-09).pdf:pdf},
	Pages = {1--6},
	Title = {{Standardized but Flexible I / O for Self-Virtualizing Devices}},
	Year = {2008}}

@unpublished{Solarflare2012a,
	Abstract = {Solarflare{\textregistered} SFN6122F dual-port PCIe Gen 3 compatible 10G Ethernet SFP+ enterprise server adapter delivers unmatched message rates with low latency and jitter over standard Ethernet along with the lowest CPU utilization and power consumption, enabling the industry's best performance and scalability for financial services and other enterprise data centers. },
	Author = {Solarflare},
	Booktitle = {Solarflare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_SFN6122F\_10GbE\_Adapter\_Brief.pdf:pdf},
	Pages = {2},
	Title = {{Dual-Port 10GbE Enterprise Server Adapter SFN6122F}},
	Year = {2012}}

@article{West2011,
	Abstract = {In order to eliminate the costs of proprietary systems and special purpose hardware, many real-time and embedded computing platforms are being built on commodity operating systems and generic hardware. Unfortunately, many such systems are ill-suited to the low-latency and predictable timing requirements of real-time applications. This article, therefore, focuses on application-specific service technologies for low-cost commodity operating systems and hardware, so that real-time service guarantees can be met. We describe contrastingmethods to deploy first-class services on commodity systems that are dispatched with low latency and execute asynchronously according to bounds on CPU, memory, and I/O device usage. Specifically, we present a ``user-level sandboxing'' (ULS) mechanism that relies on hardware protection to isolate application- specific services from the core kernel. This approach is compared with a hybrid language and runtime protection scheme, called SafeX, that allows untrusted services to be dynamically linked and loaded into a base kernel. SafeX and ULS have been implemented on commodity Linux systems. Experimental results have shown---that both approaches are capable of reducing service violations (and, hence, better qualities of service) for real-time tasks, compared to traditional user-level methods of service deployment in process- private address spaces. ULS imposes minimal additional overheads on service dispatch latency compared to SafeX, with the advantage that it does not require application-specific services to execute in the trusted kernel domain. As evidence of the potential capabilities of ULS, we show how a user-level networking stack can be implemented to avoid data copying via the kernel and allow packet processing without explicit process scheduling. This improves throughput and reduces jitter.},
	Author = {West, Richard and Parmer, Gabriel},
	Doi = {10.1145/1952522.1952523},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/West, Parmer - 2011 - Application-specific service technologies for commodity operating systems in real-time environments(2).pdf:pdf},
	Issn = {15399087},
	Journal = {ACM Transactions on Embedded Computing Systems},
	Month = apr,
	Number = {3},
	Pages = {1--21},
	Title = {{Application-specific service technologies for commodity operating systems in real-time environments}},
	Url = {http://portal.acm.org/citation.cfm?doid=1952522.1952523},
	Volume = {10},
	Year = {2011},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1952522.1952523},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1952522.1952523}}

@article{Lu2012a,
	Address = {New York, New York, USA},
	Author = {Lu, Guohan and Miao, Rui and Xiong, Yongqiang and Guo, Chuanxiong},
	Doi = {10.1145/2342441.2342448},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p31.pdf:pdf},
	Isbn = {9781450314770},
	Journal = {Proceedings of the first workshop on Hot topics in software defined networks - HotSDN '12},
	Keywords = {challenging to support this,commodity switch,fine-grained,ip 5-tuple flows,large for-,such limi-,tation makes it very,tcam entries to match,tcp,traffic co-processing unit},
	Pages = {31},
	Publisher = {ACM Press},
	Title = {{Using CPU as a traffic co-processing unit in commodity switches}},
	Url = {http://dl.acm.org/citation.cfm?doid=2342441.2342448},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=2342441.2342448},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342441.2342448}}

@inproceedings{clint,
	Abstract = {An interconnect for a high-performance cluster has to be optimized in respect to both high throughput and low latency. To avoid the tradeoff between throughput and latency, the cluster interconnect Clint1 has a segregated architecture that provides two physically separate transmission channels: A bulk channel optimized for high-bandwidth traffic and a quick channel optimized for low-latency traffic. Different scheduling strategies are applied. The bulk channel uses a scheduler that globally allocates time slots on the transmission paths before packets are sent off. This way collisions as well as blockages are avoided. In contrast, the quick channel takes a best-effort approach by sending packets when- ever they are available thereby risking collisions and retransmissions. Simulation results clearly show the performance ad- vantages of the segregated architecture. The carefully scheduled bulk channel can be loaded nearly to its full capacity without exhibiting head-of-line blocking that limits many networks while the quick channel provides low-latency communication even in the presence of high-bandwidth traffic.},
	Annote = {
        From Duplicate 1 ( 
        
        
          Separated high-bandwidth and low-latency communication in the cluster interconnect clint
        
        
         - Eberle, Hans )

        
        

        

        

        From Duplicate 2 ( 
        
        
          Separated high-bandwidth and low-latency communication in the cluster interconnect clint
        
        
         - Eberle, Hans )

        
        

        From Duplicate 1 ( 
        
        
          Separated high-bandwidth and low-latency communication in the cluster interconnect clint
        
        
         - Eberle, Hans )

        
        

        

        

        

        

      },
	Author = {Eberle, Hans},
	Booktitle = {Proceedings of SC},
	Date-Modified = {2013-01-26 18:06:16 +0000},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Eberle, Gura - 2002 - Separated High-bandwidth and Low-latency Communication in the Cluster Interconnect Clint(2).pdf:pdf},
	Isbn = {076951524X},
	Title = {{Separated high-bandwidth and low-latency communication in the cluster interconnect clint}},
	Url = {http://dl.acm.org/citation.cfm?id=1698161},
	Year = {2002},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1698161}}

@article{Mudigonda2010,
	Abstract = {Operators of data centers want a scalable network fab- ric that supports high bisection bandwidth and host mo- bility, but which costs very little to purchase and admin- ister. Ethernet almost solves the problem -- it is cheap and supports high link bandwidths -- but traditional Ethernet does not scale, because its spanning-tree topology forces traffic onto a single tree. Many researchers have de- scribed ``scalable Ethernet'' designs to solve the scaling problem, by enabling the use of multiple paths through the network. However, most such designs require spe- cific wiring topologies, which can create deployment problems, or changes to the network switches, which could obviate the commodity pricing of these parts. In this paper, we describe SPAIN (``Smart Path Assign- ment In Networks''). SPAIN provides multipath forward- ing using inexpensive, commodity off-the-shelf (COTS) Ethernet switches, over arbitrary topologies. SPAIN pre- computes a set of paths that exploit the redundancy in a given network topology, then merges these paths into a set of trees; each tree is mapped as a separate VLAN onto the physical Ethernet. SPAIN requires only mi- nor end-host software modifications, including a sim- ple algorithm that chooses between pre-installed paths to efficiently spread load over the network. We demon- strate SPAIN's ability to improve bisection bandwidth over both simulated and experimental data-center net- works.},
	Author = {Mudigonda, Jayaram and Yalagandula, Praveen and Al-Fares, Mohammad and Mogul, Jeffrey C.},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Mudigonda - Unknown - SPAIN COTS Data-Center Ethernet for Multipathing over Arbitrary Topologies.pdf:pdf},
	Journal = {Proceedings of the 7th \ldots},
	Title = {{Spain: Cots data-center ethernet for multipathing over arbitrary topologies}},
	Url = {http://static.usenix.org/event/nsdi10/tech/full\_papers/mudigonda.pdf},
	Year = {2010},
	Bdsk-Url-1 = {http://static.usenix.org/event/nsdi10/tech/full%5C_papers/mudigonda.pdf}}

@unpublished{Solarlfare2011,
	Abstract = {FAQ},
	Author = {Solarlfare},
	Booktitle = {Solarflare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_SFN5322F\_PTP\_Adapter\_FAQ.pdf:pdf},
	Number = {0},
	Pages = {2--5},
	Title = {{SFN5322F Precision Time Synchronization Server Adapter FAQ}},
	Volume = {44},
	Year = {2011}}

@article{Rizzo2012,
	Author = {Rizzo, Luigi},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/20120503-netmap-atc12.pdf:pdf},
	Journal = {USENIX ATC},
	Number = {June},
	Title = {{netmap: a novel framework for fast packet I/O}},
	Url = {https://www.usenix.org/system/files/conference/atc12/atc12-final186.pdf},
	Year = {2012},
	Bdsk-Url-1 = {https://www.usenix.org/system/files/conference/atc12/atc12-final186.pdf}}

@unpublished{Switch,
	Author = {Switch, Ethernet and Products, Server Adapter and Tolley, Bruce and Communications, Solarflare},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Switch et al. - Unknown - 10G Ethernet The Foundation for Low-Latency , Real-Time Financial Services Applications and Other , Future Cloud Applications.pdf:pdf},
	Institution = {Solarflare},
	Pages = {1--10},
	Title = {{10G Ethernet : The Foundation for Low-Latency , Real-Time Financial Services Applications and Other , Future Cloud Applications}}}

@techreport{BerryHoekstra2011,
	Abstract = {Testing the behaviour of applications and protocols on various network setups can be a difficult task to realise. With the emergence of high- speed connectivity, new research is needed to evaluate the behaviour of (existing) applications and protocols. In this research, the netem software was evaluated as a tool to emulate network characteristics on 10 GigE and 40 GigE setups. Throughput was measured using kernels with different tick speeds. However, expected throughput could not be achieved when emulating characteristics on egress traffic. Using different kernel time resolutions does not mitigate this problem. We suspect that netem is not optimised for such a high throughput link and can not cope with the large amount of packets coming in, even though the network parameters are optimally configured. We advise to only use netem when a maximum speed of 4 to 5 Gigabit per second is expected.},
	Author = {{Berry Hoekstra}, Niels Monen},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/report.pdf:pdf},
	Pages = {40},
	Title = {{Emulating network latency on high performance networks}},
	Year = {2011}}

@unpublished{Netronome2010,
	Abstract = {As networks evolve to 10- and 40-Gigabit Ethernet, network appliances requiring regular expression and signature matching at these speeds are in need of a platform that meets the application and bandwidth requirements. Many appliance manufacturers are frequently confronted with the decision to integrate regular expression capability via specialized hardware or leverage multicore x86 processors. While both processors are capable of executing the task, the common underlying problem remains network I/O. This paper addresses network I/O challenges and offers a heterogeneous architecture solution that combines the 40-Gigabit processing power of the NFP-3240 Network Flow Processor with the general-purpose processing capabilities of Intel x86 CPUs.},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome 40 Gbps RegEx Matching for Network Appliances Whitepaper (4-10).pdf:pdf},
	Pages = {1--4},
	Title = {{40 Gbps Regular Expression Matching for Network Appliances}},
	Year = {2010}}

@article{Thekkath1993,
	Abstract = {The throughput of local area networks is rapidly increasing. For example, the bandwidth of new ATM networks and FDDI token rings is an order of magnitude greater than that of Ethernets. Other network technologies promise a bandwidth increase of yet another order of magnitude in several years. However, in distributed systems, lowered latency rather than increased throughput is often of primary concern. This paper examines the system-level effects of newer high-speed network technologies on low-latency, cross-machine communications. To evaluate a number of influences, both hardware and software, we designed and implemented a new remote procedure call system targeted at providing low latency. We then ported this system to several hardware platforms (DECstation and SPARCstation) with several different networks and controllers (ATM, FDDI, and Ethernet). Comparing these systems allows us to explore the performance impact of alternative designs in the communication system with respect to achieving low latency, e.g., the network, the network controller, the hose architecture and cache system, and the kernel and user-level runtime software. Our RPC system, which achieves substantially reduced call times (170 \&mgr;seconds on an ATM network using DECstation 5000/200 hosts), allows us to isolate those components of next-generation networks and controllers that still stand in the way of low-latency communication. We demonstrate that new-generation processor technology and software design can reduce small-packet RPC times to near network-imposed limits, making network and controller design more crucial than ever to achieving truly low-latency communication.},
	Author = {Thekkath, Chandramohan a. and Levy, Henry M.},
	Doi = {10.1145/151244.151247},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Thekkath, Levy - 1993 - Limits to low-latency communication on high-speed networks(2).pdf:pdf},
	Issn = {07342071},
	Journal = {ACM Transactions on Computer Systems},
	Month = may,
	Number = {2},
	Pages = {179--203},
	Title = {{Limits to low-latency communication on high-speed networks}},
	Url = {http://portal.acm.org/citation.cfm?doid=151244.151247},
	Volume = {11},
	Year = {1993},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=151244.151247},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/151244.151247}}

@article{BerryHoekstra2011a,
	Abstract = {Testing the behaviour of applications and protocols on various network setups can be a difficult task to realise. With the emergence of high- speed connectivity, new research is needed to evaluate the behaviour of (existing) applications and protocols. In this research, the netem software was evaluated as a tool to emulate network characteristics on 10 GigE and 40 GigE setups. Throughput was measured using kernels with different tick speeds. However, expected throughput could not be achieved when emulating characteristics on egress traffic. Using different kernel time resolutions does not mitigate this problem. We suspect that netem is not optimised for such a high throughput link and can not cope with the large amount of packets coming in, even though the network parameters are optimally configured. We advise to only use netem when a maximum speed of 4 to 5 Gigabit per second is expected.},
	Author = {{Berry Hoekstra}, Niels Monen},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/report.pdf:pdf},
	Journal = {ReVision},
	Pages = {40},
	Title = {{Emulating network latency on high performance networks}},
	Year = {2011}}

@article{Arlos2007,
	Author = {Arlos, Patrik and Fiedler, Markus},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Arlos, Fiedler - 2007 - A Method to Estimate the Timestamp Accuracy.pdf:pdf},
	Pages = {197--206},
	Title = {{A Method to Estimate the Timestamp Accuracy}},
	Year = {2007}}

@misc{HyperTransportConsortium2008a,
	Abstract = {For system and subsystem manufacturers, delivering low-latency high- performance computing solutions at affordable prices has been an insurmountable barrier. Although processor speeds and bandwidth have taken quantum leaps over the last decade, the last few inches between the adapter slot and system CPU create a bottleneck that restricts the development of cost-effective high-performance computing solutions. For complex modeling, high-end transactional systems, commercial data centers and large system clusters, high latency or {"}wait time{"} is a stumbling block that is holding back the development of systems with supercomputer-level performance using off-the-shelf components. Fortunately, a new expansion interconnect brings ultra-low latency and high performance to an expansion slot, enabling direct communication between the system CPU and high performance subsystems. HTXTM, an expansion connector specification that leverages industry-standard HyperTransportTM technology, overcomes the latency barrier common with standard systems. This white paper will address some of the challenges related to developing low-cost high-performance computing solutions and introduce the advantages of HTX.},
	Annote = {
        From Duplicate 1 ( 
        
          The future of High-Performance Computing: Direct Low Latency CPU-to-Subsystem Interconnect
        
         - Hyper Transport Consortium; others )

        
        

        

        

        From Duplicate 3 ( 
        
          The future of High-Performance Computing: Direct Low Latency CPU-to-Subsystem Interconnect
        
         - Hyper Transport Consortium; others )

        
        

        From Duplicate 2 ( 
        
          The future of High-Performance Computing: Direct Low Latency CPU-to-Subsystem Interconnect
        
         - Hyper Transport Consortium; others )

        
        

        

        

        

        

      },
	Author = {{Hyper Transport Consortium} and Others},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Drivers - 2004 - The Future of High-Performance Computing Direct Low Latency CPU-to-Subsystem Interconnect.pdf:pdf},
	Number = {October},
	Pages = {1--11},
	Publisher = {Whitepaper},
	Title = {{The future of High-Performance Computing: Direct Low Latency CPU-to-Subsystem Interconnect}},
	Url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Future+of+High-Performance+Computing+:+Direct+Low+Latency+CPU-to-Subsystem+Interconnect\#0},
	Year = {2008},
	Bdsk-Url-1 = {http://scholar.google.com/scholar?hl=en%5C&btnG=Search%5C&q=intitle:The+Future+of+High-Performance+Computing+:+Direct+Low+Latency+CPU-to-Subsystem+Interconnect%5C#0}}

@misc{CaviumNetworks,
	Author = {{Cavium Networks}},
	Title = {{OCTEON III CN7XXX Multi-Core MIPS64 Processors}},
	Url = {http://www.cavium.com/OCTEON-III\_CN7XXX.html},
	Bdsk-Url-1 = {http://www.cavium.com/OCTEON-III%5C_CN7XXX.html}}

@article{Farrington2010,
	Author = {Farrington, Nathan},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Farrington - 2010 - S CALE -O UT N ETWORKING IN THE D ATA C ENTER LAST BASTION OF THE TRADITIONAL SCALE - UP APPROACH , MAKING IT THE DATA AUTHORS EXPLORE ISSUES IN MANAGING THE NETWORK AS A SINGLE PLUG - AND - PLAY.pdf:pdf},
	Pages = {29--41},
	Title = {{S CALE -O UT N ETWORKING IN THE D ATA C ENTER LAST BASTION OF THE TRADITIONAL SCALE - UP APPROACH , MAKING IT THE DATA AUTHORS EXPLORE ISSUES IN MANAGING THE NETWORK AS A SINGLE PLUG - AND - PLAY}},
	Year = {2010}}

@article{West2011a,
	Abstract = {In order to eliminate the costs of proprietary systems and special purpose hardware, many real-time and embedded computing platforms are being built on commodity operating systems and generic hardware. Unfortunately, many such systems are ill-suited to the low-latency and predictable timing requirements of real-time applications. This article, therefore, focuses on application-specific service technologies for low-cost commodity operating systems and hardware, so that real-time service guarantees can be met. We describe contrastingmethods to deploy first-class services on commodity systems that are dispatched with low latency and execute asynchronously according to bounds on CPU, memory, and I/O device usage. Specifically, we present a ``user-level sandboxing'' (ULS) mechanism that relies on hardware protection to isolate application- specific services from the core kernel. This approach is compared with a hybrid language and runtime protection scheme, called SafeX, that allows untrusted services to be dynamically linked and loaded into a base kernel. SafeX and ULS have been implemented on commodity Linux systems. Experimental results have shown---that both approaches are capable of reducing service violations (and, hence, better qualities of service) for real-time tasks, compared to traditional user-level methods of service deployment in process- private address spaces. ULS imposes minimal additional overheads on service dispatch latency compared to SafeX, with the advantage that it does not require application-specific services to execute in the trusted kernel domain. As evidence of the potential capabilities of ULS, we show how a user-level networking stack can be implemented to avoid data copying via the kernel and allow packet processing without explicit process scheduling. This improves throughput and reduces jitter.},
	Author = {West, Richard and Parmer, Gabriel},
	Doi = {10.1145/1952522.1952523},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/West, Parmer - 2011 - Application-specific service technologies for commodity operating systems in real-time environments(2).pdf:pdf},
	Issn = {15399087},
	Journal = {ACM Transactions on Embedded Computing Systems},
	Month = apr,
	Number = {3},
	Pages = {1--21},
	Title = {{Application-specific service technologies for commodity operating systems in real-time environments}},
	Url = {http://portal.acm.org/citation.cfm?doid=1952522.1952523},
	Volume = {10},
	Year = {2011},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1952522.1952523},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1952522.1952523}}

@article{Plishker2004,
	Abstract = {WRITING HIGH-PERFORMANCE CODE FOR MODERN NETWORK PROCESSORS IS DIFFICULT BECAUSE OF THEIR COMPLEXITY. NP-CLICK IS A SIMPLE PROGRAMMING MODEL THAT PERMITS PROGRAMMERS TO REAP THE BENEFITS OF A DOMAIN SPECIFIC LANGUAGE WHILE STILL ALLOWING FOR TARGET SPECIFIC OPTIMIZATIONS. RESULTS FOR THE INTEL IXP1200 INDICATE THAT NP-CLICK DELIVERS A LARGE PRODUCTIVITY GAIN AT A SLIGHT PERFORMANCE EXPENSE.},
	Author = {Plishker, William and Keutzer, Kurt},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Plishker, Keutzer - 2004 - NP-C LICK A P RODUCTIVE S OFTWARE D EVELOPMENT A PPROACH FOR N ETWORK P ROCESSORS W RITING HIGH - PERFORMANCE CODE FOR MODERN NETWORK PROCESSORS IS.pdf:pdf},
	Journal = {Ieee Micro},
	Number = {5},
	Pages = {2--11},
	Title = {{NP-C LICK : A P RODUCTIVE S OFTWARE D EVELOPMENT A PPROACH FOR N ETWORK P ROCESSORS W RITING HIGH - PERFORMANCE CODE FOR MODERN NETWORK PROCESSORS IS}},
	Volume = {24},
	Year = {2004}}

@article{Hewlett1993,
	Author = {Hewlett, F and Dalton, Chris and Watson, Greg and Banks, DaveAfterburner : Architectural Support for High-Performance Protocols Afterburner : Architectural Support for High and Calamvokis, Costas and Edwards, Aled and Lumley, John},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/HPL-93-46.pdf:pdf},
	Journal = {Interface},
	Keywords = {Gb/s networks,TCP/IP,network interfaces, TCP/IP, Gb/s networks, network,network protocols},
	Title = {{Afterburner : Architectural Support for High-Performance Protocols Afterburner : Architectural Support for High-performance Protocols}},
	Year = {1993}}

@unpublished{Intel2008,
	Abstract = {The Intel{\textregistered} 10 Gigabit AF DA Dual Port Server Adapter is the newest member of Intel's robust family of 10 Gigabit products. Designed as a low-cost, low-power adapter, the Intel 10 Gigabit AF DA Dual Port Server Adapter provides direct attach copper twinaxial cable connections between servers and a top-of-rack switch. Two ports, coupled with a low-profile PCI Express* form factor, make this adapter ideal for slot-constrained environments. Using direct attach copper cables compliant with the SFP + MSA SFF-8431 specification, the Intel 10 Gigabit AD DA Dual Port Server Adapter is well-suited for customers who require low-cost ``in-the-rack'' connections of less than 10 meters between server and top-of-rack switch.},
	Author = {Intel},
	Booktitle = {Intel},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Intel\_10\_Gig\_AFDA\_Dual\_Port\_prodbrief.pdf:pdf},
	Pages = {10--13},
	Title = {{Intel {\textregistered} 10 Gigabit AF DA Dual Port Server Adapter}},
	Year = {2008}}

@unpublished{Solareflare2011,
	Abstract = {igh-performance computing clusters rely on predictable low-latency networking to tune inter-process communications, as well as sufficient network bandwidth to support scalable clusters, storage access and management. HPC clusters require high capacity, low power, non-blocking fabrics that are easy to deploy, easy to manage, and cost-effective. Their deployment requires a flat switching architecture implemented with high-speed top of rack switches with low-latency network adapters to transfer large amounts of data between huge server memories in each compute node.},
	Author = {Solareflare and Ready, Now and Applications, Low-latency H P C},
	Booktitle = {Solarflare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_10GbE\_HPC\_Whitepaper.pdf:pdf},
	Number = {0},
	Pages = {6},
	Title = {{10G Ethernet : Now Ready for Low-Latency HPC Applications}},
	Volume = {44},
	Year = {2011}}

@inproceedings{Black1996,
	Abstract = {FLIPC is a new messaging system intended to support distributed real time applications on high performance communication hardware. Application messaging sys- tems designed for high performance computing envi- ronments are not well suited to other environments because they lack support for the complex application structures involving multiple processes, threads, and classes of message traffic found in environments such as distributed real time. These messaging systems also have not been optimized for medium size messages found in important classes of real time applications. FLIPC includes additional features to support applica- tions outside the high performance computing domain. For medium size messages, our system significantly outperforms other messaging systems on the Intel Par- agon. An explicit design focus on programmable com- munication hardware and the resulting use of wait-free synchronization was a key factor in achieving this lev- el of performance. The implementation of FLIPC was accelerated by our use of PC clusters connected by eth- ernet or by a SCSI bus as development platforms to re- duce the need for Paragon time.},
	Author = {Black, D.L. and Smith, R.D. and Sears, S.J. and Dean, R.W.},
	Booktitle = {Proceedings of the 1996 annual conference on USENIX Annual Technical Conference},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Black et al. - 1996 - FLIPC A Low Latency Messaging System for Distributed Real Time Environments FLIPC A Low Latency Messaging System for Distributed Real Time Environments.pdf:pdf},
	Number = {January},
	Pages = {19--19},
	Publisher = {Usenix Association},
	Title = {{FLIPC : A Low Latency Messaging System for Distributed Real Time Environments}},
	Url = {http://dl.acm.org/citation.cfm?id=1268318},
	Year = {1996},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1268318}}

@article{Matz2010,
	Author = {Matz, Michael and Hubiˇ, Jan and Jaeger, Andreas and Mitchell, Mark},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/abi.pdf:pdf},
	Title = {{System V Application Binary Interface}},
	Year = {2010}}

@article{Rizzo,
	Abstract = {Many applications (software switches, traffic monitors and generators, firewalls, etc.) need to send and receive packets at line rate on very fast links. Running them on commod- ity operating systems has severe performance issues. One of the culprits is the mechanism normally used to access net- work device drivers, which has huge per-packet overheads, and is a poor match for the millions of packets per seconds traversing 1..10 Gbit/s links. A number of past proposals have suggested more efficient mechanisms, but all these so- lutions are are either limited to a specific application (e.g. packet capture), or tied to a specific hardware device, or po- tentially unsafe for the operating system. the strengths of existing proposals and addresses their weak- nesses. netmap uses memory mapped packet buffers, but enforces operating systemchecks on critical operations such as programming the hardware or passing pointers to the ker- nel, and is smoothly integratedwith the synchronization sys- tem calls provided by the OS. netmap has been implemented in FreeBSD for several 1 and 10 Gbit/s network adapters. In our prototype, it takes only 90 CPU clock cycles to move one packet between the wire and the application -- about 10 times less than using the conventional APIs. With netmap, a single core running at 1.33 GHz achieves 14.88 Mpps (the peak packet rate on 10Gbit/s links). This level of efficiency is an enabling factor to the use of commodity operating systems for a wide range of high performance network applications.},
	Annote = {
        From Duplicate 1 ( 
        
          netmap : fast and safe access to network adapters for user programs
        
         - Rizzo, Luigi; Pisa, Universita )

        
        

        

        

      },
	Author = {Rizzo, Luigi and Pisa, Universita},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/ancs2011-paper61.pdf:pdf},
	Title = {netmap : fast and safe access to network adapters for user programs}}

@misc{tileragx8000,
	Title = {{Tilera}},
	Url = {http://www.tilera.com/products/processors/TILE-Gx-8000},
	Bdsk-Url-1 = {http://www.tilera.com/products/processors/TILE-Gx-8000}}

@book{Riddoch2002,
	Abstract = {In recent years, impressive advances have been made in the performance of local area networks. In particular, network interfaces have been developed that can be accessed directly by applications at user-level, through a protected mapping onto the network adapter. These user-accessible network interfaces deliver consid- erably lower overhead and latency than traditional interfaces. However, the high performance of these networks has not been made available to ordinary distributed applications. This dissertation argues that the CLAN network model is sufficiently flexi- ble to support a range of distributed programming interfaces, and delivers high performance with comparatively simple hardware. This thesis is supported by a description and analysis of the CLAN network, and the implementation of higher- level interfaces in software over CLAN. The design of a flexible low-level interface to the CLAN network is presented, together with a shared-memory technique that reduces the cost of passing infor- mation between the application and device driver in the kernel. Techniques for im- plementing message-passing and stream interfaces over CLAN's shared memory- model are then described, including a software implementation of the Virtual In- terface Architecture. The latter is compared with a hardware implementation, and found to have superior latency. The CLAN network model is shown to have a number of advantages over other networks. Finally, support for distributed applications is provided with an implementa- tion of CORBA middleware over CLAN and other networks. CORBA is found to incur low overhead in this efficient implementation, and the lowest latency yet published for a CORBA ORB is achieved with the CLAN network. It is argued that CORBA's high level of abstraction and high performance make it a suitable level at which to integrate user-accessible networks into existing and future appli- cations. In summary, this work describes the complete implementation of a network, low-level software and middleware that brings a new level of performance to dis- tributed applications.},
	Author = {Riddoch, David},
	Booktitle = {Engineering},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Riddoch - 2002 - Low Latency Distributed Computing of Doctor of Philosophy(2).pdf:pdf},
	Number = {December},
	Title = {{Low Latency Distributed Computing of Doctor of Philosophy}},
	Year = {2002}}

@unpublished{Netronome2008a,
	Abstract = {Moving device virtualization from the virtual machine monitor (VMM) to the devices improves virtual-machine perform- ance significantly, but requires support from the devices. PCI and PCI Express (PCIe) devices can provide VMs with direct and secure I/O through the use of multiple functions per card, but at significant cost and inflexibility. One solution to help reduce the costs is the PCIe SR-IOV standard, which introduces lightweight, virtual PCIe functions. Netronome is currently developing a highly configurable and programmable PCIe networking device that can change its behavior at runtime and provide a number of different types of device functions to the host system (e.g., standard NIC, specialized packet capturing devices or crypto offload engines). We have found the PCIe SR-IOV standard to be too inflexible to support these types of devices, primarily due to its mechanism for configuring virtual functions. In this paper, Netronome proposes an alternative approach which does not require additional silicon and provides significantly higher flexibility than SR-IOV. We achieve this by delegating enumeration and configuration of ``software-configurable virtual functions'' to the main device driver for the device. This solution is compatible with the higher layers of the PCI device stack of modern operating systems and hypervisors so that all the existing mechanisms can be lever- aged for hot-plugging, discovering devices, loading device drivers and assigning PCI devices to virtual machines (including providing DMA isolation with IO-MMUs). Netronome presents details of a prototype implementation for Linux{\textregistered} and Xen.{\textregistered}},
	Author = {Netronome and Paper, White},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Standardized but Flexible I-O for Self-Virtualizing Devices (5-09).pdf:pdf},
	Pages = {1--6},
	Title = {{Standardized but Flexible I / O for Self-Virtualizing Devices}},
	Year = {2008}}

@article{Shenker,
	Author = {Shenker, Scott},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/csfq-sig98.pdf:pdf},
	Title = {{Core -Stateless Fair Queueing : Achieving Approximately Fair Bandwidth Allocations in High Speed Networks}}}

@article{Willmann2007,
	Abstract = {This paper presents hardware and software mechanisms to enable concurrent direct network access (CDNA) by op- erating systems running within a virtual machine monitor In a conventional virtual machine monitor; each operating system running within a virtual machine must access the network through a software-virtualized network interface. These virtual network interfaces are multiplexed in software onto a physical network interface, incurring significant per- formance overheads. The CDNA architecture improves net- working efficiency andperformance by dividing the tasks of traffic multiplexing, interrupt delivery, and memory protec- tion between hardware and software in a novel way. The virtual machine monitor delivers interrupts and provides protection between virtual machines, while the network in- terface performs multiplexing ofthe network data. In effect, the CDNA architecture provides the abstraction that each virtual machine is connected directly to its own network in- terface. Through the use of CDNA, many of the bottlenecks imposed by software multiplexing can be eliminated with- out sacrificing protection, producing substantial efficiency improvements.},
	Author = {Willmann, P and Shafer, J and Carr, D},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/04147671.pdf:pdf},
	Isbn = {1424408059},
	Journal = {IEEE 13th International Symposium on High Performance Computer Architecture, 2007. HPCA 2007},
	Pages = {306--317},
	Title = {{Concurrent direct network access for virtual machine monitors}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4147671},
	Year = {2007},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=4147671}}

@unpublished{Halfhill2010,
	Abstract = {NetLogic is unleashing its first barrage of networking and communications processors since acquiring RMI last year. Nine new chips are scheduled to sample this fall, each with the four-way multithreading and four-issue super- scalar features of the previously announced eight-core XLP832. The new chips have one, two, four, or eight CPUs.},
	Author = {Halfhill, Tom R.},
	Booktitle = {Microprocessor},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/MPR.pdf:pdf},
	Number = {July},
	Title = {{NETLOGIC BROADENS XLP FAMILY}},
	Year = {2010}}

@inproceedings{Serebrin,
	Abstract = {We describe a hardware and software platform for devel- oping streaming applications. Programmers write stream programs in high-level languages, and a set of software tools maps these programs to code that runs on a stream- ing hardware system. The hardware platform includes two Imagine Stream Processors, together providing 32 GFLOPS peak performance, and a high-speed onboard net- work to carry video and other data between peripherals and the Imagine processors.},
	Author = {Serebrin, B. and Owens, J.D. and Chen, C.H. and Crago, S.P. and Kapasi, U.J. and Khailany, B. and Mattson, P. and Namkoong, J. and Rixner, S. and Dally, W.J.},
	Booktitle = {Proceedings. IEEE International Conference on Computer Design: VLSI in Computers and Processors},
	Doi = {10.1109/ICCD.2002.1106786},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/01106786.pdf:pdf},
	Isbn = {0-7695-1700-5},
	Pages = {303--308},
	Publisher = {IEEE Comput. Soc},
	Title = {{A stream processor development platform}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1106786},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1106786},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/ICCD.2002.1106786}}

@misc{improveddevrev2011,
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Improved Device Driver Reliability ASPLO11.pdf:pdf},
	Title = {{Improved Device Driver Reliability ASPLO11.pdf}}}

@inproceedings{Tanabe2000,
	Abstract = {Low latency high bandwidth network interface architec- tures are described. This paper proposes two types of ar- chitectures, atomic on-the\& (OTF)sending with a header TLB, and block on-the-\$y sending with protection stam- pable window memory. These techniques work very effec- tively with MEMOnet which is a class of network interface card(NIC)plugged intoamemoryslot. Wearedevelopinga network interface controller LSI called Martini. The Mar- tini chip is used in two prototype network interface cards, DIMMnet-1 based on MEMOnet, and RHiNET-2INI based on PCI. On a DIMMnet-I, the software overhead needed to generate a message is only 1 CPU cycle and the esti- mated hardware delay is less than 1OOns using atomic OTF sending. The estimated achievable sending bandwidth of DIMMnet-1 using block OTF sending is 984MBls which was observed in our experiments. This bandwidth is 7.4 times higher than the maximum bandwidth of PCI. This ex- cellent performance is available for cheap personal com- puters with DIMM slots. This paper also discribes the e\$ fects of block OTF sendingfor a PCI-based NIC.},
	Annote = {
        From Duplicate 1 ( 
        
          On-the-fly sending: a low latency high bandwidth message transfer mechanism
        
         - Tanabe, Noboru; Yamamoto, Junji; Nishi, Hiroaki; Kudoh, Tomohiro; Hamada, Yoshihiro; Nakajo, Hironori; Amano, Hideharu )

        
        

        

        

      },
	Author = {Tanabe, Noboru and Yamamoto, Junji and Nishi, Hiroaki and Kudoh, Tomohiro and Hamada, Yoshihiro and Nakajo, Hironori and Amano, Hideharu},
	Booktitle = {Parallel Architectures, Algorithms and Networks, 2000. I-SPAN 2000. Proceedings. International Symposium on},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Tanabe et al. - 2000 - On-the-fly Sending(2).pdf:pdf},
	Pages = {186--193},
	Publisher = {IEEE},
	Title = {{On-the-fly sending: a low latency high bandwidth message transfer mechanism}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=900284},
	Year = {2000},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=900284}}

@article{Stricker1992,
	Author = {Stricker, Thomas M},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/spaa92-mesh-sorting.pdf:pdf},
	Title = {{Supporting the hypercube programming model on mesh architectures ( A fast sorter for iWarp tori )}},
	Year = {1992}}

@article{Rizzoa,
	Abstract = {Many applications (software switches, traffic monitors and generators, firewalls, etc.) need to send and receive packets at line rate on very fast links. Running them on commod- ity operating systems has severe performance issues. One of the culprits is the mechanism normally used to access net- work device drivers, which has huge per-packet overheads, and is a poor match for the millions of packets per seconds traversing 1..10 Gbit/s links. A number of past proposals have suggested more efficient mechanisms, but all these so- lutions are are either limited to a specific application (e.g. packet capture), or tied to a specific hardware device, or po- tentially unsafe for the operating system. the strengths of existing proposals and addresses their weak- nesses. netmap uses memory mapped packet buffers, but enforces operating systemchecks on critical operations such as programming the hardware or passing pointers to the ker- nel, and is smoothly integratedwith the synchronization sys- tem calls provided by the OS. netmap has been implemented in FreeBSD for several 1 and 10 Gbit/s network adapters. In our prototype, it takes only 90 CPU clock cycles to move one packet between the wire and the application -- about 10 times less than using the conventional APIs. With netmap, a single core running at 1.33 GHz achieves 14.88 Mpps (the peak packet rate on 10Gbit/s links). This level of efficiency is an enabling factor to the use of commodity operating systems for a wide range of high performance network applications.},
	Author = {Rizzo, Luigi and Pisa, Universita},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/ancs2011-paper61.pdf:pdf},
	Title = {netmap : fast and safe access to network adapters for user programs}}

@article{Binkert2006,
	Abstract = {This paper proposes new network interface controller (NIC) de- signs that take advantage of integration with the host CPU to pro- vide increased flexibility for operating system kernel-based perfor- mance optimization. We believe that this approach is more likely to meet the needs of current and future high-bandwidth TCP/IP net- working on end hosts than the current trend of putting more com- plexity in the NIC, while avoiding the need to modify applications and protocols. This paper presents two such NICs. The first, the simple integrated NIC (SINIC), is a minimally complex design that moves the responsibility for managing the network FIFOs from the NIC to the kernel. Despite this closer interaction between the kernel and the NIC, SINIC provides performance equivalent to a conventional DMA-based NIC without increasing CPU overhead. The second design, V-SINIC, adds virtual per-packet registers to SINIC, enabling parallel packet processing while maintaining a FIFO model. V-SINIC allows the kernel to decouple examining a packet's header from copying its payload to memory. We exploit this capability to implement a true zero-copy receive optimization in the Linux 2.6 kernel, providing bandwidth improvements of over 50\% on unmodified sockets-based receive-intensive benchmarks.},
	Author = {Binkert, N.L. and Saidi, A.G. and Reinhardt, S.K.},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Binkert, Saidi, Reinhardt - Unknown - Integrated Network Interfaces for High-Bandwidth TCP IP.pdf:pdf},
	Isbn = {1595934510},
	Journal = {ACM SIGPLAN Notices},
	Keywords = {ip performance,network interfaces,tcp,zero-copy},
	Number = {11},
	Pages = {315--324},
	Publisher = {ACM},
	Title = {{Integrated network interfaces for high-bandwidth TCP/IP}},
	Url = {http://dl.acm.org/citation.cfm?id=1168897},
	Volume = {41},
	Year = {2006},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1168897}}

@inproceedings{Kachris2010,
	Abstract = {One of the main challenges in the multi-core area is the communication and synchronization of the cores and the design of an efficient interconnection network that is scalable to multiple cores. In this paper we present an efficient implementation of a scalable system that is targeting multi- core systems. Each cluster node consists of 4 processors that support both explicit and implicit communication. Processor's cache is augmented with scratchpad and is merged with the network interface (NI) for reduced communication latency. All nodes are connected through a novel layer-2 switch that can support up to 20 nodes. The proposed system is designed and implemented using multiple FPGA boards and the performance evaluation presents the aggregate throughput of the system (with 16 processors) and the communication latency between that cluster nodes.},
	Annote = {
        From Duplicate 1 ( 
        
          Low-latency explicit communication and synchronization in scalable multi-core clusters
        
         - Kachris, Christoforos; Nikiforos, George; Papaefstathiou, Vassilis; Yang, X.; Kavadias, S.; Katevenis, M. )

        
        

        

        

      },
	Author = {Kachris, Christoforos and Nikiforos, George and Papaefstathiou, Vassilis and Yang, X. and Kavadias, S. and Katevenis, M.},
	Booktitle = {Cluster Computing Workshops and Posters (CLUSTER WORKSHOPS), 2010 IEEE International Conference on},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Kachris, Nikiforos, Papaefstathiou - Unknown - Low-latency Explicit Communication and Synchronization in Scalable Multi-core Clusters(2).pdf:pdf},
	Isbn = {9781424483969},
	Keywords = {communication,explicit and implicit,fpgas,merged cache-network interface,multi-cores systems},
	Pages = {1--4},
	Publisher = {IEEE},
	Title = {{Low-latency explicit communication and synchronization in scalable multi-core clusters}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5613092},
	Year = {2010},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=5613092}}

@article{Farrington2009,
	Author = {Farrington, Nathan and Rubow, Erik and Vahdat, Amin},
	Doi = {10.1109/HOTI.2009.11},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/05238680.pdf:pdf},
	Journal = {2009 17th IEEE Symposium on High Performance Interconnects},
	Keywords = {data center, network, ethernet, switch, fat tree,},
	Month = aug,
	Pages = {93--102},
	Publisher = {Ieee},
	Title = {{Data Center Switch Architecture in the Age of Merchant Silicon}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5238680},
	Year = {2009},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5238680},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/HOTI.2009.11}}

@article{Metcalfe1983,
	Author = {Metcalfe, Robert M. and Boggs, David R.},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p90-metcalfe.pdf:pdf},
	Journal = {Communications of the ACM},
	Number = {1},
	Pages = {90--95},
	Title = {{Ethernet: Distributed Packet Switching for Local Networks}},
	Volume = {26},
	Year = {1983}}

@article{Binkert2011,
	Abstract = {The gem5 simulation infrastructure is the merger of the best aspects of the M5 [4] and GEMS [9] simulators. M5 provides a highly configurable simulation framework, multiple ISAs, and diverse CPU models. GEMS comple- ments these features with a detailed and flexible mem- ory system, including support for multiple cache coher- ence protocols and interconnect models. Currently, gem5 supports most commercial ISAs (ARM, ALPHA, MIPS, Power, SPARC, and x86), including booting Linux on three of them (ARM, ALPHA, and x86). The project is the result of the combined efforts of many academic and industrial institutions, including AMD, ARM, HP, MIPS, Princeton, MIT, and the Universities of Michigan, Texas, and Wisconsin. Over the past ten years, M5 and GEMS have been used in hundreds of pub- lications and have been downloaded tens of thousands of times. The high level of collaboration on the gem5 project, combined with the previous success of the com- ponent parts and a liberal BSD-like license, make gem5 a valuable full-system simulation tool},
	Author = {Binkert, Nathan and Sardashti, Somayeh and Sen, Rathijit and Sewell, Korey and Shoaib, Muhammad and Vaish, Nilay and Hill, Mark D. and Wood, David a. and Beckmann, Bradford and Black, Gabriel and Reinhardt, Steven K. and Saidi, Ali and Basu, Arkaprava and Hestness, Joel and Hower, Derek R. and Krishna, Tushar},
	Doi = {10.1145/2024716.2024718},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Binkert et al. - 2011 - The gem5 simulator(2).pdf:pdf},
	Issn = {01635964},
	Journal = {ACM SIGARCH Computer Architecture News},
	Month = aug,
	Number = {2},
	Pages = {1},
	Title = {{The gem5 simulator}},
	Url = {http://dl.acm.org/citation.cfm?doid=2024716.2024718},
	Volume = {39},
	Year = {2011},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=2024716.2024718},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2024716.2024718}}

@misc{TheMendeleySupportTeam2011,
	Abstract = {A quick introduction to Mendeley. Learn how Mendeley creates your personal digital library, how to organize and annotate documents, how to collaborate and share with colleagues, and how to generate citations and bibliographies.},
	Address = {London},
	Author = {{The Mendeley Support Team}},
	Booktitle = {Mendeley Desktop},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/The Mendeley Support Team - 2011 - Getting Started with Mendeley(4).pdf:pdf},
	Keywords = {Mendeley,how-to,user manual},
	Pages = {1--16},
	Publisher = {Mendeley Ltd.},
	Title = {{Getting Started with Mendeley}},
	Url = {http://www.mendeley.com},
	Year = {2011},
	Bdsk-Url-1 = {http://www.mendeley.com}}

@article{Cummings2009,
	Abstract = {The convergence of different types of networks into a common data center infrastructure poses a superset chal- lenge on the part of the underlying component technology. IP networks are feature-rich, storage networks are lossless with controlled topologies, and transaction networks are low-latency with low jitter, parallel multicast. A success- ful Converged Enhanced Ethernet (CEE) switch should pass the domain specific network tests, and demonstrate these disparate capabilities at the same time, while maintaining traffic separation. The FocalPoint FM4000 Ethernet switch chip was de- signed and architected both to provide a rich Ethernet fea- ture set and maintain the highest performance around cor- ner cases. It achieves this through the use of a full-rate shared memory, parallel multicasting, switch architecture along with deeply pipelined frame processing. It imple- ments traditional Ethernet, layer-3/4, and the new CEE fea- tures. In this, paper we provide an extensive performance evaluation of the FocalPoint FM4000 chip with a number of individual performance tests including, port-to-port line rate and latency, fairness of flow control under N-to-1 hot- spot, and multicast line rate and latency tests. Finally, we explore the convergence by measuring the simultane- ous performance of prioritized, flow-controlled unicast traf- fic and provisioned multicast traffic against the backdrop of full-rate best effort stressing traffic. The experimental results show that the FocalPoint FM4000 switch provides an impressive flow-through la- tency of only 300 nanoseconds, which is insensitive to the packet size. The FM4000 delivers optimal performance un- der hot-spot communication with a degree of fairness above 98\%, and provides an upper bound for latency in prioritized multicast, ranging from 1.2 to 4.3 microseconds, depending on the average size of the background best-effort traffic. A direct comparison with non-prioritized multicasts, shows a performance speedup ranging from 29 to 38 times.},
	Author = {Cummings, Uri and Daly, Dan and Collins, Rebecca and Agarwal, Virat and Petrini, Fabrizio and Perrone, Michael and Pasetto, Davide},
	Doi = {10.1109/HOTI.2009.22},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Cummings et al. - 2009 - Fulcrum's FocalPoint FM4000 A Scalable, Low-Latency 10GigE Switch for High-Performance Data Centers(2).pdf:pdf},
	Journal = {2009 17th IEEE Symposium on High Performance Interconnects},
	Month = aug,
	Pages = {42--51},
	Publisher = {Ieee},
	Title = {{Fulcrum's FocalPoint FM4000: A Scalable, Low-Latency 10GigE Switch for High-Performance Data Centers}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5238683},
	Year = {2009},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5238683},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/HOTI.2009.22}}

@inproceedings{Welsh1996,
	Abstract = {Fast Ethernet (100Base-TX) can provide a low-cost alternative to more esoteric network tech- nologies for high-performance cluster computing. We use a network architecture based on the U-Net approach to implement low-latency and high-bandwidth communication over Fast Ether- net, with performance rivaling (and in some cases exceeding) that of 155Mbps ATM. U-Net provides protected, user-level access to the network interface and enables application-level round-trip latencies of less than 60µs over Fast Ethernet},
	Annote = {
        From Duplicate 2 ( 
        
        
          Low-latency communication over Fast Ethernet
        
        
         - Welsh, Matt; Basu, Anindya; Von Eicken, T. )

        
        

        

        

      },
	Author = {Welsh, Matt and Basu, Anindya and {Von Eicken}, T.},
	Booktitle = {Euro-Par'96 Parallel Processing},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/europar.pdf:pdf},
	Pages = {185--194},
	Publisher = {Springer},
	Title = {{Low-latency communication over Fast Ethernet}},
	Url = {http://www.springerlink.com/index/P8V685374XR25158.pdf},
	Year = {1996},
	Bdsk-Url-1 = {http://www.springerlink.com/index/P8V685374XR25158.pdf}}

@inproceedings{Liao2011,
	Abstract = {Traditional architectural designs are normally focused on CPUs and have been often decoupled from I/O considerations. They are inefficient for high-speed network processing with a bandwidth of 10Gbps and beyond. Long latency I/O interconnects on mainstream servers also substantially complicate the NIC designs. In this paper, we start with fine-grained driver and OS instrumentation to fully understand the network processing overhead over 10GbE on mainstream servers. We obtain several new findings: 1) besides data copy identified by previous works, the driver and buffer release are two unexpected major overheads (up to 54\%); 2) the major source of the overheads is memory stalls and data relating to socket buffer (SKB) and page data structures are mainly responsible for the stalls; 3) prevailing platform optimizations like Direct Cache Access (DCA) are insufficient for addressing the network processing bottlenecks. Motivated by the studies, we propose a new server I/O architecture where DMA descriptor management is shifted from NICs to an on-chip (NEngine), and descriptors information about are extended with data incurring memory stalls. NEngine relies on data lookups and preloads data to eliminate the stalls during network processing. Moreover, NEngine implements efficient packet movement inside caches to address the remaining issues in data copy. The new architecture allows DMA engine to have very fast access to descriptors and keeps packets in CPU caches instead of NIC buffers, significantly simplifying NICs. Experimental results demonstrate that the new server I/O architecture improves the network processing efficiency by 47\% and web server throughput by 14\%, while substantially reducing the NIC hardware complexity.},
	Annote = {
        From Duplicate 2 ( 
        
        
          A New Server I / O Architecture for High Speed Networks
        
        
         - Liao, Guangdeng; Zhu, Xia; Bhuyan, Laxmi )

        
        

        

        

      },
	Author = {Liao, Guangdeng and Zhu, Xia and Bhuyan, Laxmi},
	Booktitle = {High Performance Computer Architecture (HPCA), 2011 IEEE},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/05749734.pdf:pdf},
	Isbn = {9781424494354},
	Pages = {255--265},
	Title = {{A New Server I / O Architecture for High Speed Networks}},
	Year = {2011}}

@article{Lecler2011,
	Author = {Lecler, J},
	Journal = {US Patent 20110085550},
	Title = {{Zero-latency network on chip (NoC)}},
	Url = {http://www.freepatentsonline.com/y2011/0085550.html},
	Year = {2011},
	Bdsk-Url-1 = {http://www.freepatentsonline.com/y2011/0085550.html}}

@article{Mysore2009,
	Author = {Mysore, Radhika Niranjan and Pamboris, Andreas},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Mysore et al. - Unknown - PortLand A Scalable Fault-Tolerant Layer 2 Data Center Network Fabric.pdf:pdf},
	Isbn = {9781605585949},
	Journal = {ACM SIGCOMM \ldots},
	Keywords = {data center network fabric,data centers,layer 2 routing in},
	Pages = {39--50},
	Title = {{PortLand: a scalable fault-tolerant layer 2 data center network fabric}},
	Url = {http://dl.acm.org/citation.cfm?id=1594977.1592575},
	Year = {2009},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1594977.1592575}}

@unpublished{Coleman2008,
	Abstract = {Understanding the PCI Express* performance capabilities of embedded design is critical in selecting a solution that supports the IO requirements for the intended usage model. Theoretical bandwidth data is not sufficient since it is simply a calculation of frequency and bus width, not taking into account protocol overhead, bus/link efficiency, platform latency or bandwidth scaling across multiple IO devices. This paper addresses how to set PCI Express* performance targets and how to collect hardware-level measurements. It begins with an overview of Intel{\textregistered} architecture and PCI Express architecture. Following these overviews, we focus on setting PCI Express performance targets, PCI Express measurement methodology, tuning, and interpreting results. This paper will help the reader understand what is required to collect meaningful PCI Express performance data and what the results mean.},
	Author = {Coleman, James and Taylor, Perry},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Coleman, Taylor - 2008 - Hardware Level IO Benchmarking of PCI Express.pdf:pdf},
	Institution = {Intel},
	Pages = {26},
	Title = {{Hardware Level IO Benchmarking of PCI Express *}},
	Url = {ftp://download.intel.com/design/intarch/PAPERS/321071.pdf},
	Year = {2008},
	Bdsk-Url-1 = {ftp://download.intel.com/design/intarch/PAPERS/321071.pdf}}

@article{Feldmann1993,
	Address = {New York, New York, USA},
	Author = {Feldmann, Anja and Stricker, Thomas M. and Warfel, Thomas E.},
	Doi = {10.1145/165231.165257},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/spaa93-arbitrary-connection-sets.pdf:pdf},
	Isbn = {0897915992},
	Journal = {Proceedings of the fifth annual ACM symposium on Parallel algorithms and architectures - SPAA '93},
	Pages = {203--212},
	Publisher = {ACM Press},
	Title = {{Supporting sets of arbitrary connections on iWarp through communication context switches}},
	Url = {http://portal.acm.org/citation.cfm?doid=165231.165257},
	Year = {1993},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=165231.165257},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/165231.165257}}

@unpublished{Netronome2009b,
	Abstract = {With rising network traffic and the need for application awareness, content inspection, and security processing, the amount of network IO processing at line rates increases exponentially. This, coupled with the need for virtualization, places a huge burden on the network IO subsystem. At 10Gbps and beyond, this dictates the use of an IO virtualization co-processor (IOV-P). By classifying network traffic into flows, applying security rules and pinning flows to a specific virtual machine (VM) on a specific core on the host, and/or by load-balancing various flows into various VMs, the IOV-P enables the overall system to achieve full network performance.},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome - Understanding Network IO Virtualization (9-09).pdf:pdf},
	Pages = {8},
	Title = {{Network IO Virtualization ( IOV )}},
	Year = {2009}}

@article{Al-Fares2010,
	Author = {Al-Fares, M and Radhakrishnan, S},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Al-fares - Unknown - Hedera Dynamic Flow Scheduling for Data Center Networks.pdf:pdf},
	Journal = {Proceedings of the \ldots},
	Title = {{Hedera: Dynamic flow scheduling for data center networks}},
	Url = {http://static.usenix.org/event/nsdi10/tech/full\_papers/al-fares.pdf},
	Year = {2010},
	Bdsk-Url-1 = {http://static.usenix.org/event/nsdi10/tech/full%5C_papers/al-fares.pdf}}

@article{Kohler2000,
	Abstract = {Click is a new software architecturefor buildingflexible and configurable routers.AClickrouterisassembledfrompacket processing modules called elements. Individual elements im- plement simple router functions like packet classification, queueing, scheduling, and interfacing with network devices. Complete configurations are built by connecting elements into a graph; packets flow along the graph's edges. Several features make individual elements more powerful and com- plex configurations easier to write, including pull processing, which models packet flow driven by transmitting interfaces, and flow-based router context, which helps an element locate other interesting elements. Wedemonstrateseveralworkingconfigurations, including an IP router and an Ethernet bridge. These configurations are modular--the IP router has 16 elements on the forward- ing path---and easy to extend by adding additional elements, which we demonstrate with augmented configurations. On commodity PC hardware running Linux, the Click 1P router can forward 64-byte packets at 73,000 packets per second, just 10\% slower than Linux alone.},
	Author = {Kohler, Eddie and Morris, Robert and Chen, B and Jannotti, John},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p217-morris.pdf:pdf},
	Isbn = {1581131402},
	Journal = {ACM Transactions on},
	Number = {Section 2},
	Pages = {217--231},
	Title = {{The Click modular router}},
	Url = {http://dl.acm.org/citation.cfm?id=354874},
	Year = {2000},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=354874}}

@article{Felderman1995,
	Author = {Felderman, E and Kulawik, E and Seitz, L and Seizovic, N},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/1b\_m1029.pdf:pdf},
	Journal = {Ieee Micro},
	Number = {February},
	Pages = {29--36},
	Title = {{Myrinet : A Gigabit-per-Second Local Area Network}},
	Year = {1995}}

@article{Schuff2007,
	Abstract = {Programmable network interfaces can provide network servers with a flexible inter- face to high-bandwidth Ethernet links, but they face critical software and architec- tural challenges. This article explores architectural and software support for an efficient programmable 10 Gigabit Ethernet controller. The design is then extended to support a self-securing Gigabit Ethernet controller that performs intrusion detec- tion on all network data frames. Both raw performance and security require high- bitrate frame data transfer, low-latency metadata access, and intensive computational capacity while still operating under the area, cost, and power bud- get of a peripheral device. These goals are achieved using a combination of paral- lel lightweight processing cores, an explicitly-partitioned memory system, and dedicated hardware assists. The firmware on the network interface is designed to utilize these resources efficiently by exploiting frame-level, flow-level, and task-level concurrency.},
	Author = {Schuff, Derek L and Pai, Vijay S and Willmann, Paul and Rixner, Scott},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/04277245.pdf:pdf},
	Journal = {Ieee Network},
	Number = {August},
	Pages = {22--28},
	Title = {{Parallel Programmable Ethernet Controllers: Performance and Security}},
	Year = {2007}}

@article{Shenkera,
	Author = {Shenker, Scott},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/csfq-sig98.pdf:pdf},
	Title = {{Core -Stateless Fair Queueing : Achieving Approximately Fair Bandwidth Allocations in High Speed Networks}}}

@unpublished{Melanox2008,
	Abstract = {For over 8 years, Mellanox Technologies has been an active leader in high-performance interconnect technology. The Company recently introduced its feature-rich 10 Gigabit Ethernet silicon and adapter with industry leading support for networking, virtualization and storage: Mellanox's ConnectX EN 10 Gigabit Ethernet adapter is the first adapter to support the PCI Express Gen 2.0 specification, which delivers 32Gb/s of PCI performance per direction with a x8 link compared to 16Gb/s with a Gen1 device. Dual-port Mellanox ConnectX EN adapters, not only deliver high availability, but also link aggrega- tion and high-performance because of PCIe Gen 2.0.},
	Author = {Melanox and Statement, Problem and Servers, More},
	Booktitle = {Melanox},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Arista\_Mellanox.pdf:pdf},
	Number = {October},
	Pages = {1--5},
	Title = {{October 2008 ARISTA : Improving Application Performance While Reducing Complexity}},
	Year = {2008}}

@inproceedings{Subramoni2010,
	Abstract = {This paper presents and evaluates the performance of a prototype of an on-line OPRA data feed decoder. Our work demonstrates that, by using best-in-class commodity hard- ware, algorithmic innovations and careful design, it is pos- sible to obtain the performance of custom-designed hard- ware solutions. Our prototype system integrates the latest Intel Nehalem processors and Myricom 10 Gigabit Ethernet technologies with an innovative algorithmic design based on the DotStar compilation tool. The resulting system can provide low la- tency, high bandwidth and the flexibility of commodity com- ponents in a single framework, with an end-to-end latency of less then four microseconds and an OPRA feed process- ing rate of almost 3 million messages per second per core, with a packet payload of only 256 bytes.},
	Annote = {
        From Duplicate 2 ( 
        
        
          Streaming, low-latency communication in on-line trading systems
        
        
         - Subramoni, Hari; Petrini, F.; Agarwal, Virat; Pasetto, D. )

        
        

        

        

      },
	Author = {Subramoni, Hari and Petrini, F. and Agarwal, Virat and Pasetto, D.},
	Booktitle = {Parallel \& Distributed Processing, Workshops and Phd Forum (IPDPSW), 2010 IEEE International Symposium on},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Subramoni, Agarwal - 2010 - Streaming , Low-latency Communication in On-line Trading Systems(2).pdf:pdf},
	Isbn = {9781424465347},
	Pages = {1--8},
	Publisher = {IEEE},
	Title = {{Streaming, low-latency communication in on-line trading systems}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5470717},
	Year = {2010},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=5470717}}

@misc{Myricom,
	Author = {{Myricom Inc}},
	Date-Modified = {2012-11-05 13:15:16 +0000},
	Title = {Myri-10G {"}Gen2{"} (5 GT/s) PCI Express Network Adapter with two SFP+ network ports for performance and failover (20Gb/s throughput)},
	Url = {http://www.myricom.com/products/network-adapters/10g-pcie2-8c2-2s.html},
	Bdsk-Url-1 = {http://www.myricom.com/products/network-adapters/10g-pcie2-8c2-2s.html}}

@article{Kermani1979,
	Abstract = {In this paper a new switching technique called virtual cut-through is proposed and its performance is analyzed. This switching system is very similar to message switching, with the difference that when a message arrives in an intermediate node and its selected outgoing channel is free (just after the reception of the header), then, in contrast to message switching, the message is sent out to the adjacent node towards its destination before it is received completely at the node; only if the message is blocked due to a busy output channel is a message buffered in an intermediate node. Therefore, the delay due to unnecessary buffering in front of an idle channel is avoided. We analyze and compare the performance of this new switching technique with that of mes- sage switching with respect to three measures: network delay, traffic gain and buffer storage requirement. Our analysis shows that cut-through switching is superior (and at worst identical) to message switching with respect to the above three performance measures.},
	Author = {Kermani, Parviz and Kleinrock, Leonard},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Kermani, Kleinrock - 1979 - Virtual Cut-Through A New Computer Communication Switching Technique.pdf:pdf},
	Journal = {Computer Networks},
	Number = {4},
	Pages = {267--286},
	Publisher = {Elsevier},
	Title = {{Virtual cut-through: A new computer communication switching technique}},
	Url = {http://www.sciencedirect.com/science/article/pii/0376507579900321},
	Volume = {3},
	Year = {1979},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0376507579900321}}

@article{Rhoden2011,
	Address = {New York, New York, USA},
	Author = {Rhoden, Barret and Klues, Kevin and Zhu, David and Brewer, Eric},
	Doi = {10.1145/2038916.2038941},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/socc11-akaros.pdf:pdf},
	Isbn = {9781450309769},
	Journal = {Proceedings of the 2nd ACM Symposium on Cloud Computing - SOCC '11},
	Keywords = {akaros,custom os,datacenter},
	Number = {C},
	Pages = {1--8},
	Publisher = {ACM Press},
	Title = {{Improving per-node efficiency in the datacenter with new OS abstractions}},
	Url = {http://dl.acm.org/citation.cfm?doid=2038916.2038941},
	Year = {2011},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=2038916.2038941},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2038916.2038941}}

@article{Morris2009,
	Annote = {
        From Duplicate 2 ( 
        
        
          FPGA Accelerated Low-Latency Market Data Feed Processing
        
        
         - Morris, Gareth W.; Thomas, David B.; Luk, Wayne )

        
        

        

        

      },
	Author = {Morris, Gareth W. and Thomas, David B. and Luk, Wayne},
	Doi = {10.1109/HOTI.2009.17},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Morris, Thomas, Luk - 2009 - FPGA Accelerated Low-Latency Market Data Feed Processing(2).pdf:pdf},
	Journal = {2009 17th IEEE Symposium on High Performance Interconnects},
	Keywords = {FPGA,finance,market-data,networks,trading},
	Month = aug,
	Pages = {83--89},
	Publisher = {Ieee},
	Title = {{FPGA Accelerated Low-Latency Market Data Feed Processing}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5238679},
	Year = {2009},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5238679},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/HOTI.2009.17}}

@unpublished{Solarflare2012b,
	Abstract = {One of the world's largest investment banks needed to distribute time synchronization to financial transaction servers co-located at worldwide exchanges. Its challenge was to utilize Precision Time Protocol (PTP, a.k.a. IEEE 1588) technology from available ecosystem components that would allow it to deploy remotely. The firm chose Solarflare's SFN5322F server adapter to simplify and optimize its time synchronization deployments.},
	Author = {Solarflare},
	Booktitle = {Solarflare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_10GbE\_PTP\_CaseStudy.pdf:pdf},
	Pages = {2},
	Title = {{Case Study Global Investment Bank Deploys Solarflare 10GbE PTP Server Adapters}},
	Year = {2012}}

@techreport{Pope2011,
	Abstract = {Solarflare's OpenOnload{\textregistered} application acceleration middleware is an accelerated network stack. It is an implementation of TCP and UDP over IP which is dynamically linked into an application's address space and granted direct access to accelerated network hardware. The network stack interposes network operations from the application and enables them to be handled completely at user-space. In so doing, it bypasses the operating system and significantly improves performance through the removal of disruptive events such as context switches and interrupts which otherwise reduce the efficiency by which a processor can execute application code.},
	Author = {Pope, Steve},
	Booktitle = {Solarflare},
	Date-Modified = {2012-11-05 13:28:39 +0000},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_OpenOnload\_IntroPaper.pdf:pdf},
	Number = {0},
	Pages = {1--8},
	Title = {{Introduction to OpenOnload, Building Application Transparency and Protocol Conformance into Application Acceleration Middleware}},
	Volume = {44},
	Year = {2011}}

@article{Iyer2002,
	Author = {Iyer, Sundar and Zhang, Rui and Mckeown, Nick},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/sigcomm2002.pdf:pdf},
	Isbn = {158113570X},
	Number = {650},
	Title = {{Routers with a Single Stage of Buffering}},
	Year = {2002}}

@article{Mysore2009a,
	Author = {Mysore, Radhika Niranjan and Pamboris, Andreas},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Mysore et al. - Unknown - PortLand A Scalable Fault-Tolerant Layer 2 Data Center Network Fabric.pdf:pdf},
	Isbn = {9781605585949},
	Journal = {ACM SIGCOMM \ldots},
	Keywords = {data center network fabric,data centers,layer 2 routing in},
	Pages = {39--50},
	Title = {{PortLand: a scalable fault-tolerant layer 2 data center network fabric}},
	Url = {http://dl.acm.org/citation.cfm?id=1594977.1592575},
	Year = {2009},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1594977.1592575}}

@article{McKenney1992,
	Author = {McKenney, Paul E. and Dove, Ken F.},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/tcpdemux.pdf:pdf},
	Journal = {ACM SIGCOMM Computer Communication},
	Title = {{Efficient Demultiplexing of Incoming TCP Packets}},
	Url = {http://dl.acm.org/citation.cfm?id=144299},
	Year = {1992},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=144299}}

@article{Al-Fares2008,
	Address = {New York, New York, USA},
	Author = {Al-Fares, Mohammad and Loukissas, Alexander and Vahdat, Amin},
	Doi = {10.1145/1402958.1402967},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Al-Fares, Loukissas, Vahdat - 2008 - A scalable, commodity data center network architecture.pdf:pdf},
	Isbn = {9781605581750},
	Journal = {Proceedings of the ACM SIGCOMM 2008 conference on Data communication - SIGCOMM '08},
	Keywords = {data center topology,equal-cost routing},
	Pages = {63},
	Publisher = {ACM Press},
	Title = {{A scalable, commodity data center network architecture}},
	Url = {http://portal.acm.org/citation.cfm?doid=1402958.1402967},
	Year = {2008},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1402958.1402967},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1402958.1402967}}

@article{Freescale2012,
	Abstract = {The first SoCs in the QorIQ Advanced Multiprocessing (AMP) series are the T4240 with 12 physical cores supporting 24 virtual cores and the T4160 with 8 physical core supporting 16 virtual cores. With frequencies scaling to 1.8 GHz, large caches, hardware acceleration and advanced system peripherals, these products target applications that benefit from consolidation of control and data plane processing in a single SoC.},
	Author = {Freescale},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/T4240T4160FS.pdf:pdf},
	Journal = {Freescale},
	Title = {{T4240: QorIQ AMP Series T4240/T4160 64-bit Multicore Communications Processors}},
	Url = {http://www.freescale.com/webapp/sps/site/prod\_summary.jsp?code=T4240},
	Year = {2012},
	Bdsk-Url-1 = {http://www.freescale.com/webapp/sps/site/prod%5C_summary.jsp?code=T4240}}

@article{Dean2008,
	Abstract = {MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a map and a reduce function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
	Author = {Dean, Jeffrey and Ghemawat, Sanjay},
	Doi = {10.1145/1327452.1327492},
	Editor = {Daniel, L Purich},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Dean, Ghemawat - 2008 - MapReduce Simplified Data Processing on Large Clusters.pdf:pdf},
	Institution = {Google, Inc.},
	Isbn = {9781595936868},
	Issn = {00010782},
	Journal = {Communications of the ACM},
	Number = {1},
	Pages = {1--13},
	Pmid = {11687618},
	Publisher = {ACM},
	Series = {SIGMOD '07},
	Title = {{MapReduce : Simplified Data Processing on Large Clusters}},
	Url = {http://portal.acm.org/citation.cfm?id=1327492},
	Volume = {51},
	Year = {2008},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?id=1327492},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1327452.1327492}}

@article{Sadoghi2011,
	Abstract = {In this demo, we present fpga-ToPSS 1(a member of Toronto Pub- lish/Subscribe System Family), an efficient event processing plat- form for high-frequency and low-latency algorithmic trading. Our event processing platform is built over reconfigurable hardware--- FPGAs---to achieve line-rate processing. Furthermore, our event processing engine supports Boolean expression matching with an expressive predicate language that models complex financial strate- gies to autonomously mimic the buying and the selling of stocks based on real-time financial data.},
	Author = {Sadoghi, Mohammad and Singh, Harsh and Jacobsen, Hans-arno},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p373-sadoghi.pdf:pdf},
	Isbn = {9781450304238},
	Journal = {msrg.toronto.edu},
	Keywords = {100 million a year,6,and complex event processing,figure 1,fpga,over,publish,subscribe,such requirements greatly increases,various degrees of parallelism},
	Pages = {373--374},
	Title = {{Demo: fpga-ToPSS--Line-speed Event Processing on FPGAs}},
	Url = {http://www.msrg.toronto.edu/publications/pdf\_files/2011/moFPGADemoDEBS11-Demo:\_fpga-ToPSS\_--\_Line-spe.pdf},
	Year = {2011},
	Bdsk-Url-1 = {http://www.msrg.toronto.edu/publications/pdf%5C_files/2011/moFPGADemoDEBS11-Demo:%5C_fpga-ToPSS%5C_--%5C_Line-spe.pdf}}

@unpublished{Netronome2012,
	Abstract = {The term virtual machine (VM) was first used in the 1960s. Since then, the use of varied forms of virtualization as an efficiency mechanism has grown dramatically. A recent study found that in 2010 alone, nearly 60\% of data centers are expanding their virtualization deployments. Virtualized network infrastructure has been around for years. Notable technologies, like Ethernet VLANs, IPSec and SSL VPNs, and L3 VPNs via MPLS or virtual routing, are all examples of tried-and-true technologies for virtualizing networks. These techniques allow a single set of physical resources to be shared among a diverse group of users, providing isolation, performance guarantees and security. Each of these benefits can also apply to application hosting platforms. Mechanisms to virtualize servers are now becoming commonplace with server virtualization seen as the key to the convergence of networking and computing in the data center. According to research firm Gartner,{\textregistered} there will be about 58 million deployed VMs by 2012.*},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Network I-O Challenges of Data Center Virtualization.pdf:pdf},
	Pages = {1--3},
	Title = {{Network I / O Challenges of Data Center Virtualization}},
	Year = {2012}}

@unpublished{Netronome2011a,
	Abstract = {As networks evolve to 10 Gigabit and 40 Gigabit Ethernet speeds, network appliances can create a significant performance bottleneck because they have failed to keep pace with ever-increasing bandwidth. Traditional server platforms provide poor packet capture performance, due to fundamental architectural issues in hardware and the operating system, making these platforms unsuitable when 10+ Gigabit levels of packet capture and application processing are required. There have been many attempts to scale the packet capture, classification and filtering performance of network appliances built on standard server platforms with some per- formance improvement. Even considering these techniques, these platforms provide actual throughput that is far below what is required to support high-throughput packet capture, classification and filtering appli- cations. To overcome these network appli- ance performance issues, Netronome has developed hard- ware and software components that allow both ISVs and end users to acceler-},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Scaling Network App Performance White Paper (4-11).pdf:pdf},
	Pages = {6},
	Title = {{Scaling Network Appliance Performance}},
	Year = {2011}}

@article{melanox7reasons2009,
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Mellanox\_ConnectX\_10GbE.pdf:pdf},
	Journal = {Integration The Vlsi Journal},
	Number = {October 2008},
	Pages = {1--6},
	Title = {{7 Reasons to deploy a Mellanox ConnectX 10GbE}},
	Year = {2009}}

@inproceedings{Tanabe2000a,
	Abstract = {Low latency high bandwidth network interface architec- tures are described. This paper proposes two types of ar- chitectures, atomic on-the\& (OTF)sending with a header TLB, and block on-the-\$y sending with protection stam- pable window memory. These techniques work very effec- tively with MEMOnet which is a class of network interface card(NIC)plugged intoamemoryslot. Wearedevelopinga network interface controller LSI called Martini. The Mar- tini chip is used in two prototype network interface cards, DIMMnet-1 based on MEMOnet, and RHiNET-2INI based on PCI. On a DIMMnet-I, the software overhead needed to generate a message is only 1 CPU cycle and the esti- mated hardware delay is less than 1OOns using atomic OTF sending. The estimated achievable sending bandwidth of DIMMnet-1 using block OTF sending is 984MBls which was observed in our experiments. This bandwidth is 7.4 times higher than the maximum bandwidth of PCI. This ex- cellent performance is available for cheap personal com- puters with DIMM slots. This paper also discribes the e\$ fects of block OTF sendingfor a PCI-based NIC.},
	Annote = {
        From Duplicate 1 ( 
        
          On-the-fly sending: a low latency high bandwidth message transfer mechanism
        
         - Tanabe, Noboru; Yamamoto, Junji; Nishi, Hiroaki; Kudoh, Tomohiro; Hamada, Yoshihiro; Nakajo, Hironori; Amano, Hideharu )

        
        

        

        

        From Duplicate 2 ( 
        
          On-the-fly sending: a low latency high bandwidth message transfer mechanism
        
         - Tanabe, Noboru; Yamamoto, Junji; Nishi, Hiroaki; Kudoh, Tomohiro; Hamada, Yoshihiro; Nakajo, Hironori; Amano, Hideharu )

        
        

        From Duplicate 1 ( 
        
          On-the-fly sending: a low latency high bandwidth message transfer mechanism
        
         - Tanabe, Noboru; Yamamoto, Junji; Nishi, Hiroaki; Kudoh, Tomohiro; Hamada, Yoshihiro; Nakajo, Hironori; Amano, Hideharu )

        
        

        

        

        

        

      },
	Author = {Tanabe, Noboru and Yamamoto, Junji and Nishi, Hiroaki and Kudoh, Tomohiro and Hamada, Yoshihiro and Nakajo, Hironori and Amano, Hideharu},
	Booktitle = {Parallel Architectures, Algorithms and Networks, 2000. I-SPAN 2000. Proceedings. International Symposium on},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Tanabe et al. - 2000 - On-the-fly Sending(2).pdf:pdf},
	Pages = {186--193},
	Publisher = {IEEE},
	Title = {{On-the-fly sending: a low latency high bandwidth message transfer mechanism}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=900284},
	Year = {2000},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=900284}}

@article{Plishker2004a,
	Abstract = {WRITING HIGH-PERFORMANCE CODE FOR MODERN NETWORK PROCESSORS IS DIFFICULT BECAUSE OF THEIR COMPLEXITY. NP-CLICK IS A SIMPLE PROGRAMMING MODEL THAT PERMITS PROGRAMMERS TO REAP THE BENEFITS OF A DOMAIN SPECIFIC LANGUAGE WHILE STILL ALLOWING FOR TARGET SPECIFIC OPTIMIZATIONS. RESULTS FOR THE INTEL IXP1200 INDICATE THAT NP-CLICK DELIVERS A LARGE PRODUCTIVITY GAIN AT A SLIGHT PERFORMANCE EXPENSE.},
	Annote = {
        From Duplicate 1 ( 
        
          NP-C LICK : A P RODUCTIVE S OFTWARE D EVELOPMENT A PPROACH FOR N ETWORK P ROCESSORS W RITING HIGH - PERFORMANCE CODE FOR MODERN NETWORK PROCESSORS IS
        
         - Plishker, William; Keutzer, Kurt )

        
        

        

        

      },
	Author = {Plishker, William and Keutzer, Kurt},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Plishker, Keutzer - 2004 - NP-C LICK A P RODUCTIVE S OFTWARE D EVELOPMENT A PPROACH FOR N ETWORK P ROCESSORS W RITING HIGH - PERFORMANCE CODE FOR MODERN NETWORK PROCESSORS IS.pdf:pdf},
	Journal = {Ieee Micro},
	Number = {5},
	Pages = {2--11},
	Title = {{NP-C LICK : A P RODUCTIVE S OFTWARE D EVELOPMENT A PPROACH FOR N ETWORK P ROCESSORS W RITING HIGH - PERFORMANCE CODE FOR MODERN NETWORK PROCESSORS IS}},
	Volume = {24},
	Year = {2004}}

@unpublished{Netronome2011b,
	Abstract = {Today's network and computing infra- structure is of critical interest to all aspects of our lives, from business and commerce to personal entertainment, and even national security. These vital communication systems share a couple of important characteristics: they require massive amounts of bandwidth to support our insatiable appetite for IP-based services and they require mechanisms offering visibility into all data protocol and application layers to ensure network security. Unfortunately, the network appliances commonly hosting security applications have failed to keep pace with improvements in network performance. However, a new heterogeneous multi- core processing architecture can scale to support tomorrow's throughput needs while providing the ability to see deeply into network traffic.},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome\_Developing High-performance Embedded Network Security Applications White Paper\_4-11.pdf:pdf},
	Pages = {1--4},
	Title = {{Developing High-performance Embedded Network Security Applications A Heterogeneous Multicore Processing Approach}},
	Year = {2011}}

@article{Mudigonda,
	Author = {Mudigonda, Jayaram},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Mudigonda - Unknown - SPAIN COTS Data-Center Ethernet for Multipathing over Arbitrary Topologies.pdf:pdf},
	Title = {{SPAIN : COTS Data-Center Ethernet for Multipathing over Arbitrary Topologies}}}

@unpublished{Netronome2009c,
	Abstract = {4x1gigabit Ethernet line-rate flow processing and deeppacket inspection. Intel IXP2855NPU(16microengines,plus cryptohardware)},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome Flow Engine Product Brief (4-09).pdf:pdf},
	Pages = {2},
	Title = {{Netronome Flow Engine Acceleration Card}},
	Year = {2009}}

@article{Colp2011,
	Author = {Colp, Patrick and Nanavati, Mihir and Zhu, Jun and Aiello, William and Coker, George and Deegan, Tim and Loscocco, Peter and Warfield, Andrew},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/xoar-sosp-final.pdf:pdf},
	Isbn = {9781450309776},
	Title = {{Breaking Up is Hard to Do : Security and Functionality in a Commodity Hypervisor}},
	Year = {2011}}

@inproceedings{Hashimoto2010,
	Abstract = {TCP/IP offload engine (TOE) is an essential technology to increase throughput of network connection. In this paper we present a novel approach for TOE implementation in embedded system with very stringent requirements on area and power. Our approach is based on two design optimizations. The first one deals with architectural enhancement for reducing the size of memory buffers in TOE hardware. The second one optimizes the TCP/IP data flow in order to speculatively process the TCP/IP packet headers in parallel to DMA data transfers. Experiments show that prototype design of TOE receiver operating at a very low (25MHz) frequency can achieve 13.1Mbs the approach is very effective. A throughput while requiring only 57.5K 2-input NAND logic gates for control logic.},
	Author = {Hashimoto, Koji and Moshnyaga, Vasily G},
	Booktitle = {Signals, Systems and Computers (ASILOMAR), 2010},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/05757731.pdf:pdf},
	Isbn = {9781424497218},
	Pages = {1249--1253},
	Title = {{A New Approach for TCP / IP Offload Engine Implementation in Embedded Systems}},
	Year = {2010}}

@inproceedings{Magoutis2004,
	Author = {Magoutis, Kostas and Seltzer, M.I. and Gabber, Eran},
	Booktitle = {Third Workshop on Novel Uses of System Area Networks (SAN-3)(Held in conjunction with HPCA-10)},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/paper.pdf:pdf},
	Title = {{The case against user-level networking}},
	Url = {http://scholar.google.com/scholar?hl=en\&btnG=Search\&q=intitle:The+Case+Against+User-Level+Networking\#0},
	Year = {2004},
	Bdsk-Url-1 = {http://scholar.google.com/scholar?hl=en%5C&btnG=Search%5C&q=intitle:The+Case+Against+User-Level+Networking%5C#0}}

@inproceedings{Ruan2004,
	Author = {Ruan, Y and Pai, V S},
	Booktitle = {Performance Evaluation Review},
	Keywords = {connection scheduling,latency,network server},
	Number = {1},
	Pages = {424--425},
	Title = {{The origins of network server latency \& the myth of connection scheduling}},
	Url = {http://www.scopus.com/inward/record.url?eid=2-s2.0-8344236090\&partnerID=40\&md5=98d9e12de40dffa27671a799642f0be0},
	Volume = {32},
	Year = {2004},
	Bdsk-Url-1 = {http://www.scopus.com/inward/record.url?eid=2-s2.0-8344236090%5C&partnerID=40%5C&md5=98d9e12de40dffa27671a799642f0be0}}

@unpublished{Systems2010,
	Abstract = {With more trading decisions and order execution processes being automated, it is critical to make sure information flows quickly and consistently through the front, mid and back office. The picture goes well beyond just raw speed, however, as market participants understand that consistency and predictability are just as important. This paper describes how a system based on message routers from Solace Systems and 10GigE technology from Cisco Systems and Solarflare Communications can deliver lower and more consistent latency than software-based solutions. It also provides performance numbers including average and 99.9th percentile figures at a variety of rates. When routing 1,000,000 messages per second the platform exhibited average latency of 28 microseconds and 99.9th percentile latency of 32 microseconds. At five times that volume, a rate that represents substantial performance headroom for most firms, latency was still low with minimal jitter: averaging 39 microseconds with 99.9th percentile of 48.},
	Author = {Systems, Solace and Solarflare},
	Booktitle = {Solarflare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Low\_Latency\_10GbE\_Solace\_Cisco\_Solarflare.pdf:pdf},
	Pages = {4},
	Title = {{Achieving Low , Consistent Latency in Market Data Distribution with Solace , Cisco and Solarflare}},
	Year = {2010}}

@unpublished{Tilera2011,
	Author = {Tilera},
	Booktitle = {Tilera},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Tile-Gx 3036 SB012-01.pdf:pdf},
	Pages = {1},
	Title = {{TILE-Gx 3036 Specifications 36 Cores}},
	Year = {2011}}

@article{Brebner2011,
	Author = {Brebner, Gordon},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Brebner - 2011 - Reconfigurable Computing for High Performance Networking Applications(2).pdf:pdf},
	Journal = {Reconfigurable Computing: Architectures, Tools and Applications},
	Number = {March},
	Pages = {1--1},
	Publisher = {Springer Berlin/Heidelberg},
	Title = {{Reconfigurable computing for high performance networking applications}},
	Url = {http://china.xilinx.com/innovation/research-labs/keynotes/Arc2011-Keynote.pdf},
	Volume = {6578},
	Year = {2011},
	Bdsk-Url-1 = {http://china.xilinx.com/innovation/research-labs/keynotes/Arc2011-Keynote.pdf}}

@article{Vergara2010,
	Author = {Vergara, Arturo and Moral, Antol\'{\i}n and P\'{e}rez, Jorge},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/05624919.pdf:pdf},
	Isbn = {9781424467051},
	Pages = {0--5},
	Title = {{COSTA : A Model to Analyze Next Generation Broadband Access Platform Competition}},
	Year = {2010}}

@article{Kohler2000a,
	Abstract = {Click is a new software architecturefor buildingflexible and configurable routers.AClickrouterisassembledfrompacket processing modules called elements. Individual elements im- plement simple router functions like packet classification, queueing, scheduling, and interfacing with network devices. Complete configurations are built by connecting elements into a graph; packets flow along the graph's edges. Several features make individual elements more powerful and com- plex configurations easier to write, including pull processing, which models packet flow driven by transmitting interfaces, and flow-based router context, which helps an element locate other interesting elements. Wedemonstrateseveralworkingconfigurations, including an IP router and an Ethernet bridge. These configurations are modular--the IP router has 16 elements on the forward- ing path---and easy to extend by adding additional elements, which we demonstrate with augmented configurations. On commodity PC hardware running Linux, the Click 1P router can forward 64-byte packets at 73,000 packets per second, just 10\% slower than Linux alone.},
	Author = {Kohler, Eddie and Morris, Robert and Chen, Benjie and Jannotti, John and Kaashoek, M Frans},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p217-morris.pdf:pdf;:Users/mgrosvenor/Dropbox/PHD/Reading/kohler00click-yapteaparprfotci.pdf:pdf},
	Isbn = {1581131402},
	Journal = {ACM Transactions on},
	Number = {Section 2},
	Pages = {217--231},
	Title = {{The Click modular router}},
	Url = {http://dl.acm.org/citation.cfm?id=354874},
	Volume = {1},
	Year = {2000},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=354874}}

@unpublished{Solarlfare2011a,
	Abstract = {Princeton Plasma Physics Laboratory (PPPL), joined by the world-wide fusion energy research community, is working to develop the first self-sustaining fusion reactor, slated to go on line by 2016. To reach this goal, researchers model the properties of deuterium and tritium movement in a plasma field, which is required for sustained fusion reaction.},
	Author = {Solarlfare},
	Booktitle = {Solarflare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_10GbE\_PPPL\_CaseStudy.pdf:pdf},
	Pages = {4},
	Title = {{Case Study Princeton Plasma Physics Laboratory ( PPPL ) Finds 10GbE Improves Cluster Performance by 36 \% over DDR InfiniBand}},
	Year = {2011}}

@unpublished{Netronome2007,
	Abstract = {The Internet has become the backbone of commerce, entertainment and information exchange. It is still evolving and new business models, usage models and tech- nologies are deployed daily. New technologies that are having an impact include Web 2.0, hosted applica- tions, rich-media sites and real-time com- munication. While these applications drive a continued need for increased bandwidth, greater reliability and lower latency from the network, simultaneously security requirements dictate that the network must have significantly greater application awareness. This whitepaper focuses on the requirements for next-generation network appliances in intelligently processing traffic for the growing real-time, interactive and transactional applications. We define the term ``intelligent networking'' to encompass the needs of these applications.},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome - Intelligent Network Applications for 10Gbps and Beyond (9-07)(1).pdf:pdf},
	Pages = {4},
	Title = {{Intelligent Network Applications for 10Gbps and Beyond}},
	Year = {2007}}

@article{Zhang2010,
	Author = {Zhang, Jingjing and Member, Student and Ansari, Nirwan and Jin, Yaohui and Member, Associate},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2010 - Dichotomy Slot Allocation A QoS Guaranteed Scheduling Algorithm for Input-Queued Switches.pdf:pdf},
	Number = {1},
	Pages = {74--83},
	Title = {{Dichotomy Slot Allocation : A QoS Guaranteed Scheduling Algorithm for Input-Queued Switches}},
	Volume = {4},
	Year = {2010}}

@article{Gupte,
	Abstract = {Abstract---In many mission critical real-time networked sys- tems, such as those used in financial institutions, incoming data (such as market feeds) is brought in on redundant links. These links are generally provided by separate providers for maximum redundancy. Although the data on both of these links is expected to be the same, there are delays and packet losses that can be different. In this paper we describe a NetFPGA module which can accurately measure these delays to help the institutions evaluate the quality of service provided to them by their vendors.},
	Author = {Gupte, Adwait and Lockwood, John W},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/NetFPGA\_Dev\_2010\_Precise\_Latency\_Comparison\_Module.pdf:pdf},
	Journal = {North American NetFPGA Developers Workshop},
	Pages = {2--6},
	Publisher = {North American NetFPGA Developers Workshop},
	Title = {{Precise Latency Comparison Module for the NetFPGA Latency in a Time-Critical Network}}}

@article{Stonebraker2005,
	Abstract = {Applications that require real-time processing of high-volume data steams are pushing the limits of traditional data processing infrastructures. These stream-based applications include market feed processing and electronic trading on Wall Street, network and infrastructure monitoring, fraud detection, and command and control in military environments. Furthermore, as the ``sea change'' caused by cheap micro-sensor technology takes hold, we expect to see everything of material significance on the planet get ``sensor-tagged'' and report its state or location in real time. This sensorization of the real world will lead to a ``green field'' of novel monitoring and control applications with high-volume and low-latency processing requirements. Recently, several technologies have emerged---including off-the- shelf stream processing engines---specifically to address the challenges of processing high-volume, real-time data without requiring the use of custom code. At the same time, some existing software technologies, such as main memory DBMSs and rule engines, are also being ``repurposed'' by marketing departments to address these applications. In this paper, we outline eight requirements that a system should meet to excel at a variety of real-time stream processing applications. Our goal is to provide high-level guidance to information technologists so that they will know what to look for when evaluating alternative stream processing solutions. As such, this paper serves a purpose comparable to the requirements papers in relational DBMSs and on-line analytical processing. We also briefly review alternative software technologies in the context of our requirements. The paper attempts to be vendor neutral, so no commercial products are mentioned. 1. INTRODUCTION On Wall Street and other global exch},
	Author = {Stonebraker, Michael and \c{C}etintemel, U{\v g}ur and Zdonik, Stan},
	Doi = {10.1145/1107499.1107504},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/8rulesSigRec.pdf:pdf},
	Issn = {01635808},
	Journal = {ACM SIGMOD Record},
	Month = dec,
	Number = {4},
	Pages = {42--47},
	Title = {{The 8 requirements of real-time stream processing}},
	Url = {http://portal.acm.org/citation.cfm?doid=1107499.1107504},
	Volume = {34},
	Year = {2005},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1107499.1107504},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1107499.1107504}}

@unpublished{Semi2009,
	Abstract = {Achronix are the world's fastest programmable logic devices, with up to 1.5 GHz fabric performance --- suitable for a wide range of uses in networking, telecommunica- tions, video, digital signal processing, high-performance computing, imaging, industrial and military applications.},
	Author = {Semi, Archronix},
	Booktitle = {Archronix Semi},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Speedster-Plug-In\_Card\_SPC60\_Product\_Brief.pdf:pdf},
	Pages = {5--6},
	Title = {{Speedster{\textregistered} Plug-In Card --- SPC60}},
	Year = {2009}}

@inproceedings{Kachris2010a,
	Abstract = {One of the main challenges in the multi-core area is the communication and synchronization of the cores and the design of an efficient interconnection network that is scalable to multiple cores. In this paper we present an efficient implementation of a scalable system that is targeting multi- core systems. Each cluster node consists of 4 processors that support both explicit and implicit communication. Processor's cache is augmented with scratchpad and is merged with the network interface (NI) for reduced communication latency. All nodes are connected through a novel layer-2 switch that can support up to 20 nodes. The proposed system is designed and implemented using multiple FPGA boards and the performance evaluation presents the aggregate throughput of the system (with 16 processors) and the communication latency between that cluster nodes.},
	Annote = {        From Duplicate 1 (                   Low-latency explicit communication and synchronization in scalable multi-core clusters                 - Kachris, Christoforos; Nikiforos, George; Papaefstathiou, Vassilis; Yang, X.; Kavadias, S.; Katevenis, M. )
                
        
        
        From Duplicate 2 (                   Low-latency explicit communication and synchronization in scalable multi-core clusters                 - Kachris, Christoforos; Nikiforos, George; Papaefstathiou, Vassilis; Yang, X.; Kavadias, S.; Katevenis, M. )
                
        From Duplicate 1 (                   Low-latency explicit communication and synchronization in scalable multi-core clusters                 - Kachris, Christoforos; Nikiforos, George; Papaefstathiou, Vassilis; Yang, X.; Kavadias, S.; Katevenis, M. )
                
        
        
        
        
      },
	Author = {Kachris, Christoforos and Nikiforos, George and Papaefstathiou, Vassilis and Yang, X. and Kavadias, S. and Katevenis, M.},
	Booktitle = {Cluster Computing Workshops and Posters (CLUSTER WORKSHOPS), 2010 IEEE International Conference on},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Kachris, Nikiforos, Papaefstathiou - Unknown - Low-latency Explicit Communication and Synchronization in Scalable Multi-core Clusters(2).pdf:pdf},
	Isbn = {9781424483969},
	Keywords = {communication,explicit and implicit,fpgas,merged cache-network interface,multi-cores systems},
	Pages = {1--4},
	Publisher = {IEEE},
	Title = {{Low-latency explicit communication and synchronization in scalable multi-core clusters}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5613092},
	Year = {2010},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=5613092}}

@unpublished{Freescale2012a,
	Author = {Freescale},
	Booktitle = {Freescale},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/T4240T4160FS.pdf:pdf},
	Title = {{QorIQ AMP Series T4240/T4160 Processors}},
	Year = {2012}}

@article{Hurwitz2004,
	Author = {Hurwitz, J},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/01268985.pdf:pdf},
	Journal = {Micro, IEEE},
	Pages = {10--22},
	Title = {{End-to-end performance of 10-gigabit Ethernet on commodity systems}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1268985},
	Year = {2004},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=1268985}}

@article{Memory2006,
	Author = {Memory, Local and Lameter, Christoph},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/numamemory.pdf:pdf},
	Pages = {1--25},
	Title = {{Local and Remote Memory : Memory in a Linux / NUMA System}},
	Year = {2006}}

@article{Perche2010,
	Author = {Perche, Patrice},
	Doi = {10.1016/S1353-4858(10)70125-2},
	Issn = {13534858},
	Journal = {Network Security},
	Number = {10},
	Pages = {9--12},
	Publisher = {Elsevier Ltd},
	Title = {{Network latency : avoid paying a tax on time}},
	Url = {http://dx.doi.org/10.1016/S1353-4858(10)70125-2},
	Volume = {2010},
	Year = {2010},
	Bdsk-Url-1 = {http://dx.doi.org/10.1016/S1353-4858(10)70125-2}}

@article{Lamport1978,
	Author = {Lamport, Leslie},
	Doi = {10.1145/359545.359563},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/time-clocks.pdf:pdf},
	Issn = {00010782},
	Journal = {Communications of the ACM},
	Keywords = {and phrases,clock synchronization,computer networks,distributed systems,multiprocess},
	Month = jul,
	Number = {7},
	Pages = {558--565},
	Title = {{Time, clocks, and the ordering of events in a distributed system}},
	Url = {http://portal.acm.org/citation.cfm?doid=359545.359563},
	Volume = {21},
	Year = {1978},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=359545.359563},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/359545.359563}}

@article{Aberer2006,
	Abstract = {A key problem in current sensor network technology is the het- erogeneity of the available software and hardware platforms which makes deployment and application development a tedious and time consuming task. To minimize the unnecessary and repetitive im- plementation of identical functionalities for different platforms, we present our Global Sensor Networks (GSN) middleware which sup- ports the flexible integration and discovery of sensor networks and sensor data, enables fast deployment and addition of newplatforms, provides distributed querying, filtering, and combination of sen- sor data, and supports the dynamic adaption of the system con- figuration during operation. GSN's central concept is the virtual sensor abstraction which enables the user to declaratively specify XML-based deployment descriptors in combination with the pos- sibility to integrate sensor network data through plain SQL queries over local and remote sensor data sources. In this demonstration, we specifically focus on the deployment aspects and allow users to dynamically reconfigure the running system, to add new sensor networks on the fly, and to monitor the effects of the changes via a graphical interface. The GSN implementation is available from http://globalsn.sourceforge.net/.},
	Author = {Aberer, Karl and Hauswirth, Manfred and Salehi, Ali},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p1199-aberer.pdf:pdf},
	Isbn = {1595933859},
	Journal = {conference on Very large data bases},
	Pages = {1199--1202},
	Publisher = {VLDB Endowment},
	Title = {{A middleware for fast and flexible sensor network deployment}},
	Url = {http://dl.acm.org/citation.cfm?id=1164243},
	Year = {2006},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1164243}}

@article{Shen,
	Author = {Shen, Yanming and Chao, H Jonathan},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Some Unsolved Problems in High Speed Packet Switching (2).pdf:pdf},
	Title = {{Some Unsolved Problems in High Speed Packet Swtiching `` Follow the money '' -- Deep Throat}}}

@article{Arlos2007a,
	Author = {Arlos, Patrik and Fiedler, Markus},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Arlos, Fiedler - 2007 - A Method to Estimate the Timestamp Accuracy.pdf:pdf},
	Pages = {197--206},
	Title = {{A Method to Estimate the Timestamp Accuracy}},
	Year = {2007}}

@article{Cardwell2000,
	Abstract = {Several analytic models describe the steady-state throughput of bulk transfer TCP flows as a function of round trip time and packet loss rate. These models describe flows based on the assumption that they are long enough to sustain many packet losses. However, most TCP transfers across today's Internet are short enough to see few, if any, losses and consequently their performance is dominated by startup effects such as connection establishment and slow start. This paper extends the steady-state model proposed in Padhye et al. (1998), in order to capture these startup effects. The extended model characterizes the expected value and distribution of TCP connection establishment and data transfer latency as a function of transfer size, round trip time, and packet loss rate. Using simulations, controlled measurements of TCP transfers, and live Web measurements we show that, unlike earlier steady-state models for TCP performance, our extended model describes connection establishment and data transfer latency under a range of packet loss conditions, including no loss},
	Author = {Cardwell, Neal and Savage, Stefan and Anderson, Thomas},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/00832574.pdf:pdf},
	Isbn = {0780358805},
	Journal = {Network},
	Pages = {1742--1751},
	Title = {{Modeling TCP latency}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=832574},
	Volume = {00},
	Year = {2000},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=832574}}

@article{Jamrozik1996,
	Abstract = {New high-speed networks greatly encourage the use of network memory as a cache for virtual memory and file pages, thereby reducing the need for disk access. Because pages are the fundamental transfer and access units in remote memory systems, page size is a key performance factor. Recently, page sizes of modern processors have been increasing in order to provide more TLB coverage and amortize disk access costs. Unfortunately, for high-speed networks, small transfers are needed to provide low latency. This trend in page size is thus at odds with the use of network memory on high-speed networks.This paper studies the use of subpages as a means of reducing transfer size and latency in a remote-memory environment. Using trace-driven simulation, we show how and why subpages reduce latency and improve performance of programs using network memory. Our results show that memory-intensive applications execute up to 1.8 times faster when executing with 1K-byte subpages, when compared to the same applications using full 8K-byte pages in the global memory system. Those same applications using 1K-byte subpages execute up to 4 times faster than they would using the disk for backing store. Using a prototype implementation on the DEC Alpha and AN2 network, we demonstrate how subpages can reduce remote-memory fault time; e.g., our prototype is able to satisfy a fault on a 1K subpage stored in remote memory in 0.5 milliseconds, one third the time of a full page.},
	Author = {Jamrozik, Herv\'{e} A and Feeley, Michael J and Voelker, Geoffrey M and {Evans II}, James and Karlin, Anna R and Levy, Henry M and Vernon, Mary K},
	Isbn = {0897917677},
	Issn = {03621340},
	Journal = {SIGOPS Oper Syst Rev},
	Number = {5},
	Pages = {258--267},
	Publisher = {ACM},
	Series = {ASPLOS-VII},
	Title = {{Reducing network latency using subpages in a global memory environment}},
	Url = {http://doi.acm.org/10.1145/248208.237198},
	Volume = {30},
	Year = {1996},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/248208.237198}}

@article{Matz2010a,
	Author = {Matz, Michael and Hubiˇ, Jan and Jaeger, Andreas and Mitchell, Mark},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/abi.pdf:pdf},
	Title = {{System V Application Binary Interface}},
	Year = {2010}}

@misc{Brebner2011a,
	Author = {Brebner, Gordon},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Brebner - 2011 - Field Programmable Technology for Mainstream Processing(2).pdf:pdf},
	Number = {June},
	Pages = {1--28},
	Title = {{Field Programmable Technology for Mainstream Processing}},
	Year = {2011}}

@article{Gross1992,
	Author = {Gross, T and Hasegawa, A and Hinrichs, S},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/cmu-cs-92-215-impact-of-comm-styles.pdf:pdf},
	Number = {7330},
	Title = {{The impact of communication style on machine resource usage for the iWarp parallel processor}},
	Url = {http://oai.dtic.mil/oai/oai?verb=getRecord\&metadataPrefix=html\&identifier=ADA262425},
	Year = {1992},
	Bdsk-Url-1 = {http://oai.dtic.mil/oai/oai?verb=getRecord%5C&metadataPrefix=html%5C&identifier=ADA262425}}

@misc{Riddoch2009,
	Abstract = {Presentation Slides},
	Author = {Riddoch, David},
	Booktitle = {Solarflare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/STAC\_Solarflare\_1109.pdf:pdf},
	Pages = {10},
	Title = {{Solarstorm Ethernet Adapters}},
	Year = {2009}}

@inproceedings{Sadoghi2011a,
	Abstract = {We present fpga-ToPSS (Toronto Publish/Subscribe System), an efficient event processing platform to support high-frequency and low-latency event matching. fpga-ToPSS is built over reconfigurable hardware---FPGAs---to achieve line-rate processing by exploring various degrees of parallelism. Furthermore, each of our proposed FPGA-based designs is geared towards a unique application requirement, such as flexibility, adaptability, scalability, or pure performance, such that each solution is specifically optimized to attain a high level of parallelism. Therefore, each solution is formulated as a design trade-off between the degree of parallelism versus the desired application requirement. Moreover, our event processing engine supports Boolean expression matching with an expressive predicate language applicable to a wide range of applications including real-time data analysis, algorithmic trading, targeted advertisement, and (complex) event processing.},
	Author = {Sadoghi, Mohammad and Singh, Harsh and Jacobsen, Hans-arno},
	Booktitle = {DaMoN '11 Proceedings of the Seventh International Workshop on Data Management on New Hardware},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p27-sadoghi.pdf:pdf},
	Isbn = {9781450306584},
	Pages = {27--32},
	Title = {{Towards highly parallel event processing through reconfigurable hardware}},
	Url = {http://www.cse.ust.hk/damon2011/proceedings/p4-sadoghi.pdf},
	Year = {2011},
	Bdsk-Url-1 = {http://www.cse.ust.hk/damon2011/proceedings/p4-sadoghi.pdf}}

@inproceedings{Pratt2001,
	Author = {Pratt, Ian},
	Booktitle = {Proceedings of the Twentieth Annual Joint Conference of the IEEE Computer and Communications Societie INFOCOM01},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/00916688.pdf:pdf},
	Isbn = {0780370163},
	Title = {{Arsenic: A user-accessible gigabit ethernet interface}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=916688},
	Year = {2001},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=916688}}

@article{Hinrichs1994,
	Address = {New York, New York, USA},
	Author = {Hinrichs, Susan and Kosak, Corey and O'Hallaron, David R. and Stricker, Thomas M. and Take, Riichiro},
	Doi = {10.1145/181014.181427},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/spaa94-all-to-all-communication-arch copy.pdf:pdf},
	Isbn = {0897916719},
	Journal = {Proceedings of the sixth annual ACM symposium on Parallel algorithms and architectures - SPAA '94},
	Pages = {310--319},
	Publisher = {ACM Press},
	Title = {{An architecture for optimal all-to-all personalized communication}},
	Url = {http://portal.acm.org/citation.cfm?doid=181014.181427},
	Year = {1994},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=181014.181427},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/181014.181427}}

@unpublished{Netronome2009d,
	Abstract = {ISVs require a cost-effective way to offer their solutions across a variety of hardware platforms to support a broad range of target market segments and customer profiles, while simultaneously only developing a single application that scales across these platforms without modifica- tion. To support this family of products, ISV-developed network security appliances are deployed on standard Intel{\textregistered} Architecture (IA) servers, providing the best software architecture for application development and hosting with hardware platforms that meet the variety of customer requirements for price, performance and power. ISVs can offer accelerated platforms coupled with Intel{\textregistered} QuickAssist Technology without radically changing their application code across their entire range of hardware plat- forms, including low-end, single-core systems, emerging system-on-a-chip (SoC) devices, multi-core IA servers and multi- core IA platforms with hardware-based accelerators. A tight coupling of Intel{\textregistered} QuickAssist Technol- ogy and Netronome's hardware- and soft- ware-based accelera- tion technologies scales performance up to 10Gbps for networks with strin- gent performance requirements.},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome-Scaling Security Application Performance with Intel{\textregistered} QuickAssist Technology (3-09).pdf:pdf},
	Pages = {5},
	Title = {{Scaling Security Application Performance with Intel QuickAssist Technology}},
	Year = {2009}}

@article{Sadoghi2010,
	Abstract = {In this demo, we present fpga-ToPSS (Toronto Publish/Subscribe System Family), an efficient event processing platform for high- frequency and low-latency algorithmic trading. Our event process- ing platform is built over reconfigurable hardware---FPGAs---to achieve line-rate processing. Furthermore, our event processing engine supports Boolean expression matching with an expressive predicate language that models complex financial strategies to au- tonomously buy and sell stocks based on real-time financial data.},
	Annote = {
        From Duplicate 3 ( 
        
        
          Efficient event processing through reconfigurable hardware for algorithmic trading
        
        
         - Sadoghi, Mohammad; Labrecque, Martin; Singh, Harsh )

        
        

        

        

      },
	Author = {Sadoghi, Mohammad and Labrecque, Martin and Singh, Harsh and Shum, Warren and Jacobsen, Hans-arno},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p1525-sadoghi.pdf:pdf;:Users/mgrosvenor/Dropbox/PHD/Reading/moTrading-Efficient\_Event\_Processing\_through\_ copy.pdf:pdf},
	Journal = {Proceedings of the VLDB Endowment},
	Pages = {1525--1528},
	Title = {{Efficient event processing through reconfigurable hardware for algorithmic trading}},
	Url = {http://dl.acm.org/citation.cfm?id=1921029},
	Year = {2010},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1921029}}

@unpublished{Tilera2012,
	Abstract = {The TILE-GxTM 8000 series offers high performance for both control plane and data plane processing making it ideal for high speed packet processing and line rate security applications. TileDirectTM technology provides coherent I/O directly into the tile caches to deliver ultimate low-latency packet processing performance. The extensive I/O options make getting data in to and out of the system a matter of preference, not a compromise due to system limitations.},
	Author = {Tilera},
	Booktitle = {Tilera},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/TILE-Gx 8000 Series Brief\_0.pdf:pdf},
	Pages = {2},
	Title = {{TILE-Gx {\texttrademark} 8000 Series Processor}},
	Year = {2012}}

@article{Cummings2009a,
	Abstract = {The convergence of different types of networks into a common data center infrastructure poses a superset chal- lenge on the part of the underlying component technology. IP networks are feature-rich, storage networks are lossless with controlled topologies, and transaction networks are low-latency with low jitter, parallel multicast. A success- ful Converged Enhanced Ethernet (CEE) switch should pass the domain specific network tests, and demonstrate these disparate capabilities at the same time, while maintaining traffic separation. The FocalPoint FM4000 Ethernet switch chip was de- signed and architected both to provide a rich Ethernet fea- ture set and maintain the highest performance around cor- ner cases. It achieves this through the use of a full-rate shared memory, parallel multicasting, switch architecture along with deeply pipelined frame processing. It imple- ments traditional Ethernet, layer-3/4, and the new CEE fea- tures. In this, paper we provide an extensive performance evaluation of the FocalPoint FM4000 chip with a number of individual performance tests including, port-to-port line rate and latency, fairness of flow control under N-to-1 hot- spot, and multicast line rate and latency tests. Finally, we explore the convergence by measuring the simultane- ous performance of prioritized, flow-controlled unicast traf- fic and provisioned multicast traffic against the backdrop of full-rate best effort stressing traffic. The experimental results show that the FocalPoint FM4000 switch provides an impressive flow-through la- tency of only 300 nanoseconds, which is insensitive to the packet size. The FM4000 delivers optimal performance un- der hot-spot communication with a degree of fairness above 98\%, and provides an upper bound for latency in prioritized multicast, ranging from 1.2 to 4.3 microseconds, depending on the average size of the background best-effort traffic. A direct comparison with non-prioritized multicasts, shows a performance speedup ranging from 29 to 38 times.},
	Author = {Cummings, Uri and Daly, Dan and Collins, Rebecca and Agarwal, Virat and Petrini, Fabrizio and Perrone, Michael and Pasetto, Davide},
	Doi = {10.1109/HOTI.2009.22},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Cummings et al. - 2009 - Fulcrum's FocalPoint FM4000 A Scalable, Low-Latency 10GigE Switch for High-Performance Data Centers(2).pdf:pdf},
	Journal = {2009 17th IEEE Symposium on High Performance Interconnects},
	Month = aug,
	Pages = {42--51},
	Publisher = {Ieee},
	Title = {{Fulcrum's FocalPoint FM4000: A Scalable, Low-Latency 10GigE Switch for High-Performance Data Centers}},
	Url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5238683},
	Year = {2009},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5238683},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/HOTI.2009.22}}

@article{Clark1989,
	Author = {Clark, David D and Romkey, John and Salwen, Howard},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/00029545.pdf:pdf},
	Journal = {IEEE Communications Magazine},
	Pages = {23--29},
	Title = {{An Analysis of TCP Processing Overhead}},
	Year = {1989}}

@article{Al-Fares2010a,
	Author = {Al-Fares, M and Radhakrishnan, S},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Al-fares - Unknown - Hedera Dynamic Flow Scheduling for Data Center Networks.pdf:pdf},
	Journal = {Proceedings of the \ldots},
	Title = {{Hedera: Dynamic flow scheduling for data center networks}},
	Url = {http://static.usenix.org/event/nsdi10/tech/full\_papers/al-fares.pdf},
	Year = {2010},
	Bdsk-Url-1 = {http://static.usenix.org/event/nsdi10/tech/full%5C_papers/al-fares.pdf}}

@inproceedings{Yocum1997,
	Abstract = {New network technology continues to improve both the latency and bandwidth of communication in com- puter clusters. The fastest high-speed networks ap- proach or exceed the I/O bus bandwidths of ``gigabit- ready'' hosts. These advances introduce new considera- tionsf o r the design of network interfaces and messaging systems f o r low-latency communication. This paper investigates cut-through delivery, a tech- nique f o r overlapping host I/O DMA transfers with net- work traversal. Cut-through delivery signijicantly re- duces end-to-end latency of large messages, which are often critical f o r application performance. We have implemented cut-through delivery in Trapeze, a new messaging substrate f o r network mem- ory and other distributed operating system services. Our current Trapeze prototype is capable of demand-fetching 8K virtual memory pages in 2 0 0 p across a Myrinet cluster of DEC AlphaStations.},
	Annote = {
        From Duplicate 1 ( 
        
        
          Cut-through delivery in Trapeze: An exercise in low-latency messaging
        
        
         - Yocum, K.G.; Chase, J.S.; Gallatin, A.J.; Lebeck, A.R. )

        
        

        

        

        From Duplicate 2 ( 
        
        
          Cut-through delivery in Trapeze: An exercise in low-latency messaging
        
        
         - Yocum, K.G.; Chase, J.S.; Gallatin, A.J.; Lebeck, A.R. )

        
        

        From Duplicate 1 ( 
        
        
          Cut-through delivery in Trapeze: An exercise in low-latency messaging
        
        
         - Yocum, K.G.; Chase, J.S.; Gallatin, A.J.; Lebeck, A.R. )

        
        

        

        

        

        

      },
	Author = {Yocum, K.G. and Chase, J.S. and Gallatin, A.J. and Lebeck, A.R.},
	Booktitle = {High Performance Distributed Computing, 1997. Proceedings. The Sixth IEEE International Symposium on},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Yocum et al. - 1997 - Cut-Through Delivery in Trapeze An Exercise in Low-Latency Messaging.pdf:pdf},
	Pages = {243--252},
	Publisher = {IEEE},
	Title = {{Cut-through delivery in Trapeze: An exercise in low-latency messaging}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=626425},
	Year = {1997},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=626425}}

@unpublished{Solarflare2012c,
	Abstract = {The Solarflare{\textregistered} SFN5122F dual-port 10G Ethernet SFP+ enterprise server adapter delivers the industry's best application performance, lowest power consumption, and most scalable virtualization, enabling unmatched performance and scalability for enterprise data centers.},
	Author = {Solarflare},
	Booktitle = {Solarlfare},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_SFN5122F\_10GbE\_Adapter\_Brief.pdf:pdf;:Users/mgrosvenor/Dropbox/PHD/Reading/Solarflare\_SFN6122F\_10GbE\_Adapter\_Brief.pdf:pdf},
	Pages = {2},
	Title = {{Dual-Port 10GbE Enterprise Server Adapter SFN5122F}},
	Year = {2012}}

@article{Schuff2007a,
	Abstract = {Programmable network interfaces can provide network servers with a flexible inter- face to high-bandwidth Ethernet links, but they face critical software and architec- tural challenges. This article explores architectural and software support for an efficient programmable 10 Gigabit Ethernet controller. The design is then extended to support a self-securing Gigabit Ethernet controller that performs intrusion detec- tion on all network data frames. Both raw performance and security require high- bitrate frame data transfer, low-latency metadata access, and intensive computational capacity while still operating under the area, cost, and power bud- get of a peripheral device. These goals are achieved using a combination of paral- lel lightweight processing cores, an explicitly-partitioned memory system, and dedicated hardware assists. The firmware on the network interface is designed to utilize these resources efficiently by exploiting frame-level, flow-level, and task-level concurrency.},
	Annote = {
        From Duplicate 1 ( 
        
          Parallel Programmable Ethernet Controllers: Performance and Security
        
         - Schuff, Derek L; Pai, Vijay S; Willmann, Paul; Rixner, Scott )

        
        

        

        

      },
	Author = {Schuff, Derek L and Pai, Vijay S and Willmann, Paul and Rixner, Scott},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/04277245.pdf:pdf},
	Journal = {Ieee Network},
	Number = {August},
	Pages = {22--28},
	Title = {{Parallel Programmable Ethernet Controllers: Performance and Security}},
	Year = {2007}}

@book{Lin1997,
	Author = {Lin, Steven and McKeown, N},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p15-lin.pdf:pdf},
	Isbn = {089791905X},
	Title = {{A simulation study of IP switching}},
	Url = {http://dl.acm.org/citation.cfm?id=263135},
	Year = {1997},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=263135}}

@article{Binkert,
	Author = {Binkert, Nathan L and Hsu, Lisa R and Saidi, Ali G and Dreslinski, Ronald G and Schultz, Andrew L and Reinhardt, Steven K},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/caecw05.pdf:pdf},
	Number = {Figure 1},
	Pages = {4--11},
	Title = {{Analyzing NIC Overheads in Network-Intensive Workloads}}}

@article{Vattikonda2012,
	Address = {New York, New York, USA},
	Author = {Vattikonda, Bhanu Chandra and Porter, George and Vahdat, Amin and Snoeren, Alex C.},
	Doi = {10.1145/2168836.2168859},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/tdma-eurosys12.pdf:pdf},
	Isbn = {9781450312233},
	Journal = {Proceedings of the 7th ACM european conference on Computer Systems - EuroSys '12},
	Keywords = {experimenta-,measurement,performance},
	Pages = {225},
	Publisher = {ACM Press},
	Title = {{Practical TDMA for datacenter ethernet}},
	Url = {http://dl.acm.org/citation.cfm?doid=2168836.2168859},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?doid=2168836.2168859},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2168836.2168859}}

@article{Lu,
	Author = {Lu, Guohan and Guo, Chuanxiong and Li, Yulong and Zhou, Zhiqiang},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/serverswitch-msr-tr11-3.pdf:pdf},
	Title = {{ServerSwitch : A Programmable and High Performance Platform for Data Center Networks}}}

@unpublished{Kane2011,
	Abstract = {The Impulse financial feed handling platform is a low latency system that allows financial organisations to utilize their own trading strategies on a customizable hardware platform. The Impulse system carries no monthly lease costs or run time royalty fees. Users are free to scale this system as needed within their organization. And they are free to modify their strategy without releasing proprietary data outside their organization or paying professional services fees.},
	Author = {Kane, Computing and Technologies, Impulse Accelerated},
	Booktitle = {Computing},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Financial, Handler - 2011 - Press Release Press Release(2).pdf:pdf},
	Number = {January},
	Pages = {2},
	Title = {{Customizable, FPGA-enabled, low latency system with redistributable IP}},
	Year = {2011}}

@article{Sharma2006,
	Abstract = {Network proximity and latency estimation is an important component in discovering and locating services and applications. With the growing number of services and service providers in the large-scale Internet, accurately estimating network proximity/latency with minimal probing overhead becomes essential for scalable deployment. Although there exist a number of network distance estimation schemes, they either rely on extensive infrastructure support, require the IP address of the potential targets, falsely cluster distant nodes, or perform poorly with even few measurement errors. We propose Netvigator, a scalable network proximity and latency estimation tool that uses information obtained from probing a small number of landmark nodes and intermediate routers (termed milestones) that are discovered en route to the landmarks, to identify the closest nodes. With very little additional probing overhead, Netvigator uses distance information to the milestones to accurately locate the closest nodes. We developed a Netvigator prototype and report our performance evaluation on PlanetLab and in the intranet of a large enterprise. Netvigator is a running service on PlanetLab as a part of HP Labs' S-3 (Scalable Sensing Service).},
	Author = {Sharma, Puneet and Xu, Zhichen and Banerjee, Sujata and Lee, Sung-Ju},
	Doi = {10.1145/1140086.1140092},
	Issn = {01464833},
	Journal = {ACM SIGCOMM Computer Communication Review},
	Number = {3},
	Pages = {39},
	Publisher = {ACM},
	Title = {{Estimating network proximity and latency}},
	Url = {http://doi.acm.org/10.1145/1140086.1140092},
	Volume = {36},
	Year = {2006},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1140086.1140092},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1140086.1140092}}

@inproceedings{Willmann2005,
	Abstract = {This paper explores the hardware and software mech- anisms necessary for an efficient programmable 10 Giga- bit Ethernet network interface card. Network interface pro- cessing requires support for the following characteristics: a large volume of frame data, frequently accessed frame metadata, and high frame rate processing. This paper pro- poses three mechanisms to improve programmable network interface efficiency. First, a partitioned memory organiza- tion enables low-latency access to control data and high- bandwidth access to frame contents from a high-capacity memory. Second, a novel distributed task-queue mecha- nism enables parallelization of frame processing across many low-frequency cores, while using software to main- tain total frame ordering. Finally, the addition of two new atomic read-modify-write instructions reduces frame order- ing overheads by 50\%. Combining these hardware and soft- ware mechanisms enables a network interface card to satu- rate a full-duplex 10 Gb/s Ethernet link by utilizing 6 pro- cessor cores and 4 banks of on-chip SRAM operating at 166 MHz, along with external 500 MHz GDDR SDRAM.},
	Author = {Willmann, Paul and Kim, H. and Rixner, S. and Pai, V.S.},
	Booktitle = {High-Performance Computer Architecture, 2005. HPCA-11. 11th International Symposium on},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Willmann et al. - 2005 - An efficient programmable 10 gigabit Ethernet network interface card.pdf:pdf},
	Pages = {96--107},
	Publisher = {IEEE},
	Title = {{An efficient programmable 10 gigabit Ethernet network interface card}},
	Url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1385932},
	Year = {2005},
	Bdsk-Url-1 = {http://ieeexplore.ieee.org/xpls/abs%5C_all.jsp?arnumber=1385932}}

@unpublished{Netronome2009e,
	Abstract = {In a short time, network infrastructure bandwidth has scaled exponentially to 10Gbps with designs for the next generation of Ethernet promising between 40Gbps to 100Gbps. At the same time, the complexity and breadth of applications that run over these backbones are drastically changing. Accordingly, to accommodate the ever- increasing need for network security, control and visibility that is required for network traffic, communications equipment needs to be protocol-, content- and application-aware at increasingly higher and higher speeds},
	Author = {Netronome},
	Booktitle = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/The Depths of Netronome DPI (3-09).pdf:pdf},
	Pages = {4},
	Title = {{The Depths of Netronome Deep Packet Inspection}},
	Year = {2009}}

@inproceedings{Attig2009,
	Abstract = {The NetFPGA platform enables users to build working pro- totypes of high-speed, hardware-acceleratednetworking sys- tems. However, one roadblock is that a typical networking specialist with a software-side backgroundwill find the pro- gramming of the FPGA to be a challenge because of the need for hardware design and description skills. This pa- per introduces G, which is a high-level packet-centric lan- guage for describing packet processing specifications in an implementation-independentmanner. This language can be compiled to give high-speed FPGA-based components. An extension has been produced that allows these components to be dropped easily into the data path of the standard NetF- PGA framework. This allows a user to write and debug packet processing functions at a high-level in G, and then use these on the NetFPGA alongside other components de- signed in the traditional way.},
	Author = {Attig, Michael and Brebner, Gordon},
	Booktitle = {NetFPGA Developers Workshop},
	File = {:Users/mgrosvenor/Library/Application Support/Mendeley Desktop/Downloaded/Attig, Brebner - Unknown - High-level programming of the FPGA on NetFPGA(2).pdf:pdf},
	Title = {{High-level programming of the FPGA on NetFPGA}},
	Url = {http://www.altusfidelitas.org/publications/NetFPGA\_Developers\_Workshop\_2009\_Proceedings.pdf\#page=50},
	Year = {2009},
	Bdsk-Url-1 = {http://www.altusfidelitas.org/publications/NetFPGA%5C_Developers%5C_Workshop%5C_2009%5C_Proceedings.pdf%5C#page=50}}

@unpublished{Melanox2012a,
	Abstract = {Cloud computing is a collection of technologies and practices used to abstract the provisioning and management of computer hardware. The goal is to simplify the users experience so they can get the benefit of compute resources on demand; or in the language of cloud computing ``as a service''. The resources that comprise an individual cloud are generally made available to end users using an interface that conforms to one of three levels of abstractions. From most granular to most abstract these are Infrastructure-as-a-Service (Iaas), Platform-as-a-Service (PaaS) and Software-as-a-Service (SaaS).},
	Author = {Melanox},
	Booktitle = {Melanox Technologies},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/WP\_Cloud\_Computing.pdf:pdf},
	Pages = {1--5},
	Title = {{Introduction to Cloud Design}},
	Year = {2012}}

@unpublished{Melanox,
	Abstract = {With the recent release of TIBCO FTL TM, TIBCO is once again changing the game when it comes to providing high performance messaging middleware. Many solutions have emerged to try and provide next generation systems with extreme low latency but they are doing this by sacrificing the traditional features and functions that mission critical middleware solutions require. TIBCO's approach is to offer a middleware solution that offers extreme low latency without sacrifice, allowing for the scalability not only to meet the demands for low latency data distribution but also to meet the demands as the application grows from a few instances to thousands of instances. In this report with the assistance of HP and Mellanox/Voltaire, TIBCO provides benchmarks using TIBCO FTL 1.0 across a number of physical transports to show the latency, average latency for a given transport. In addition TIBCO is showing how variable message size has minimal impact on the latency metrics depending on what transport is being used. The goal of this report is not to show all the different use case, as there are other benchmarks that provide these types of reports. For this report TIBCO, HP and Mellanox/Voltaire wanted to show the performance benefits of the end-to-end solution and give a general overview of how infrastructure and data distribution decisions can impact overall latency. The final results of these test show that in all categories using TIBCO FTL, HP DL380 G7 systems and network equipment for Mellanox/Voltaire, customers can get the lowest latency data distribution.},
	Author = {Melanox},
	Booktitle = {Melanox},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/FTL-HP-Mellanox.pdf:pdf},
	Pages = {19},
	Title = {{TIBCO , HP and Mellanox High Performance Extreme Low Latency Messaging}},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUIJidUJHRvcFgkb2JqZWN0c1gkdmVyc2lvblkkYXJjaGl2ZXLRBgdUcm9vdIABqAkKFRYXGyIjVSRudWxs0wsMDQ4RElpOUy5vYmplY3RzViRjbGFzc1dOUy5rZXlzog8QgASABoAHohMUgAKAA1lhbGlhc0RhdGFccmVsYXRpdmVQYXRo0hgMGRpXTlMuZGF0YU8RAb4AAAAAAb4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAMo8fxNIKwAAAAXNFBVDb25uZWN0WDNfRU5fQ2FyZC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADtf61zL1odwAAAAAAAAAAAAIABAAACSAAAAAAAAAAAAAAAAAAAAAHUmVhZGluZwAAEAAIAADKPHEDAAAAEQAIAADMvWh3AAAAAQAUAAXNFAA6vWoAG4N0AAXGbAAAvzEAAgBMTWFjaW50b3NoIEhEOlVzZXJzOgBtZ3Jvc3Zlbm9yOgBEcm9wYm94OgBQSEQ6AFJlYWRpbmc6AENvbm5lY3RYM19FTl9DYXJkLnBkZgAOACwAFQBDAG8AbgBuAGUAYwB0AFgAMwBfAEUATgBfAEMAYQByAGQALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADpVc2Vycy9tZ3Jvc3Zlbm9yL0Ryb3Bib3gvUEhEL1JlYWRpbmcvQ29ubmVjdFgzX0VOX0NhcmQucGRmABMAAS8AABUAAgAR//8AAIAF0hwdHh9YJGNsYXNzZXNaJGNsYXNzbmFtZaMfICFdTlNNdXRhYmxlRGF0YVZOU0RhdGFYTlNPYmplY3RfEC8uLi8uLi9Ecm9wYm94L1BIRC9SZWFkaW5nL0Nvbm5lY3RYM19FTl9DYXJkLnBkZtIcHSQloiUhXE5TRGljdGlvbmFyeRIAAYagXxAPTlNLZXllZEFyY2hpdmVyAAgAEQAWAB8AKAAyADUAOgA8AEUASwBSAF0AZABsAG8AcQBzAHUAeAB6AHwAhgCTAJgAoAJiAmQCaQJyAn0CgQKPApYCnwLRAtYC2QLmAusAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAAC/Q==}}

@misc{Microsystems,
	Author = {Microsystems, Netlogic},
	Title = {{Multi-Core, Multi-Thread Superscalar Communication Processor}},
	Url = {http://www.netlogicmicro.com/Products/ProductBriefs/MultiCore/XLP832.htm},
	Bdsk-Url-1 = {http://www.netlogicmicro.com/Products/ProductBriefs/MultiCore/XLP832.htm}}

@article{Patterson2004a,
	Author = {Patterson, David a.},
	Doi = {10.1145/1022594.1022596},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/p71-patterson.pdf:pdf},
	Issn = {00010782},
	Journal = {Communications of the ACM},
	Month = oct,
	Number = {10},
	Pages = {71--75},
	Title = {{Latency lags bandwith}},
	Url = {http://portal.acm.org/citation.cfm?doid=1022594.1022596},
	Volume = {47},
	Year = {2004},
	Bdsk-Url-1 = {http://portal.acm.org/citation.cfm?doid=1022594.1022596},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1022594.1022596}}

@unpublished{Netronome,
	Abstract = {Today's network and computing infra- structure is of critical interest to all aspects of our lives, from business and commerce to personal entertainment, and even national security. These vital communication systems share a couple of important characteristics: they require massive amounts of bandwidth to support our insatiable appetite for IP-based services and they require mechanisms offering visibility into all data protocol and application layers to ensure network security. Unfortunately, the network appliances commonly hosting security applications have failed to keep pace with improvements in network performance. However, a new heterogeneous multi- core processing architecture can scale to support tomorrow's throughput needs while providing the ability to see deeply into network traffic.},
	Author = {Netronome},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/Netronome\_Developing High-performance Embedded Network Security Applications White Paper\_4-11.pdf:pdf},
	Title = {{Developing Embedded Network Security Applications}}}

@unpublished{Networks2011,
	Abstract = {The new Cavium 10 Gigabit Ethernet Intelligent Network Adapter family targets Secure Network Services, iSCSI, FCoE and compression acceleration in Appliances, Blade Servers and Storage systems with up to 10 Gbps performance. This family includes 2 different product lines, one supporting PCI-X connectivity and the other supporting PCI-Express. Additionally, these adapters include hardware offload for TCP, compression/decompression, security (SSL/IPsec, SRTP, Data-at-rest), firewall, intrusion prevention, anti-virus applications, FCoE and iSCSI -- to deliver the most advanced, multi-function acceleration. Optional C/C++ programmability on the card allows vendors to easily add proprietary features in a field upgradeable manner.},
	Author = {Networks, Cavium},
	Booktitle = {Cavium Networks},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/INA\_Product\_Brief\_rev1.pdf:pdf},
	Pages = {2},
	Title = {{Cavium 10 Gigabit Ethernet Intelligent Network Adapter Family Cavium 10 Gigabit Ethernet Intelligent Network Adapter Family}},
	Year = {2011}}

@article{Iyer2003,
	Author = {Iyer, Sundar and Member, Associate and Mckeown, Nick W and Member, Senior},
	File = {:Users/mgrosvenor/Dropbox/PHD/Reading/01194826.pdf:pdf},
	Number = {2},
	Pages = {314--324},
	Title = {{Analysis of the Parallel Packet Switch Architecture}},
	Volume = {11},
	Year = {2003}}

@inproceedings{Wang:2010:CPO:1851182.1851222,
	Acmid = {1851222},
	Address = {New York, NY, USA},
	Author = {Wang, Guohui and Andersen, David G. and Kaminsky, Michael and Papagiannaki, Konstantina and Ng, T.S. Eugene and Kozuch, Michael and Ryan, Michael},
	Booktitle = {Proceedings of the ACM SIGCOMM 2010 conference},
	Doi = {10.1145/1851182.1851222},
	Isbn = {978-1-4503-0201-2},
	Keywords = {data center networking, hybrid network, optical circuit switching},
	Location = {New Delhi, India},
	Numpages = {12},
	Pages = {327--338},
	Publisher = {ACM},
	Series = {SIGCOMM '10},
	Title = {c-Through: part-time optics in data centers},
	Url = {http://doi.acm.org/10.1145/1851182.1851222},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1851182.1851222},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1851182.1851222}}

@inproceedings{Ballani:2011:TPD:2018436.2018465,
	Acmid = {2018465},
	Address = {New York, NY, USA},
	Author = {Ballani, Hitesh and Costa, Paolo and Karagiannis, Thomas and Rowstron, Ant},
	Booktitle = {Proceedings of the ACM SIGCOMM 2011 conference},
	Doi = {10.1145/2018436.2018465},
	Isbn = {978-1-4503-0797-0},
	Keywords = {allocation, bandwidth, datacenter, virtual network},
	Location = {Toronto, Ontario, Canada},
	Numpages = {12},
	Pages = {242--253},
	Publisher = {ACM},
	Series = {SIGCOMM '11},
	Title = {Towards predictable datacenter networks},
	Url = {http://doi.acm.org/10.1145/2018436.2018465},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2018436.2018465},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2018436.2018465}}

@inproceedings{Farrington:2010:HHE:51182.1851223,
	Acmid = {1851223},
	Address = {New York, NY, USA},
	Author = {Farrington, Nathan and Porter, George and Radhakrishnan, Sivasankar and Bazzaz, Hamid Hajabdolali and Subramanya, Vikram and Fainman, Yeshaiahu and Papen, George and Vahdat, Amin},
	Booktitle = {Proceedings of the ACM SIGCOMM 2010 conference},
	Date-Modified = {2012-11-05 15:18:18 +0000},
	Doi = {10.1145/1851182.1851223},
	Isbn = {978-1-4503-0201-2},
	Keywords = {data center networks, optical networks},
	Location = {New Delhi, India},
	Numpages = {12},
	Pages = {339--350},
	Publisher = {ACM},
	Series = {SIGCOMM '10},
	Title = {Helios: a hybrid electrical/optical switch architecture for modular data centers},
	Url = {http://doi.acm.org/10.1145/1851182.1851223},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1851182.1851223},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1851182.1851223}}

@inproceedings{Abu-Libdeh:2010,
	Acmid = {1851191},
	Address = {New York, NY, USA},
	Author = {Abu-Libdeh, Hussam and Costa, Paolo and Rowstron, Antony and O'Shea, Greg and Donnelly, Austin},
	Booktitle = {Proceedings of the ACM SIGCOMM 2010 conference},
	Date-Modified = {2012-11-05 15:14:53 +0000},
	Doi = {10.1145/1851182.1851191},
	Isbn = {978-1-4503-0201-2},
	Keywords = {data centers, key-value stores, routing protocols},
	Location = {New Delhi, India},
	Numpages = {12},
	Pages = {51--62},
	Publisher = {ACM},
	Series = {SIGCOMM '10},
	Title = {Symbiotic routing in future data centers},
	Url = {http://doi.acm.org/10.1145/1851182.1851191},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1851182.1851191},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1851182.1851191}}

@inproceedings{Greenberg:2009:VSF:92568.1592576,
	Acmid = {1592576},
	Address = {New York, NY, USA},
	Author = {Greenberg, Albert and Hamilton, James R. and Jain, Navendu and Kandula, Srikanth and Kim, Changhoon and Lahiri, Parantap and Maltz, David A. and Patel, Parveen and Sengupta, Sudipta},
	Booktitle = {Proceedings of the ACM SIGCOMM 2009 conference on Data communication},
	Date-Modified = {2012-11-05 15:17:35 +0000},
	Doi = {10.1145/1592568.1592576},
	Isbn = {978-1-60558-594-9},
	Keywords = {commoditization, data center network},
	Location = {Barcelona, Spain},
	Numpages = {12},
	Pages = {51--62},
	Publisher = {ACM},
	Series = {SIGCOMM '09},
	Title = {VL2: a scalable and flexible data center network},
	Url = {http://doi.acm.org/10.1145/1592568.1592576},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1592568.1592576},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1592568.1592576}}

@inproceedings{Costa:2012:CEI:2228298.2228302,
	Acmid = {2228302},
	Address = {Berkeley, CA, USA},
	Author = {Costa, Paolo and Donnelly, Austin and Rowstron, Antony and O'Shea, Greg},
	Booktitle = {Proceedings of the 9th USENIX conference on Networked Systems Design and Implementation},
	Location = {San Jose, CA},
	Numpages = {1},
	Pages = {3--3},
	Publisher = {USENIX Association},
	Series = {NSDI'12},
	Title = {Camdoop: exploiting in-network aggregation for big data applications},
	Url = {http://dl.acm.org/citation.cfm?id=2228298.2228302},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2228298.2228302}}

@inproceedings{Guo:2009:BHP:1592568.1592577,
	Acmid = {1592577},
	Author = {Guo, Chuanxiong and Lu, Guohan and Li, Dan and Wu, Haitao and Zhang, Xuan and Shi, Yunfeng and Tian, Chen and Zhang, Yongguang and Lu, Songwu},
	Booktitle = {Proceedings of SIGCOMM},
	Doi = {10.1145/1592568.1592577},
	Isbn = {978-1-60558-594-9},
	Keywords = {modular data center, multi-path, server-centric network},
	Numpages = {12},
	Pages = {63--74},
	Title = {{BCube: a high performance, server-centric network architecture for modular data centers}},
	Url = {http://doi.acm.org/10.1145/1592568.1592577},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1592568.1592577},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1592568.1592577}}

@inproceedings{NiranjanMysore:2009,
	Acmid = {1592575},
	Address = {New York, NY, USA},
	Author = {Niranjan Mysore, Radhika and Pamboris, Andreas and Farrington, Nathan and Huang, Nelson and Miri, Pardis and Radhakrishnan, Sivasankar and Subramanya, Vikram and Vahdat, Amin},
	Booktitle = {Proceedings of the ACM SIGCOMM 2009 conference on Data communication},
	Date-Modified = {2012-11-05 15:01:35 +0000},
	Doi = {10.1145/1592568.1592575},
	Isbn = {978-1-60558-594-9},
	Keywords = {data center network fabric, layer 2 routing in data centers},
	Location = {Barcelona, Spain},
	Numpages = {12},
	Pages = {39--50},
	Publisher = {ACM},
	Series = {SIGCOMM '09},
	Title = {PortLand: a scalable fault-tolerant layer 2 data center network fabric},
	Url = {http://doi.acm.org/10.1145/1592568.1592575},
	Year = {2009},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1592568.1592575},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1592568.1592575}}

@inproceedings{Guo:2008:DSF:1402958.1402968,
	Acmid = {1402968},
	Address = {New York, NY, USA},
	Author = {Guo, Chuanxiong and Wu, Haitao and Tan, Kun and Shi, Lei and Zhang, Yongguang and Lu, Songwu},
	Booktitle = {Proceedings of the ACM SIGCOMM 2008 conference on Data communication},
	Doi = {10.1145/1402958.1402968},
	Isbn = {978-1-60558-175-0},
	Keywords = {data center, fault-tolerance, network topology, throughput},
	Location = {Seattle, WA, USA},
	Numpages = {12},
	Pages = {75--86},
	Publisher = {ACM},
	Series = {SIGCOMM '08},
	Title = {Dcell: a scalable and fault-tolerant network structure for data centers},
	Url = {http://doi.acm.org/10.1145/1402958.1402968},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1402958.1402968},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1402958.1402968}}

@article{342015,
	Author = {Boden, N.J. and Cohen, D. and Felderman, R.E. and Kulawik, A.E. and Seitz, C.L. and Seizovic, J.N. and Wen-King Su},
	Doi = {10.1109/40.342015},
	Issn = {0272-1732},
	Journal = {Micro, IEEE},
	Keywords = {Myrinet local area network;communication channels;cut-through switches;gigabit-per-second local area network;host interfaces;packet communication;packet switching;software;computer interfaces;local area networks;network interfaces;performance evaluation;},
	Month = {feb},
	Number = {1},
	Pages = {29 -36},
	Title = {Myrinet: a gigabit-per-second local area network},
	Volume = {15},
	Year = {1995},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/40.342015}}

@inproceedings{Al-Fares:2008:SCD:1402958.1402967,
	Acmid = {1402967},
	Address = {New York, NY, USA},
	Author = {Al-Fares, Mohammad and Loukissas, Alexander and Vahdat, Amin},
	Booktitle = {Proceedings of the ACM SIGCOMM 2008 conference on Data communication},
	Doi = {10.1145/1402958.1402967},
	Isbn = {978-1-60558-175-0},
	Keywords = {data center topology, equal-cost routing},
	Location = {Seattle, WA, USA},
	Numpages = {12},
	Pages = {63--74},
	Publisher = {ACM},
	Series = {SIGCOMM '08},
	Title = {A scalable, commodity data center network architecture},
	Url = {http://doi.acm.org/10.1145/1402958.1402967},
	Year = {2008},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1402958.1402967},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1402958.1402967}}

@inproceedings{Farrington:2009:DCS:1633800.1634472,
	Acmid = {1634472},
	Address = {Washington, DC, USA},
	Author = {Farrington, Nathan and Rubow, Erik and Vahdat, Amin},
	Booktitle = {Proceedings of the 2009 17th IEEE Symposium on High Performance Interconnects},
	Doi = {10.1109/HOTI.2009.11},
	Isbn = {978-0-7695-3847-1},
	Keywords = {data center, network, ethernet, switch, fat tree, commodity, asic},
	Numpages = {10},
	Pages = {93--102},
	Publisher = {IEEE Computer Society},
	Series = {HOTI '09},
	Title = {Data Center Switch Architecture in the Age of Merchant Silicon},
	Url = {http://dx.doi.org/10.1109/HOTI.2009.11},
	Year = {2009},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/HOTI.2009.11}}

@inproceedings{Nychis:2012:ONN:2342356.2342436,
	Acmid = {2342436},
	Address = {New York, NY, USA},
	Author = {Nychis, George P. and Fallin, Chris and Moscibroda, Thomas and Mutlu, Onur and Seshan, Srinivasan},
	Booktitle = {Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer communication},
	Doi = {10.1145/2342356.2342436},
	Isbn = {978-1-4503-1419-0},
	Keywords = {congestion control, multi-core, on-chip networks},
	Location = {Helsinki, Finland},
	Numpages = {12},
	Pages = {407--418},
	Publisher = {ACM},
	Series = {SIGCOMM '12},
	Title = {On-chip networks from a networking perspective: congestion and scalability in many-core interconnects},
	Url = {http://doi.acm.org/10.1145/2342356.2342436},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342436},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342436}}

@inproceedings{Benson,
	Acmid = {1879175},
	Address = {New York, NY, USA},
	Author = {Benson, Theophilus and Akella, Aditya and Maltz, David A.},
	Booktitle = {Proceedings of the 10th ACM SIGCOMM conference on Internet measurement},
	Doi = {10.1145/1879141.1879175},
	Isbn = {978-1-4503-0483-2},
	Keywords = {characterization, data center traffic},
	Location = {Melbourne, Australia},
	Numpages = {14},
	Pages = {267--280},
	Publisher = {ACM},
	Series = {IMC '10},
	Title = {Network traffic characteristics of data centers in the wild},
	Url = {http://doi.acm.org/10.1145/1879141.1879175},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1879141.1879175},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1879141.1879175}}

@inproceedings{cardwell2000a,
	Author = {Cardwell, N. and Savage, S. and Anderson, T.},
	Booktitle = {INFOCOM 2000. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies. Proceedings. IEEE},
	Date-Modified = {2012-11-05 17:24:55 +0000},
	Doi = {10.1109/INFCOM.2000.832574},
	Issn = {0743-166X},
	Keywords = {Internet;TCP latency;Web measurements;connection establishment;data transfer latency;modeling;packet loss rate;performance;round trip time;slow start;startup effects;steady-state throughput;transfer size;Internet;delay estimation;performance evaluation;telecommunication traffic;transport protocols;},
	Month = {mar},
	Pages = {1742 -1751 vol.3},
	Title = {Modeling TCP latency},
	Volume = {3},
	Year = {2000},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/INFCOM.2000.832574}}

@inproceedings{netmap,
	Acmid = {2342830},
	Author = {Rizzo, Luigi},
	Booktitle = {Proceedings of USENIX ATC},
	Date-Modified = {2013-01-26 02:59:56 +0000},
	Location = {Boston, MA},
	Numpages = {1},
	Title = {Netmap: a novel framework for fast packet I/O},
	Url = {http://dl.acm.org/citation.cfm?id=2342821.2342830},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2342821.2342830}}

@inproceedings{Popa:2010:CCD:1921168.1921189,
	Acmid = {1921189},
	Address = {New York, NY, USA},
	Articleno = {16},
	Author = {Popa, Lucian and Ratnasamy, Sylvia and Iannaccone, Gianluca and Krishnamurthy, Arvind and Stoica, Ion},
	Booktitle = {Proceedings of the 6th International COnference},
	Doi = {10.1145/1921168.1921189},
	Isbn = {978-1-4503-0448-1},
	Location = {Philadelphia, Pennsylvania},
	Numpages = {12},
	Pages = {16:1--16:12},
	Publisher = {ACM},
	Series = {Co-NEXT '10},
	Title = {A cost comparison of datacenter network architectures},
	Url = {http://doi.acm.org/10.1145/1921168.1921189},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1921168.1921189},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1921168.1921189}}

@inproceedings{Al-Fares:2010:HDF:1855711.1855730,
	Acmid = {1855730},
	Address = {Berkeley, CA, USA},
	Author = {Al-Fares, Mohammad and Radhakrishnan, Sivasankar and Raghavan, Barath and Huang, Nelson and Vahdat, Amin},
	Booktitle = {Proceedings of the 7th USENIX conference on Networked systems design and implementation},
	Location = {San Jose, California},
	Numpages = {1},
	Pages = {19--19},
	Publisher = {USENIX Association},
	Series = {NSDI'10},
	Title = {Hedera: dynamic flow scheduling for data center networks},
	Url = {http://dl.acm.org/citation.cfm?id=1855711.1855730},
	Year = {2010},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=1855711.1855730}}

@article{342018,
	Author = {Anderson, T.E. and Culler, D.E. and Patterson, D.},
	Doi = {10.1109/40.342018},
	Issn = {0272-1732},
	Journal = {Micro, IEEE},
	Keywords = {efficient communication hardware;efficient communication software;enterprise-scale network file systems;file system performance;multiple workstation operating systems;parallel computing;scalable file storage;virtual memory;workstation networks;computer networks;local area networks;network operating systems;operating systems (computers);workstations;},
	Month = {feb},
	Number = {1},
	Pages = {54 -64},
	Title = {A case for NOW (Networks of Workstations)},
	Volume = {15},
	Year = {1995},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/40.342018}}

@article{Perche20109,
	Author = {Patrice Perche},
	Doi = {10.1016/S1353-4858(10)70125-2},
	Issn = {1353-4858},
	Journal = {Network Security},
	Number = {10},
	Pages = {9 - 12},
	Title = {Network latency: avoid paying a tax on time},
	Url = {http://www.sciencedirect.com/science/article/pii/S1353485810701252},
	Volume = {2010},
	Year = {2010},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S1353485810701252},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/S1353-4858(10)70125-2}}

@inproceedings{Binkert:2005:PAS:1090956.1092208,
	Acmid = {1092208},
	Address = {Washington, DC, USA},
	Author = {Binkert, Nathan L. and Hsu, Lisa R. and Saidi, Ali G. and Dreslinski, Ronald G. and Schultz, Andrew L. and Reinhardt, Steven K.},
	Booktitle = {Proceedings of the 14th International Conference on Parallel Architectures and Compilation Techniques},
	Doi = {10.1109/PACT.2005.35},
	Isbn = {0-7695-2429-X},
	Numpages = {13},
	Pages = {218--230},
	Publisher = {IEEE Computer Society},
	Series = {PACT '05},
	Title = {Performance Analysis of System Overheads in TCP/IP Workloads},
	Url = {http://dx.doi.org/10.1109/PACT.2005.35},
	Year = {2005},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/PACT.2005.35}}

@inproceedings{Binkert04analyzingnic,
	Author = {Nathan L. Binkert and Lisa R. Hsu and Ali G. Saidi and Ronald G. Dreslinski and Andrew L. Schultz and Steven K. Reinhardt},
	Booktitle = {In 8th Workshop on Computer Architecture Evaluation using Commercial Workloads (CAECW), Feb 2005},
	Title = {Analyzing NIC Overheads in Network-Intensive Workloads},
	Year = {2004}}

@inproceedings{Iyer:2002:RSS:633025.633050,
	Acmid = {633050},
	Address = {New York, NY, USA},
	Author = {Iyer, Sundar and Zhang, Rui and McKeown, Nick},
	Booktitle = {Proceedings of the 2002 conference on Applications, technologies, architectures, and protocols for computer communications},
	Doi = {10.1145/633025.633050},
	Isbn = {1-58113-570-X},
	Keywords = {buffers, constraint sets, routers, switching},
	Location = {Pittsburgh, Pennsylvania, USA},
	Numpages = {14},
	Pages = {251--264},
	Publisher = {ACM},
	Series = {SIGCOMM '02},
	Title = {Routers with a single stage of buffering},
	Url = {http://doi.acm.org/10.1145/633025.633050},
	Year = {2002},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/633025.633050},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/633025.633050}}

@inproceedings{Beheshti_obtaininghigh,
	Author = {Neda Beheshti and Yashar Ganjali and Ashish Goel and Nick Mckeown},
	Booktitle = {Proceedings of the 16th International Workshop on Quality of Service},
	Location = {Enschede},
	Pages = {65i--69},
	Series = {IWQoS'08},
	Title = {Obtaining high throughput in networks with tiny buffers},
	Year = {2008}}

@inproceedings{Boggs:1988:MCE:52324.52347,
	Acmid = {52347},
	Address = {New York, NY, USA},
	Author = {Boggs, D. R. and Mogul, J. C. and Kent, C. A.},
	Booktitle = {Symposium proceedings on Communications architectures and protocols},
	Doi = {10.1145/52324.52347},
	Isbn = {0-89791-279-9},
	Location = {Stanford, California, United States},
	Numpages = {13},
	Pages = {222--234},
	Publisher = {ACM},
	Series = {SIGCOMM '88},
	Title = {Measured capacity of an Ethernet: myths and reality},
	Url = {http://doi.acm.org/10.1145/52324.52347},
	Year = {1988},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/52324.52347},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/52324.52347}}

@inproceedings{Gau:2011:LMP:2069117.2069121,
	Acmid = {2069121},
	Address = {New York, NY, USA},
	Author = {Gau, Victor and Hwang, Jenq-Neng and Lan, Kung-Ming and Pai, Hung-I and Chen, Jian-Ren and Chen, Yi-Yuan},
	Booktitle = {Proceedings of the 6th ACM workshop on Wireless multimedia networking and computing},
	Doi = {10.1145/2069117.2069121},
	Isbn = {978-1-4503-0903-5},
	Keywords = {latency minimization, p-persistent csma, throughput maximization},
	Location = {Miami, Florida, USA},
	Numpages = {6},
	Pages = {3--8},
	Publisher = {ACM},
	Series = {WMuNeP '11},
	Title = {Latency minimized probabilistic CSMA/CA},
	Url = {http://doi.acm.org/10.1145/2069117.2069121},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2069117.2069121},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2069117.2069121}}

@article{1325277,
	Abstract = {The integration of data services with bandwidth-consuming broadcast services in the access network segment is anticipated in the foreseeable future. The Ethernet passive optical network (EPON) is actively being developed to meet the ever-increasing bandwidth demand in a cost-effective and future-proof manner, with internetworking among connected users to emulate shared local area network (LAN) capability being an important feature. In this work, we propose a novel EPON that utilizes an N times;N star coupler to facilitate shared LAN capability in addition to conventional access services. It features high upstream channel utilization with reasonable delay, relieves the processing burden at the central office, and offers significant savings in the downstream bandwidth for data transmission.},
	Author = {E. Wong and Chang-Joon Chae},
	Doi = {10.1109/LPT.2004.833047},
	Issn = {1041-1135},
	Journal = {Photonics Technology Letters, IEEE},
	Keywords = {CSMA/CD;access network segment;bandwidth-consuming broadcast services;carrier-sense multiple access with collision detection;channel utilization;data services integration;ethernet passive optical network;optical internetworking;shared LAN;shared local area network emulation;star coupler;LAN interconnection;broadband networks;carrier sense multiple access;optical fibre LAN;optical fibre subscriber loops;telecommunication channels;},
	Month = {sept.},
	Number = {9},
	Pages = {2195 -2197},
	Title = {CSMA/CD-based ethernet passive optical network with optical internetworking capability among users},
	Volume = {16},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/LPT.2004.833047}}

@inproceedings{Bodik:2012:SFB:2342356.2342439,
	Acmid = {2342439},
	Address = {New York, NY, USA},
	Author = {Bod\'{\i}k, Peter and Menache, Ishai and Chowdhury, Mosharaf and Mani, Pradeepkumar and Maltz, David A. and Stoica, Ion},
	Booktitle = {Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer communication},
	Doi = {10.1145/2342356.2342439},
	Isbn = {978-1-4503-1419-0},
	Keywords = {bandwidth, datacenter networks, fault tolerance},
	Location = {Helsinki, Finland},
	Numpages = {12},
	Pages = {431--442},
	Publisher = {ACM},
	Series = {SIGCOMM '12},
	Title = {Surviving failures in bandwidth-constrained datacenters},
	Url = {http://doi.acm.org/10.1145/2342356.2342439},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342439},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342439}}

@inproceedings{El-Sayed:2012:TMD:2254756.2254778,
	Acmid = {2254778},
	Address = {New York, NY, USA},
	Author = {El-Sayed, Nosayba and Stefanovici, Ioan A. and Amvrosiadis, George and Hwang, Andy A. and Schroeder, Bianca},
	Booktitle = {Proceedings of the 12th ACM SIGMETRICS/PERFORMANCE joint international conference on Measurement and Modeling of Computer Systems},
	Doi = {10.1145/2254756.2254778},
	Isbn = {978-1-4503-1097-0},
	Keywords = {CPU, DRAM, LSE, data center, energy, fans, hard drive, memory, performance, reliability, temperature},
	Location = {London, England, UK},
	Numpages = {12},
	Pages = {163--174},
	Publisher = {ACM},
	Series = {SIGMETRICS '12},
	Title = {Temperature management in data centers: why some (might) like it hot},
	Url = {http://doi.acm.org/10.1145/2254756.2254778},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2254756.2254778},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2254756.2254778}}

@inproceedings{Wu:2012:NAD:2342356.2342438,
	Acmid = {2342438},
	Address = {New York, NY, USA},
	Author = {Wu, Xin and Turner, Daniel and Chen, Chao-Chih and Maltz, David A. and Yang, Xiaowei and Yuan, Lihua and Zhang, Ming},
	Booktitle = {Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer communication},
	Doi = {10.1145/2342356.2342438},
	Isbn = {978-1-4503-1419-0},
	Keywords = {automated failure mitigation, datacenter networks},
	Location = {Helsinki, Finland},
	Numpages = {12},
	Pages = {419--430},
	Publisher = {ACM},
	Series = {SIGCOMM '12},
	Title = {NetPilot: automating datacenter network failure mitigation},
	Url = {http://doi.acm.org/10.1145/2342356.2342438},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342438},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342438}}

@inproceedings{Vishwanath:2010:CCC:1807128.1807161,
	Acmid = {1807161},
	Address = {New York, NY, USA},
	Author = {Vishwanath, Kashi Venkatesh and Nagappan, Nachiappan},
	Booktitle = {Proceedings of the 1st ACM symposium on Cloud computing},
	Doi = {10.1145/1807128.1807161},
	Isbn = {978-1-4503-0036-0},
	Keywords = {datacenters, failures},
	Location = {Indianapolis, Indiana, USA},
	Numpages = {12},
	Pages = {193--204},
	Publisher = {ACM},
	Series = {SoCC '10},
	Title = {Characterizing cloud computing hardware reliability},
	Url = {http://doi.acm.org/10.1145/1807128.1807161},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1807128.1807161},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1807128.1807161}}

@inproceedings{Wilson:2011:BNL:2018436.2018443,
	Acmid = {2018443},
	Author = {Wilson, Christo and Ballani, Hitesh and Karagiannis, Thomas and Rowtron, Ant},
	Booktitle = {Proceedings of SIGCOMM},
	Doi = {10.1145/2018436.2018443},
	Isbn = {978-1-4503-0797-0},
	Keywords = {datacenter, deadline, online services, rate control, sla},
	Location = {Toronto, Ontario, Canada},
	Numpages = {12},
	Pages = {50--61},
	Title = {{Better never than late: meeting deadlines in datacenter networks}},
	Url = {http://doi.acm.org/10.1145/2018436.2018443},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2018436.2018443},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2018436.2018443}}

@article{Patterson:2004:LLB:1022594.1022596,
	Acmid = {1022596},
	Address = {New York, NY, USA},
	Author = {Patterson, David A.},
	Doi = {10.1145/1022594.1022596},
	Issn = {0001-0782},
	Issue_Date = {October 2004},
	Journal = {Commun. ACM},
	Month = oct,
	Number = {10},
	Numpages = {5},
	Pages = {71--75},
	Publisher = {ACM},
	Title = {Latency lags bandwith},
	Url = {http://doi.acm.org/10.1145/1022594.1022596},
	Volume = {47},
	Year = {2004},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1022594.1022596},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1022594.1022596}}

@inproceedings{Heller:2012:CPP:2342441.2342444,
	Acmid = {2342444},
	Address = {New York, NY, USA},
	Author = {Heller, Brandon and Sherwood, Rob and McKeown, Nick},
	Booktitle = {Proceedings of the first workshop on Hot topics in software defined networks},
	Doi = {10.1145/2342441.2342444},
	Isbn = {978-1-4503-1477-0},
	Keywords = {controller placement, latency, openflow, sdn, software-defined networks},
	Location = {Helsinki, Finland},
	Numpages = {6},
	Pages = {7--12},
	Publisher = {ACM},
	Series = {HotSDN '12},
	Title = {The controller placement problem},
	Url = {http://doi.acm.org/10.1145/2342441.2342444},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342441.2342444},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342441.2342444}}

@inproceedings{Keslassy:2003:SIR:863955.863978,
	Acmid = {863978},
	Address = {New York, NY, USA},
	Author = {Keslassy, Isaac and Chuang, Shang-Tse and Yu, Kyoungsik and Miller, David and Horowitz, Mark and Solgaard, Olav and McKeown, Nick},
	Booktitle = {Proceedings of the 2003 conference on Applications, technologies, architectures, and protocols for computer communications},
	Doi = {10.1145/863955.863978},
	Isbn = {1-58113-735-4},
	Keywords = {internet router, load-balancing, packet-switch},
	Location = {Karlsruhe, Germany},
	Numpages = {12},
	Pages = {189--200},
	Publisher = {ACM},
	Series = {SIGCOMM '03},
	Title = {Scaling internet routers using optics},
	Url = {http://doi.acm.org/10.1145/863955.863978},
	Year = {2003},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/863955.863978},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/863955.863978}}

@inproceedings{Ye:2010:DSO:1872007.1872037,
	Acmid = {1872037},
	Address = {New York, NY, USA},
	Articleno = {24},
	Author = {Ye, Xiaohui and Yin, Yawei and Yoo, S. J. B. and Mejia, Paul and Proietti, Roberto and Akella, Venkatesh},
	Booktitle = {Proceedings of the 6th ACM/IEEE Symposium on Architectures for Networking and Communications Systems},
	Doi = {10.1145/1872007.1872037},
	Isbn = {978-1-4503-0379-8},
	Keywords = {AWGR, data center networks, low latency optical switches},
	Location = {La Jolla, California},
	Numpages = {12},
	Pages = {24:1--24:12},
	Publisher = {ACM},
	Series = {ANCS '10},
	Title = {DOS: a scalable optical switch for datacenters},
	Url = {http://doi.acm.org/10.1145/1872007.1872037},
	Year = {2010},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/1872007.1872037},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/1872007.1872037}}

@inproceedings{Bazzaz:2011:SOD:2038916.2038946,
	Acmid = {2038946},
	Address = {New York, NY, USA},
	Articleno = {30},
	Author = {Bazzaz, Hamid Hajabdolali and Tewari, Malveeka and Wang, Guohui and Porter, George and Ng, T. S. Eugene and Andersen, David G. and Kaminsky, Michael and Kozuch, Michael A. and Vahdat, Amin},
	Booktitle = {Proceedings of the 2nd ACM Symposium on Cloud Computing},
	Doi = {10.1145/2038916.2038946},
	Isbn = {978-1-4503-0976-9},
	Keywords = {data center networking, hybrid network, optical circuit switching},
	Location = {Cascais, Portugal},
	Numpages = {8},
	Pages = {30:1--30:8},
	Publisher = {ACM},
	Series = {SOCC '11},
	Title = {Switching the optical divide: fundamental challenges for hybrid electrical/optical datacenter networks},
	Url = {http://doi.acm.org/10.1145/2038916.2038946},
	Year = {2011},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2038916.2038946},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2038916.2038946}}

@inproceedings{Alizadeh:2012:LMT:2228298.2228324,
	Acmid = {2228324},
	Author = {Alizadeh, Mohammad and Kabbani, Abdul and Edsall, Tom and Prabhakar, Balaji and Vahdat, Amin and Yasuda, Masato},
	Booktitle = {Proceedings of NSDI},
	Location = {San Jose, CA},
	Numpages = {1},
	Title = {Less is more: trading a little bandwidth for ultra-low latency in the data center},
	Url = {http://dl.acm.org/citation.cfm?id=2228298.2228324},
	Year = {2012},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=2228298.2228324}}

@inproceedings{Vamanan:2012:DDT:342356.2342388,
	Acmid = {2342388},
	Address = {New York, NY, USA},
	Author = {Vamanan, Balajee and Hasan, Jahangir and Vijaykumar, T.N.},
	Booktitle = {Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer communication},
	Date-Modified = {2012-11-05 15:35:42 +0000},
	Doi = {10.1145/2342356.2342388},
	Isbn = {978-1-4503-1419-0},
	Keywords = {cloud services, datacenter, deadline, ecn, oldi, sla, tcp},
	Location = {Helsinki, Finland},
	Numpages = {12},
	Pages = {115--126},
	Publisher = {ACM},
	Series = {SIGCOMM '12},
	Title = {Deadline-aware datacenter tcp (D2TCP)},
	Url = {http://doi.acm.org/10.1145/2342356.2342388},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342388},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342388}}

@inproceedings{Hong:2012:FFQ:2342356.2342389,
	Acmid = {2342389},
	Author = {Hong, Chi-Yao and Caesar, Matthew and Godfrey, P. Brighten},
	Booktitle = {Proceedings of SIGCOMM},
	Doi = {10.1145/2342356.2342389},
	Isbn = {978-1-4503-1419-0},
	Keywords = {data center, deadline, flow scheduling},
	Location = {Helsinki, Finland},
	Numpages = {12},
	Pages = {127--138},
	Title = {{Finishing flows quickly with preemptive scheduling}},
	Url = {http://doi.acm.org/10.1145/2342356.2342389},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342389},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342389}}

@article{Metcalfe:1983:EDP:357980.358015,
	Acmid = {358015},
	Address = {New York, NY, USA},
	Author = {Metcalfe, Robert M. and Boggs, David R.},
	Doi = {10.1145/357980.358015},
	Issn = {0001-0782},
	Issue_Date = {Jan. 1983},
	Journal = {Commun. ACM},
	Keywords = {broadcast communication, computer networks, distributed computing, distributed control, multiprocessing, packet switching, statistical arbitration},
	Month = jan,
	Number = {1},
	Numpages = {6},
	Pages = {90--95},
	Publisher = {ACM},
	Title = {Ethernet: distributed packet switching for local computer networks},
	Url = {http://doi.acm.org/10.1145/357980.358015},
	Volume = {26},
	Year = {1983},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/357980.358015},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/357980.358015}}

@inproceedings{Zats:2012:DRF:2342356.2342390,
	Acmid = {2342390},
	Address = {New York, NY, USA},
	Author = {Zats, David and Das, Tathagata and Mohan, Prashanth and Borthakur, Dhruba and Katz, Randy},
	Booktitle = {Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer communication},
	Doi = {10.1145/2342356.2342390},
	Isbn = {978-1-4503-1419-0},
	Keywords = {datacenter network, flow statistics, multi-path},
	Location = {Helsinki, Finland},
	Numpages = {12},
	Pages = {139--150},
	Publisher = {ACM},
	Series = {SIGCOMM '12},
	Title = {DeTail: reducing the flow completion time tail in datacenter networks},
	Url = {http://doi.acm.org/10.1145/2342356.2342390},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342390},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342390}}

@inproceedings{Xie:2012:OCC:2342356.2342397,
	Acmid = {2342397},
	Address = {New York, NY, USA},
	Author = {Xie, Di and Ding, Ning and Hu, Y. Charlie and Kompella, Ramana},
	Booktitle = {Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer communication},
	Doi = {10.1145/2342356.2342397},
	Isbn = {978-1-4503-1419-0},
	Keywords = {allocation, bandwidth, datacenter, network reservation, profiling},
	Location = {Helsinki, Finland},
	Numpages = {12},
	Pages = {199--210},
	Publisher = {ACM},
	Series = {SIGCOMM '12},
	Title = {The only constant is change: incorporating time-varying network reservations in data centers},
	Url = {http://doi.acm.org/10.1145/2342356.2342397},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2342356.2342397},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2342356.2342397}}

@inproceedings{Eberle:2002:SHL:762761.762804,
	Acmid = {762804},
	Address = {Los Alamitos, CA, USA},
	Author = {Eberle, Hans and Gura, Nils},
	Booktitle = {Proceedings of the 2002 ACM/IEEE conference on Supercomputing},
	Location = {Baltimore, Maryland},
	Numpages = {12},
	Pages = {1--12},
	Publisher = {IEEE Computer Society Press},
	Series = {Supercomputing '02},
	Title = {Separated high-bandwidth and low-latency communication in the cluster interconnect Clint},
	Url = {http://dl.acm.org/citation.cfm?id=762761.762804},
	Year = {2002},
	Bdsk-Url-1 = {http://dl.acm.org/citation.cfm?id=762761.762804}}

@inproceedings{Arpaci-dusseau99clusteri/o,
	Author = {Remzi H. Arpaci-dusseau and Eric Anderson and Noah Treuhaft and David E. Culler and Joseph M. Hellerstein and David Patterson and Kathy Yelick},
	Booktitle = {In Proceedings of the Sixth Workshop on Input/Output in Parallel and Distributed Systems},
	Pages = {10--22},
	Publisher = {ACM Press},
	Title = {Cluster I/O with River: Making the Fast Case Common},
	Year = {1999}}

@inproceedings{342706,
	Abstract = {Ethernet has been the dominant local area network architecture in the last decade, and we believe that it will continue to be so because of its cost-effectiveness and the availability of higher-bandwidth Ethernets. We propose and evaluate a software-based protocol called RETHER (Real-time ETHERnet) that provider real-time performance guarantees to multimedia applications without modifying existing Ethernet hardware. RETHER features a hybrid mode of operation to reduce the performance impact on non-real-time network packets, a race-condition-free distributed admission control mechanism, and an efficient token-passing scheme that protects the network against token loss due to node failures},
	Author = {Venkatramani, C. and Tzi-cker Chiueh},
	Booktitle = {Real-Time Systems Symposium, 1994., Proceedings.},
	Doi = {10.1109/REAL.1994.342706},
	Keywords = {Ethernet; RETHER; local area network architecture; multimedia applications; node failures; race-condition-free distributed admission control mechanism; real-time performance; real-time traffic; software-based protocol; token loss; token-passing scheme; local area networks; multimedia computing; network interfaces; real-time systems; transport protocols;},
	Month = {dec},
	Pages = {282 -286},
	Title = {Supporting real-time traffic on Ethernet},
	Year = {1994},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/REAL.1994.342706}}

@article{Lee2002411,
	Abstract = {The real-time industrial network, often referred to as fieldbus, is an important element for building automated manufacturing systems. Thus, in order to satisfy the real-time requirements of field devices such as sensors, actuators, and controllers, numerous standard organizations and vendors have developed various fieldbus protocols. As a result, the IEC 61158 standard, including Profibus, WorldFIP, and Foundation Fieldbus, was recently announced as an international standard. These fieldbus protocols have an important advantage over the widely used Ethernet (IEEE 802.3) in terms of the deterministic characteristics. However, the application of fieldbus has been limited due to the high cost of hardware and the difficulty in interfacing with multivendor products. In order to solve these problems, the computer network technology, especially Ethernet, is being adopted by the industrial automation field. The key technical obstacle for Ethernet for industrial applications is that its nondeterministic behavior makes it inadequate for real-time applications, where the frames containing real-time information, such as control command and alarm signal, have to be delivered within a certain time limit. Recently, the development of switched Ethernet shows a very promising prospect for industrial applications due to the elimination of uncertainties in the network operation that leads to the dramatically improved performance. This paper focuses on the application of the switched Ethernet for industrial communications. More specifically, this paper presents the performance evaluation of the switched Ethernet on an experimental network testbed along with an implementation method for using the switched Ethernet for industrial automation.},
	Author = {Kyung Chang Lee and Suk Lee},
	Doi = {10.1016/S0920-5489(02)00070-3},
	Issn = {0920-5489},
	Journal = {Computer Standards \& Interfaces},
	Keywords = {Communication delay},
	Number = {5},
	Pages = {411 - 423},
	Title = {Performance evaluation of switched Ethernet for real-time industrial communications},
	Url = {http://www.sciencedirect.com/science/article/pii/S0920548902000703},
	Volume = {24},
	Year = {2002},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/S0920548902000703},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/S0920-5489(02)00070-3}}

@inproceedings{484195,
	Abstract = {Efficient transfer of information between all levels of a manufacturing organisation is becoming an increasingly essential element in maintaining industrial competitiveness. Since manufacturing is a distributed activity with varying levels of time-criticality at different levels in the hierarchy, the architecture of the computer communication networks must match these fundamental requirements. One appropriate solution is the General Motor's Manufacturing Automation Protocol local area network-MAP. Another possibility, proposed in this paper, is to use Ethernet for higher level communications, where time is less critical, and to supplement this with a ldquo;real-time Ethernet rdquo; at the lower levels. This paper therefore describes a system designed to convert segments of a factory wide Ethernet network to support hard real-time operation. The system, called TEMPRA, uses a simple method to control the release of Ethernet packets in a collision free manner. High priority real-time operation is guaranteed to the user through a dual stack architecture, which has a separate deterministic stack for high reliability real-time messages-whilst background traffic is handled using CSMA/CD and TCP/IP protocols},
	Author = {Pritty, D.W. and Malone, J.R. and Smeed, D.N. and Banerjee, S.K. and Lawrie, N.L.},
	Booktitle = {Industrial Electronics, Control, and Instrumentation, 1995., Proceedings of the 1995 IEEE IECON 21st International Conference on},
	Doi = {10.1109/IECON.1995.484195},
	Keywords = {CSMA/CD protocols;Ethernet;Manufacturing Automation Protocol;TCP/IP protocols;TEMPRA;background traffic;collision free communication;computer communication networks architecture;deterministic stack;distributed activity;dual stack architecture;factory networking;hierarchy;higher level communications;information transfer;local area network;manufacturing organisation;packet release;real-time operation;real-time upgrade;time-criticality;carrier sense multiple access;distributed control;hierarchical systems;industrial control;local area networks;network interfaces;real-time systems;transport protocols;},
	Month = {nov},
	Pages = {1631 -1637 vol.2},
	Title = {A real-time upgrade for Ethernet based factory networking},
	Volume = {2},
	Year = {1995},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/IECON.1995.484195}}

@inproceedings{1310992,
	Abstract = { Ethernet, the most widely used commodity network, increasingly moves toward switches as implementation technology thus replacing buses. This allows to use traffic shaping techniques to implement hard real-time distributed systems on commodity networks. However, because Ethernet switches lack build-in policing features, nodes connected by switched Ethernet need to be cooperative. Although the theory behind traffic shaping for real-time communication is known for some time, it has not been considered for Ethernet so far. In this paper, we present the implementation of traffic shaping on switched Ethernet technology. We make thorough experiments to understand the cost and practical limits of using fast and gigabit Ethernet for hard real-time communication. We do measurements to analyze properties of switches and delays that we can achieve using these switches. We further analyze the influences of non real-time Linux nodes sharing the network.},
	Author = {Loeser, J. and Haertig, H.},
	Booktitle = {Real-Time Systems, 2004. ECRTS 2004. Proceedings. 16th Euromicro Conference on},
	Doi = {10.1109/EMRTS.2004.1310992},
	Issn = {1068-3070},
	Keywords = {Linux; build-in policing features; commodity network; low-latency communication; real-time communication; real-time distributed systems; switched Ethernet; traffic shaping; Linux; delays; local area networks; real-time systems; telecommunication traffic;},
	Month = {june-2 july},
	Pages = {13 - 22},
	Title = {Low-latency hard real-time communication over switched Ethernet},
	Year = {2004},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/EMRTS.2004.1310992}}

@inproceedings{Vattikonda:2012:PTD:2168836.2168859,
	Acmid = {2168859},
	Address = {New York, NY, USA},
	Author = {Vattikonda, Bhanu Chandra and Porter, George and Vahdat, Amin and Snoeren, Alex C.},
	Booktitle = {Proceedings of the 7th ACM european conference on Computer Systems},
	Doi = {10.1145/2168836.2168859},
	Isbn = {978-1-4503-1223-3},
	Keywords = {TDMA, datacenter, ethernet},
	Location = {Bern, Switzerland},
	Numpages = {14},
	Pages = {225--238},
	Publisher = {ACM},
	Series = {EuroSys '12},
	Title = {Practical TDMA for datacenter ethernet},
	Url = {http://doi.acm.org/10.1145/2168836.2168859},
	Year = {2012},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/2168836.2168859},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/2168836.2168859}}

@inproceedings{Meisner:1977:DST:800103.803346,
	Acmid = {803346},
	Address = {New York, NY, USA},
	Author = {Meisner, Norman B. and Segal, Joshua L. and Tanigawa, Malcolm Y.},
	Booktitle = {Proceedings of the fifth symposium on Data communications},
	Doi = {10.1145/800103.803346},
	Location = {Snowbird, Utah, United States},
	Numpages = {1.04},
	Pages = {5.14--5.18},
	Publisher = {ACM},
	Series = {SIGCOMM '77},
	Title = {Dual-Mode Slotted TDMA Digital Bus},
	Url = {http://doi.acm.org/10.1145/800103.803346},
	Year = {1977},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/800103.803346},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/800103.803346}}

@inproceedings{Wandeler:2006:OTT:1118299.1118417,
	Acmid = {1118417},
	Address = {Piscataway, NJ, USA},
	Author = {Wandeler, Ernesto and Thiele, Lothar},
	Booktitle = {Proceedings of the 2006 Asia and South Pacific Design Automation Conference},
	Doi = {10.1145/1118299.1118417},
	Isbn = {0-7803-9451-8},
	Location = {Yokohama, Japan},
	Numpages = {6},
	Pages = {479--484},
	Publisher = {IEEE Press},
	Series = {ASP-DAC '06},
	Title = {Optimal TDMA time slot and cycle length allocation for hard real-time systems},
	Url = {http://dx.doi.org/10.1145/1118299.1118417},
	Year = {2006},
	Bdsk-Url-1 = {http://dx.doi.org/10.1145/1118299.1118417}}

// Tomba, L.},
@inproceedings{zorzi1994comparison,
  title={A comparison of CDMA, TDMA and Slotted ALOHA multiple access schemes in cellular mobile radio systems},
  author={Zorzi, M. and others},
  booktitle={5th IEEE International Symposium on Wireless Networks},
  OPT_volume={3},
  OPT_pages={776--780},
  year={1994},
  OPT_organization={IEEE}
}
@inproceedings{529070,
	Abstract = {The increasing demand for mobile radio services and the scarce bandwidth available suggest to devote considerable research efforts to find more efficient multiple access techniques in order to improve the system capacity. We compare the system performance of three mobile radio systems: the well known TDMA system, which is the basis of the European GSM, the recent CDMA system (a standard introduced by Qualcomm) and the proposed slotted Aloha packet system. Performance comparisons are made for these systems when the radio propagation is impaired by Rice fading and log-normal shadowing. The results show that the performance of slotted Aloha is comparable or better than CDMA, while exhibiting a virtual insensitivity to propagation conditions},
	Author = {Zorzi, M. and others},
Booktitle = {Personal, Indoor and Mobile Radio Communications, 1994. Wireless Networks - Catching the Mobile Future., 5th IEEE International Symposium on},
	Doi = {10.1109/WNCMF.1994.529070},
	Keywords = {CDMA;CDMA system;European GSM;Qualcomm;Rice fading;TDMA;bandwidth;cellular mobile radio systems;log-normal shadowing;mobile radio services;multiple access techniques;propagation conditions;radio propagation;slotted Aloha multiple access;slotted Aloha packet system;standard;system capacity;system performance;Rician channels;cellular radio;code division multiple access;fading;land mobile radio;packet switching;radiowave propagation;time division multiple access;},
	Month = {sep},
	Pages = {776 -780 vol.3},
	Title = {A comparison of CDMA, TDMA and slotted Aloha multiple access schemes in cellular mobile radio systems},
	Volume = {3},
	Year = {1994},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/WNCMF.1994.529070}}

@article{Bux18625,
	Abstract = {The major technical concepts underlying token-ring technology are examined, and performance issues arising in the design of such local-area networks (LANs) are detailed. Following a survey of analytical queuing models to describe the basic token-ring operation, three topics are discussed in detail: (1) the IEEE 802.5 token ring and its performance; (2) the ANSI fiber distributed data interface (FDDI) token ring and its performance; and (3) architecture and performance issues arising in the interconnection of token-ring networks with regard to the various components of a multiring architecture demonstrating which congestion-control problems can arise in such a network and how they can be overcome. The author concludes with a number of open questions concerning the understanding of the quantitative behavior of token-ring-based LANs},
	Author = {Bux, W.},
	Date-Modified = {2012-11-02 12:51:08 +0000},
	Doi = {10.1109/5.18625},
	Issn = {0018-9219},
	Journal = {Proceedings of the IEEE},
	Keywords = {ANSI fiber distributed data interface;IEEE 802.5;congestion-control problems;local-area networks;multiring architecture;queuing models;token-ring technology;local area networks;},
	Month = {feb},
	Number = {2},
	Pages = {238 -256},
	Title = {Token-ring local-area networks and their performance},
	Volume = {77},
	Year = {1989},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/5.18625}}

@electronic{infiniband2000,
	Author = {{InfiniBand Trade Association}},
	Date-Modified = {2012-11-05 13:53:50 +0000},
	Publisher = {InfiniBand Trade Association},
	Title = {InfiniBand Architecture Specification: Release 1.0},
	Year = {2000}}
